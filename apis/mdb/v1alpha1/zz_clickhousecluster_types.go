/*
Copyright 2022 YANDEX LLC
This is modified version of the software, made by the Crossplane Authors
and available at: https://github.com/crossplane-contrib/provider-jet-template

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AccessInitParameters struct {

	// (Boolean) Allow access for DataLens.
	// Allow access for DataLens.
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// (Boolean) Allow access for DataTransfer.
	// Allow access for DataTransfer.
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// (Boolean) Allow access for Yandex.Metrika.
	// Allow access for Yandex.Metrika.
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// (Boolean) Allow access for Serverless.
	// Allow access for Serverless.
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// (Boolean) Allow access for Web SQL.
	// Allow access for Web SQL.
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// (Boolean) Allow access for YandexQuery.
	// Allow access for YandexQuery.
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type AccessObservation struct {

	// (Boolean) Allow access for DataLens.
	// Allow access for DataLens.
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// (Boolean) Allow access for DataTransfer.
	// Allow access for DataTransfer.
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// (Boolean) Allow access for Yandex.Metrika.
	// Allow access for Yandex.Metrika.
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// (Boolean) Allow access for Serverless.
	// Allow access for Serverless.
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// (Boolean) Allow access for Web SQL.
	// Allow access for Web SQL.
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// (Boolean) Allow access for YandexQuery.
	// Allow access for YandexQuery.
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type AccessParameters struct {

	// (Boolean) Allow access for DataLens.
	// Allow access for DataLens.
	// +kubebuilder:validation:Optional
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// (Boolean) Allow access for DataTransfer.
	// Allow access for DataTransfer.
	// +kubebuilder:validation:Optional
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// (Boolean) Allow access for Yandex.Metrika.
	// Allow access for Yandex.Metrika.
	// +kubebuilder:validation:Optional
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// (Boolean) Allow access for Serverless.
	// Allow access for Serverless.
	// +kubebuilder:validation:Optional
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// (Boolean) Allow access for Web SQL.
	// Allow access for Web SQL.
	// +kubebuilder:validation:Optional
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// (Boolean) Allow access for YandexQuery.
	// Allow access for YandexQuery.
	// +kubebuilder:validation:Optional
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type BackupWindowStartInitParameters struct {

	// (Number) The hour at which backup will be started.
	// The hour at which backup will be started.
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// (Number) The minute at which backup will be started.
	// The minute at which backup will be started.
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type BackupWindowStartObservation struct {

	// (Number) The hour at which backup will be started.
	// The hour at which backup will be started.
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// (Number) The minute at which backup will be started.
	// The minute at which backup will be started.
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type BackupWindowStartParameters struct {

	// (Number) The hour at which backup will be started.
	// The hour at which backup will be started.
	// +kubebuilder:validation:Optional
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// (Number) The minute at which backup will be started.
	// The minute at which backup will be started.
	// +kubebuilder:validation:Optional
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type ClickhouseClusterInitParameters struct {

	// (Block List, Max: 1) Access policy to the ClickHouse cluster. (see below for nested schema)
	// Access policy to the ClickHouse cluster.
	Access []AccessInitParameters `json:"access,omitempty" tf:"access,omitempty"`

	// (String, Sensitive) A password used to authorize as user admin when sql_user_management enabled.
	// A password used to authorize as user `admin` when `sql_user_management` enabled.
	AdminPasswordSecretRef *v1.SecretKeySelector `json:"adminPasswordSecretRef,omitempty" tf:"-"`

	// (Number) The period in days during which backups are stored.
	// The period in days during which backups are stored.
	BackupRetainPeriodDays *float64 `json:"backupRetainPeriodDays,omitempty" tf:"backup_retain_period_days,omitempty"`

	// (Block List, Max: 1) Time to start the daily backup, in the UTC timezone. (see below for nested schema)
	// Time to start the daily backup, in the UTC timezone.
	BackupWindowStart []BackupWindowStartInitParameters `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// (Block List, Max: 1) Configuration of the ClickHouse subcluster. (see below for nested schema)
	// Configuration of the ClickHouse subcluster.
	Clickhouse []ClickhouseInitParameters `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// (Block List, Max: 1) Cloud Storage settings. (see below for nested schema)
	// Cloud Storage settings.
	CloudStorage []CloudStorageInitParameters `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// (String) The cluster identifier.
	// The cluster identifier.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Boolean) Whether to copy schema on new ClickHouse hosts.
	// Whether to copy schema on new ClickHouse hosts.
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// (Block Set, Deprecated) A database of the ClickHouse cluster. (see below for nested schema)
	// A database of the ClickHouse cluster.
	Database []DatabaseInitParameters `json:"database,omitempty" tf:"database,omitempty"`

	// (Boolean) The true value means that resource is protected from accidental deletion.
	// The `true` value means that resource is protected from accidental deletion.
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// (String) The resource description.
	// The resource description.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (Boolean) Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	// Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// (String) Deployment environment of the ClickHouse cluster. Can be either PRESTABLE or PRODUCTION.
	// Deployment environment of the ClickHouse cluster. Can be either `PRESTABLE` or `PRODUCTION`.
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// id is used.
	// The folder identifier that resource belongs to. If it is not provided, the default provider `folder-id` is used.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/resourcemanager/v1alpha1.Folder
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// Reference to a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDRef *v1.Reference `json:"folderIdRef,omitempty" tf:"-"`

	// Selector for a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDSelector *v1.Selector `json:"folderIdSelector,omitempty" tf:"-"`

	// (Block Set) A set of protobuf or capnproto format schemas. (see below for nested schema)
	// A set of `protobuf` or `capnproto` format schemas.
	FormatSchema []FormatSchemaInitParameters `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// (Block List, Min: 1) A host of the ClickHouse cluster. (see below for nested schema)
	// A host of the ClickHouse cluster.
	Host []HostInitParameters `json:"host,omitempty" tf:"host,omitempty"`

	// (Map of String) A set of key/value label pairs which assigned to resource.
	// A set of key/value label pairs which assigned to resource.
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// (Block Set) A group of machine learning models. (see below for nested schema)
	// A group of machine learning models.
	MLModel []MLModelInitParameters `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	MaintenanceWindow []MaintenanceWindowInitParameters `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// (String) The resource name.
	// The resource name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The VPC Network ID of subnets which resource attached to.
	// The `VPC Network ID` of subnets which resource attached to.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Network
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Reference to a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDRef *v1.Reference `json:"networkIdRef,omitempty" tf:"-"`

	// Selector for a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDSelector *v1.Selector `json:"networkIdSelector,omitempty" tf:"-"`

	// (Boolean) Grants admin user database management permission.
	// Grants `admin` user database management permission.
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// (Boolean) Enables admin user with user management permission.
	// Enables `admin` user with user management permission.
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// (Set of String) The list of security groups applied to resource or their components.
	// The list of security groups applied to resource or their components.
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// (String) Service account which linked to the resource.
	// [Service account](https://yandex.cloud/docs/iam/concepts/users/service-accounts) which linked to the resource.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/iam/v1alpha1.ServiceAccount
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// Reference to a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDRef *v1.Reference `json:"serviceAccountIdRef,omitempty" tf:"-"`

	// Selector for a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDSelector *v1.Selector `json:"serviceAccountIdSelector,omitempty" tf:"-"`

	// (Block Set) A shard of the ClickHouse cluster. (see below for nested schema)
	// A shard of the ClickHouse cluster.
	Shard []ShardInitParameters `json:"shard,omitempty" tf:"shard,omitempty"`

	// (Block List) A group of clickhouse shards. (see below for nested schema)
	// A group of clickhouse shards.
	ShardGroup []ShardGroupInitParameters `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// (Block Set, Deprecated) A user of the ClickHouse cluster. (see below for nested schema)
	// A user of the ClickHouse cluster.
	User []UserInitParameters `json:"user,omitempty" tf:"user,omitempty"`

	// (String) Version of the ClickHouse server software.
	// Version of the ClickHouse server software.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// (Block List, Max: 1) Configuration of the ZooKeeper subcluster. (see below for nested schema)
	// Configuration of the ZooKeeper subcluster.
	Zookeeper []ZookeeperInitParameters `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterObservation struct {

	// (Block List, Max: 1) Access policy to the ClickHouse cluster. (see below for nested schema)
	// Access policy to the ClickHouse cluster.
	Access []AccessObservation `json:"access,omitempty" tf:"access,omitempty"`

	// (Number) The period in days during which backups are stored.
	// The period in days during which backups are stored.
	BackupRetainPeriodDays *float64 `json:"backupRetainPeriodDays,omitempty" tf:"backup_retain_period_days,omitempty"`

	// (Block List, Max: 1) Time to start the daily backup, in the UTC timezone. (see below for nested schema)
	// Time to start the daily backup, in the UTC timezone.
	BackupWindowStart []BackupWindowStartObservation `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// (Block List, Max: 1) Configuration of the ClickHouse subcluster. (see below for nested schema)
	// Configuration of the ClickHouse subcluster.
	Clickhouse []ClickhouseObservation `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// (Block List, Max: 1) Cloud Storage settings. (see below for nested schema)
	// Cloud Storage settings.
	CloudStorage []CloudStorageObservation `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// (String) The cluster identifier.
	// The cluster identifier.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Boolean) Whether to copy schema on new ClickHouse hosts.
	// Whether to copy schema on new ClickHouse hosts.
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// (String) The creation timestamp of the resource.
	// The creation timestamp of the resource.
	CreatedAt *string `json:"createdAt,omitempty" tf:"created_at,omitempty"`

	// (Block Set, Deprecated) A database of the ClickHouse cluster. (see below for nested schema)
	// A database of the ClickHouse cluster.
	Database []DatabaseObservation `json:"database,omitempty" tf:"database,omitempty"`

	// (Boolean) The true value means that resource is protected from accidental deletion.
	// The `true` value means that resource is protected from accidental deletion.
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// (String) The resource description.
	// The resource description.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (Boolean) Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	// Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// (String) Deployment environment of the ClickHouse cluster. Can be either PRESTABLE or PRODUCTION.
	// Deployment environment of the ClickHouse cluster. Can be either `PRESTABLE` or `PRODUCTION`.
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// id is used.
	// The folder identifier that resource belongs to. If it is not provided, the default provider `folder-id` is used.
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// (Block Set) A set of protobuf or capnproto format schemas. (see below for nested schema)
	// A set of `protobuf` or `capnproto` format schemas.
	FormatSchema []FormatSchemaObservation `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// (String) Aggregated health of the cluster. Can be ALIVE, DEGRADED, DEAD or HEALTH_UNKNOWN. For more information see health field of JSON representation in the official documentation.
	// Aggregated health of the cluster. Can be `ALIVE`, `DEGRADED`, `DEAD` or `HEALTH_UNKNOWN`. For more information see `health` field of JSON representation in [the official documentation](https://yandex.cloud/docs/managed-clickhouse/api-ref/Cluster/).
	Health *string `json:"health,omitempty" tf:"health,omitempty"`

	// (Block List, Min: 1) A host of the ClickHouse cluster. (see below for nested schema)
	// A host of the ClickHouse cluster.
	Host []HostObservation `json:"host,omitempty" tf:"host,omitempty"`

	// (String) The ID of this resource.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// (Map of String) A set of key/value label pairs which assigned to resource.
	// A set of key/value label pairs which assigned to resource.
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// (Block Set) A group of machine learning models. (see below for nested schema)
	// A group of machine learning models.
	MLModel []MLModelObservation `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	MaintenanceWindow []MaintenanceWindowObservation `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// (String) The resource name.
	// The resource name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The VPC Network ID of subnets which resource attached to.
	// The `VPC Network ID` of subnets which resource attached to.
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// (Boolean) Grants admin user database management permission.
	// Grants `admin` user database management permission.
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// (Boolean) Enables admin user with user management permission.
	// Enables `admin` user with user management permission.
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// (Set of String) The list of security groups applied to resource or their components.
	// The list of security groups applied to resource or their components.
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// (String) Service account which linked to the resource.
	// [Service account](https://yandex.cloud/docs/iam/concepts/users/service-accounts) which linked to the resource.
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// (Block Set) A shard of the ClickHouse cluster. (see below for nested schema)
	// A shard of the ClickHouse cluster.
	Shard []ShardObservation `json:"shard,omitempty" tf:"shard,omitempty"`

	// (Block List) A group of clickhouse shards. (see below for nested schema)
	// A group of clickhouse shards.
	ShardGroup []ShardGroupObservation `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// (String) Status of the cluster. Can be CREATING, STARTING, RUNNING, UPDATING, STOPPING, STOPPED, ERROR or STATUS_UNKNOWN. For more information see status field of JSON representation in the official documentation.
	// Status of the cluster. Can be `CREATING`, `STARTING`, `RUNNING`, `UPDATING`, `STOPPING`, `STOPPED`, `ERROR` or `STATUS_UNKNOWN`. For more information see `status` field of JSON representation in [the official documentation](https://yandex.cloud/docs/managed-clickhouse/api-ref/Cluster/).
	Status *string `json:"status,omitempty" tf:"status,omitempty"`

	// (Block Set, Deprecated) A user of the ClickHouse cluster. (see below for nested schema)
	// A user of the ClickHouse cluster.
	User []UserObservation `json:"user,omitempty" tf:"user,omitempty"`

	// (String) Version of the ClickHouse server software.
	// Version of the ClickHouse server software.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// (Block List, Max: 1) Configuration of the ZooKeeper subcluster. (see below for nested schema)
	// Configuration of the ZooKeeper subcluster.
	Zookeeper []ZookeeperObservation `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterParameters struct {

	// (Block List, Max: 1) Access policy to the ClickHouse cluster. (see below for nested schema)
	// Access policy to the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	Access []AccessParameters `json:"access,omitempty" tf:"access,omitempty"`

	// (String, Sensitive) A password used to authorize as user admin when sql_user_management enabled.
	// A password used to authorize as user `admin` when `sql_user_management` enabled.
	// +kubebuilder:validation:Optional
	AdminPasswordSecretRef *v1.SecretKeySelector `json:"adminPasswordSecretRef,omitempty" tf:"-"`

	// (Number) The period in days during which backups are stored.
	// The period in days during which backups are stored.
	// +kubebuilder:validation:Optional
	BackupRetainPeriodDays *float64 `json:"backupRetainPeriodDays,omitempty" tf:"backup_retain_period_days,omitempty"`

	// (Block List, Max: 1) Time to start the daily backup, in the UTC timezone. (see below for nested schema)
	// Time to start the daily backup, in the UTC timezone.
	// +kubebuilder:validation:Optional
	BackupWindowStart []BackupWindowStartParameters `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// (Block List, Max: 1) Configuration of the ClickHouse subcluster. (see below for nested schema)
	// Configuration of the ClickHouse subcluster.
	// +kubebuilder:validation:Optional
	Clickhouse []ClickhouseParameters `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// (Block List, Max: 1) Cloud Storage settings. (see below for nested schema)
	// Cloud Storage settings.
	// +kubebuilder:validation:Optional
	CloudStorage []CloudStorageParameters `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// (String) The cluster identifier.
	// The cluster identifier.
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Boolean) Whether to copy schema on new ClickHouse hosts.
	// Whether to copy schema on new ClickHouse hosts.
	// +kubebuilder:validation:Optional
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// (Block Set, Deprecated) A database of the ClickHouse cluster. (see below for nested schema)
	// A database of the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	Database []DatabaseParameters `json:"database,omitempty" tf:"database,omitempty"`

	// (Boolean) The true value means that resource is protected from accidental deletion.
	// The `true` value means that resource is protected from accidental deletion.
	// +kubebuilder:validation:Optional
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// (String) The resource description.
	// The resource description.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (Boolean) Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	// Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	// +kubebuilder:validation:Optional
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// (String) Deployment environment of the ClickHouse cluster. Can be either PRESTABLE or PRODUCTION.
	// Deployment environment of the ClickHouse cluster. Can be either `PRESTABLE` or `PRODUCTION`.
	// +kubebuilder:validation:Optional
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// id is used.
	// The folder identifier that resource belongs to. If it is not provided, the default provider `folder-id` is used.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/resourcemanager/v1alpha1.Folder
	// +kubebuilder:validation:Optional
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// Reference to a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDRef *v1.Reference `json:"folderIdRef,omitempty" tf:"-"`

	// Selector for a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDSelector *v1.Selector `json:"folderIdSelector,omitempty" tf:"-"`

	// (Block Set) A set of protobuf or capnproto format schemas. (see below for nested schema)
	// A set of `protobuf` or `capnproto` format schemas.
	// +kubebuilder:validation:Optional
	FormatSchema []FormatSchemaParameters `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// (Block List, Min: 1) A host of the ClickHouse cluster. (see below for nested schema)
	// A host of the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	Host []HostParameters `json:"host,omitempty" tf:"host,omitempty"`

	// (Map of String) A set of key/value label pairs which assigned to resource.
	// A set of key/value label pairs which assigned to resource.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// (Block Set) A group of machine learning models. (see below for nested schema)
	// A group of machine learning models.
	// +kubebuilder:validation:Optional
	MLModel []MLModelParameters `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	MaintenanceWindow []MaintenanceWindowParameters `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// (String) The resource name.
	// The resource name.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The VPC Network ID of subnets which resource attached to.
	// The `VPC Network ID` of subnets which resource attached to.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Network
	// +kubebuilder:validation:Optional
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Reference to a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDRef *v1.Reference `json:"networkIdRef,omitempty" tf:"-"`

	// Selector for a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDSelector *v1.Selector `json:"networkIdSelector,omitempty" tf:"-"`

	// (Boolean) Grants admin user database management permission.
	// Grants `admin` user database management permission.
	// +kubebuilder:validation:Optional
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// (Boolean) Enables admin user with user management permission.
	// Enables `admin` user with user management permission.
	// +kubebuilder:validation:Optional
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// (Set of String) The list of security groups applied to resource or their components.
	// The list of security groups applied to resource or their components.
	// +kubebuilder:validation:Optional
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// (String) Service account which linked to the resource.
	// [Service account](https://yandex.cloud/docs/iam/concepts/users/service-accounts) which linked to the resource.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/iam/v1alpha1.ServiceAccount
	// +kubebuilder:validation:Optional
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// Reference to a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDRef *v1.Reference `json:"serviceAccountIdRef,omitempty" tf:"-"`

	// Selector for a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDSelector *v1.Selector `json:"serviceAccountIdSelector,omitempty" tf:"-"`

	// (Block Set) A shard of the ClickHouse cluster. (see below for nested schema)
	// A shard of the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	Shard []ShardParameters `json:"shard,omitempty" tf:"shard,omitempty"`

	// (Block List) A group of clickhouse shards. (see below for nested schema)
	// A group of clickhouse shards.
	// +kubebuilder:validation:Optional
	ShardGroup []ShardGroupParameters `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// (Block Set, Deprecated) A user of the ClickHouse cluster. (see below for nested schema)
	// A user of the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	User []UserParameters `json:"user,omitempty" tf:"user,omitempty"`

	// (String) Version of the ClickHouse server software.
	// Version of the ClickHouse server software.
	// +kubebuilder:validation:Optional
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// (Block List, Max: 1) Configuration of the ZooKeeper subcluster. (see below for nested schema)
	// Configuration of the ZooKeeper subcluster.
	// +kubebuilder:validation:Optional
	Zookeeper []ZookeeperParameters `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseInitParameters struct {

	// (Block List, Max: 1) ClickHouse server parameters. For more information, see the official documentation. (see below for nested schema)
	// ClickHouse server parameters. For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/settings-list).
	Config []ConfigInitParameters `json:"config,omitempty" tf:"config,omitempty"`

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to hosts of the ClickHouse subcluster.
	Resources []ResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseObservation struct {

	// (Block List, Max: 1) ClickHouse server parameters. For more information, see the official documentation. (see below for nested schema)
	// ClickHouse server parameters. For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/settings-list).
	Config []ConfigObservation `json:"config,omitempty" tf:"config,omitempty"`

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to hosts of the ClickHouse subcluster.
	Resources []ResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseParameters struct {

	// (Block List, Max: 1) ClickHouse server parameters. For more information, see the official documentation. (see below for nested schema)
	// ClickHouse server parameters. For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/settings-list).
	// +kubebuilder:validation:Optional
	Config []ConfigParameters `json:"config,omitempty" tf:"config,omitempty"`

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to hosts of the ClickHouse subcluster.
	// +kubebuilder:validation:Optional
	Resources []ResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type CloudStorageInitParameters struct {

	// (Boolean) Enables temporary storage in the cluster repository of data requested from the object repository.
	// Enables temporary storage in the cluster repository of data requested from the object repository.
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// (Number) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// (Boolean) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (Number) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// (Boolean) Disables merging of data parts in Yandex Object Storage.
	// Disables merging of data parts in `Yandex Object Storage`.
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type CloudStorageObservation struct {

	// (Boolean) Enables temporary storage in the cluster repository of data requested from the object repository.
	// Enables temporary storage in the cluster repository of data requested from the object repository.
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// (Number) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// (Boolean) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (Number) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// (Boolean) Disables merging of data parts in Yandex Object Storage.
	// Disables merging of data parts in `Yandex Object Storage`.
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type CloudStorageParameters struct {

	// (Boolean) Enables temporary storage in the cluster repository of data requested from the object repository.
	// Enables temporary storage in the cluster repository of data requested from the object repository.
	// +kubebuilder:validation:Optional
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// (Number) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// +kubebuilder:validation:Optional
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// (Boolean) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`

	// (Number) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// +kubebuilder:validation:Optional
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// (Boolean) Disables merging of data parts in Yandex Object Storage.
	// Disables merging of data parts in `Yandex Object Storage`.
	// +kubebuilder:validation:Optional
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type CompressionInitParameters struct {

	// (Number) Compression level for ZSTD method.
	// Compression level for `ZSTD` method.
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// (String) Compression method. Two methods are available: LZ4 and zstd.
	// Compression method. Two methods are available: `LZ4` and `zstd`.
	Method *string `json:"method,omitempty" tf:"method,omitempty"`

	// (Number) Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	MinPartSize *float64 `json:"minPartSize,omitempty" tf:"min_part_size,omitempty"`

	// (Number) Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	MinPartSizeRatio *float64 `json:"minPartSizeRatio,omitempty" tf:"min_part_size_ratio,omitempty"`
}

type CompressionObservation struct {

	// (Number) Compression level for ZSTD method.
	// Compression level for `ZSTD` method.
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// (String) Compression method. Two methods are available: LZ4 and zstd.
	// Compression method. Two methods are available: `LZ4` and `zstd`.
	Method *string `json:"method,omitempty" tf:"method,omitempty"`

	// (Number) Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	MinPartSize *float64 `json:"minPartSize,omitempty" tf:"min_part_size,omitempty"`

	// (Number) Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	MinPartSizeRatio *float64 `json:"minPartSizeRatio,omitempty" tf:"min_part_size_ratio,omitempty"`
}

type CompressionParameters struct {

	// (Number) Compression level for ZSTD method.
	// Compression level for `ZSTD` method.
	// +kubebuilder:validation:Optional
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// (String) Compression method. Two methods are available: LZ4 and zstd.
	// Compression method. Two methods are available: `LZ4` and `zstd`.
	// +kubebuilder:validation:Optional
	Method *string `json:"method" tf:"method,omitempty"`

	// (Number) Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// +kubebuilder:validation:Optional
	MinPartSize *float64 `json:"minPartSize" tf:"min_part_size,omitempty"`

	// (Number) Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// +kubebuilder:validation:Optional
	MinPartSizeRatio *float64 `json:"minPartSizeRatio" tf:"min_part_size_ratio,omitempty"`
}

type ConfigInitParameters struct {

	// (Boolean) Enable or disable asynchronous_insert_log system table.
	// Enable or disable asynchronous_insert_log system table.
	AsynchronousInsertLogEnabled *bool `json:"asynchronousInsertLogEnabled,omitempty" tf:"asynchronous_insert_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	AsynchronousInsertLogRetentionSize *float64 `json:"asynchronousInsertLogRetentionSize,omitempty" tf:"asynchronous_insert_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_insert_log records will be retained before removal.
	// The maximum time that asynchronous_insert_log records will be retained before removal.
	AsynchronousInsertLogRetentionTime *float64 `json:"asynchronousInsertLogRetentionTime,omitempty" tf:"asynchronous_insert_log_retention_time,omitempty"`

	// (Boolean) Enable or disable asynchronous_metric_log system table.
	// Enable or disable asynchronous_metric_log system table.
	AsynchronousMetricLogEnabled *bool `json:"asynchronousMetricLogEnabled,omitempty" tf:"asynchronous_metric_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	AsynchronousMetricLogRetentionSize *float64 `json:"asynchronousMetricLogRetentionSize,omitempty" tf:"asynchronous_metric_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_metric_log records will be retained before removal.
	// The maximum time that asynchronous_metric_log records will be retained before removal.
	AsynchronousMetricLogRetentionTime *float64 `json:"asynchronousMetricLogRetentionTime,omitempty" tf:"asynchronous_metric_log_retention_time,omitempty"`

	// engine tables in the background.
	// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
	BackgroundBufferFlushSchedulePoolSize *float64 `json:"backgroundBufferFlushSchedulePoolSize,omitempty" tf:"background_buffer_flush_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
	BackgroundCommonPoolSize *float64 `json:"backgroundCommonPoolSize,omitempty" tf:"background_common_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for executing distributed sends.
	// The maximum number of threads that will be used for executing distributed sends.
	BackgroundDistributedSchedulePoolSize *float64 `json:"backgroundDistributedSchedulePoolSize,omitempty" tf:"background_distributed_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// (Number) Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// (Number) The maximum number of threads that will be used for executing background operations for message streaming.
	// The maximum number of threads that will be used for executing background operations for message streaming.
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
	BackgroundMovePoolSize *float64 `json:"backgroundMovePoolSize,omitempty" tf:"background_move_pool_size,omitempty"`

	// engine tables.
	// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// (Block List) Data compression configuration. (see below for nested schema)
	// Data compression configuration.
	Compression []CompressionInitParameters `json:"compression,omitempty" tf:"compression,omitempty"`

	// (String) Default database name.
	// Default database name.
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// (Boolean) Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	DictionariesLazyLoad *bool `json:"dictionariesLazyLoad,omitempty" tf:"dictionaries_lazy_load,omitempty"`

	// (Boolean) Enable or disable geobase.
	// Enable or disable geobase.
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// (String) Address of the archive with the user geobase in Object Storage.
	// Address of the archive with the user geobase in Object Storage.
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// (Block List) Graphite rollup configuration. (see below for nested schema)
	// Graphite rollup configuration.
	GraphiteRollup []GraphiteRollupInitParameters `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// (Block List, Max: 1) JDBC bridge configuration. (see below for nested schema)
	// JDBC bridge configuration.
	JdbcBridge []JdbcBridgeInitParameters `json:"jdbcBridge,omitempty" tf:"jdbc_bridge,omitempty"`

	// (Block List, Max: 1) Kafka connection configuration. (see below for nested schema)
	// Kafka connection configuration.
	Kafka []KafkaInitParameters `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// (Block List) Kafka topic connection configuration. (see below for nested schema)
	// Kafka topic connection configuration.
	KafkaTopic []KafkaTopicInitParameters `json:"kafkaTopic,omitempty" tf:"kafka_topic,omitempty"`

	// (Number) The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// (String) Logging level.
	// Logging level.
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// (Number) Maximum size of cache for marks
	// Maximum size of cache for marks
	MarkCacheSize *float64 `json:"markCacheSize,omitempty" tf:"mark_cache_size,omitempty"`

	// (Number) Limit on total number of concurrently executed queries.
	// Limit on total number of concurrently executed queries.
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// (Number) Max server connections.
	// Max server connections.
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// (Number) Restriction on dropping partitions.
	// Restriction on dropping partitions.
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// (Number) Restriction on deleting tables.
	// Restriction on deleting tables.
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// (Block List, Max: 1) MergeTree engine configuration. (see below for nested schema)
	// MergeTree engine configuration.
	MergeTree []MergeTreeInitParameters `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// (Boolean) Enable or disable metric_log system table.
	// Enable or disable metric_log system table.
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// (Number) The maximum size that metric_log can grow to before old data will be removed.
	// The maximum size that metric_log can grow to before old data will be removed.
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// (Number) The maximum time that metric_log records will be retained before removal.
	// The maximum time that metric_log records will be retained before removal.
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// (Boolean) Enable or disable opentelemetry_span_log system table.
	// Enable or disable opentelemetry_span_log system table.
	OpentelemetrySpanLogEnabled *bool `json:"opentelemetrySpanLogEnabled,omitempty" tf:"opentelemetry_span_log_enabled,omitempty"`

	// (Number) The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	OpentelemetrySpanLogRetentionSize *float64 `json:"opentelemetrySpanLogRetentionSize,omitempty" tf:"opentelemetry_span_log_retention_size,omitempty"`

	// (Number) The maximum time that opentelemetry_span_log records will be retained before removal.
	// The maximum time that opentelemetry_span_log records will be retained before removal.
	OpentelemetrySpanLogRetentionTime *float64 `json:"opentelemetrySpanLogRetentionTime,omitempty" tf:"opentelemetry_span_log_retention_time,omitempty"`

	// (Number) The maximum size that part_log can grow to before old data will be removed.
	// The maximum size that part_log can grow to before old data will be removed.
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// (Number) The maximum time that part_log records will be retained before removal.
	// The maximum time that part_log records will be retained before removal.
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// (Block List, Max: 1) Query cache configuration. (see below for nested schema)
	// Query cache configuration.
	QueryCache []QueryCacheInitParameters `json:"queryCache,omitempty" tf:"query_cache,omitempty"`

	// (Number) The maximum size that query_log can grow to before old data will be removed.
	// The maximum size that query_log can grow to before old data will be removed.
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// (Number) The maximum time that query_log records will be retained before removal.
	// The maximum time that query_log records will be retained before removal.
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// (Block List) Query masking rules configuration. (see below for nested schema)
	// Query masking rules configuration.
	QueryMaskingRules []QueryMaskingRulesInitParameters `json:"queryMaskingRules,omitempty" tf:"query_masking_rules,omitempty"`

	// (Boolean) Enable or disable query_thread_log system table.
	// Enable or disable query_thread_log system table.
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// (Number) The maximum size that query_thread_log can grow to before old data will be removed.
	// The maximum size that query_thread_log can grow to before old data will be removed.
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// (Number) The maximum time that query_thread_log records will be retained before removal.
	// The maximum time that query_thread_log records will be retained before removal.
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// (Boolean) Enable or disable query_views_log system table.
	// Enable or disable query_views_log system table.
	QueryViewsLogEnabled *bool `json:"queryViewsLogEnabled,omitempty" tf:"query_views_log_enabled,omitempty"`

	// (Number) The maximum size that query_views_log can grow to before old data will be removed.
	// The maximum size that query_views_log can grow to before old data will be removed.
	QueryViewsLogRetentionSize *float64 `json:"queryViewsLogRetentionSize,omitempty" tf:"query_views_log_retention_size,omitempty"`

	// (Number) The maximum time that query_views_log records will be retained before removal.
	// The maximum time that query_views_log records will be retained before removal.
	QueryViewsLogRetentionTime *float64 `json:"queryViewsLogRetentionTime,omitempty" tf:"query_views_log_retention_time,omitempty"`

	// (Block List, Max: 1) RabbitMQ connection configuration. (see below for nested schema)
	// RabbitMQ connection configuration.
	Rabbitmq []RabbitmqInitParameters `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// (Boolean) Enable or disable session_log system table.
	// Enable or disable session_log system table.
	SessionLogEnabled *bool `json:"sessionLogEnabled,omitempty" tf:"session_log_enabled,omitempty"`

	// (Number) The maximum size that session_log can grow to before old data will be removed.
	// The maximum size that session_log can grow to before old data will be removed.
	SessionLogRetentionSize *float64 `json:"sessionLogRetentionSize,omitempty" tf:"session_log_retention_size,omitempty"`

	// (Number) The maximum time that session_log records will be retained before removal.
	// The maximum time that session_log records will be retained before removal.
	SessionLogRetentionTime *float64 `json:"sessionLogRetentionTime,omitempty" tf:"session_log_retention_time,omitempty"`

	// (Boolean) Enable or disable text_log system table.
	// Enable or disable text_log system table.
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// (String) Logging level for text_log system table.
	// Logging level for text_log system table.
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// (Number) The maximum size that text_log can grow to before old data will be removed.
	// The maximum size that text_log can grow to before old data will be removed.
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// (Number) The maximum time that text_log records will be retained before removal.
	// The maximum time that text_log records will be retained before removal.
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// (String) The server's time zone.
	// The server's time zone.
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (Number) Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// (Boolean) Enable or disable trace_log system table.
	// Enable or disable trace_log system table.
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// (Number) The maximum size that trace_log can grow to before old data will be removed.
	// The maximum size that trace_log can grow to before old data will be removed.
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// (Number) The maximum time that trace_log records will be retained before removal.
	// The maximum time that trace_log records will be retained before removal.
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// (Number) Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`

	// (Boolean) Enable or disable zookeeper_log system table.
	// Enable or disable zookeeper_log system table.
	ZookeeperLogEnabled *bool `json:"zookeeperLogEnabled,omitempty" tf:"zookeeper_log_enabled,omitempty"`

	// (Number) The maximum size that zookeeper_log can grow to before old data will be removed.
	// The maximum size that zookeeper_log can grow to before old data will be removed.
	ZookeeperLogRetentionSize *float64 `json:"zookeeperLogRetentionSize,omitempty" tf:"zookeeper_log_retention_size,omitempty"`

	// (Number) The maximum time that zookeeper_log records will be retained before removal.
	// The maximum time that zookeeper_log records will be retained before removal.
	ZookeeperLogRetentionTime *float64 `json:"zookeeperLogRetentionTime,omitempty" tf:"zookeeper_log_retention_time,omitempty"`
}

type ConfigObservation struct {

	// (Boolean) Enable or disable asynchronous_insert_log system table.
	// Enable or disable asynchronous_insert_log system table.
	AsynchronousInsertLogEnabled *bool `json:"asynchronousInsertLogEnabled,omitempty" tf:"asynchronous_insert_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	AsynchronousInsertLogRetentionSize *float64 `json:"asynchronousInsertLogRetentionSize,omitempty" tf:"asynchronous_insert_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_insert_log records will be retained before removal.
	// The maximum time that asynchronous_insert_log records will be retained before removal.
	AsynchronousInsertLogRetentionTime *float64 `json:"asynchronousInsertLogRetentionTime,omitempty" tf:"asynchronous_insert_log_retention_time,omitempty"`

	// (Boolean) Enable or disable asynchronous_metric_log system table.
	// Enable or disable asynchronous_metric_log system table.
	AsynchronousMetricLogEnabled *bool `json:"asynchronousMetricLogEnabled,omitempty" tf:"asynchronous_metric_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	AsynchronousMetricLogRetentionSize *float64 `json:"asynchronousMetricLogRetentionSize,omitempty" tf:"asynchronous_metric_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_metric_log records will be retained before removal.
	// The maximum time that asynchronous_metric_log records will be retained before removal.
	AsynchronousMetricLogRetentionTime *float64 `json:"asynchronousMetricLogRetentionTime,omitempty" tf:"asynchronous_metric_log_retention_time,omitempty"`

	// engine tables in the background.
	// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
	BackgroundBufferFlushSchedulePoolSize *float64 `json:"backgroundBufferFlushSchedulePoolSize,omitempty" tf:"background_buffer_flush_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
	BackgroundCommonPoolSize *float64 `json:"backgroundCommonPoolSize,omitempty" tf:"background_common_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for executing distributed sends.
	// The maximum number of threads that will be used for executing distributed sends.
	BackgroundDistributedSchedulePoolSize *float64 `json:"backgroundDistributedSchedulePoolSize,omitempty" tf:"background_distributed_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// (Number) Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// (Number) The maximum number of threads that will be used for executing background operations for message streaming.
	// The maximum number of threads that will be used for executing background operations for message streaming.
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
	BackgroundMovePoolSize *float64 `json:"backgroundMovePoolSize,omitempty" tf:"background_move_pool_size,omitempty"`

	// engine tables.
	// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// (Block List) Data compression configuration. (see below for nested schema)
	// Data compression configuration.
	Compression []CompressionObservation `json:"compression,omitempty" tf:"compression,omitempty"`

	// (String) Default database name.
	// Default database name.
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// (Boolean) Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	DictionariesLazyLoad *bool `json:"dictionariesLazyLoad,omitempty" tf:"dictionaries_lazy_load,omitempty"`

	// (Boolean) Enable or disable geobase.
	// Enable or disable geobase.
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// (String) Address of the archive with the user geobase in Object Storage.
	// Address of the archive with the user geobase in Object Storage.
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// (Block List) Graphite rollup configuration. (see below for nested schema)
	// Graphite rollup configuration.
	GraphiteRollup []GraphiteRollupObservation `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// (Block List, Max: 1) JDBC bridge configuration. (see below for nested schema)
	// JDBC bridge configuration.
	JdbcBridge []JdbcBridgeObservation `json:"jdbcBridge,omitempty" tf:"jdbc_bridge,omitempty"`

	// (Block List, Max: 1) Kafka connection configuration. (see below for nested schema)
	// Kafka connection configuration.
	Kafka []KafkaObservation `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// (Block List) Kafka topic connection configuration. (see below for nested schema)
	// Kafka topic connection configuration.
	KafkaTopic []KafkaTopicObservation `json:"kafkaTopic,omitempty" tf:"kafka_topic,omitempty"`

	// (Number) The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// (String) Logging level.
	// Logging level.
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// (Number) Maximum size of cache for marks
	// Maximum size of cache for marks
	MarkCacheSize *float64 `json:"markCacheSize,omitempty" tf:"mark_cache_size,omitempty"`

	// (Number) Limit on total number of concurrently executed queries.
	// Limit on total number of concurrently executed queries.
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// (Number) Max server connections.
	// Max server connections.
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// (Number) Restriction on dropping partitions.
	// Restriction on dropping partitions.
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// (Number) Restriction on deleting tables.
	// Restriction on deleting tables.
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// (Block List, Max: 1) MergeTree engine configuration. (see below for nested schema)
	// MergeTree engine configuration.
	MergeTree []MergeTreeObservation `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// (Boolean) Enable or disable metric_log system table.
	// Enable or disable metric_log system table.
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// (Number) The maximum size that metric_log can grow to before old data will be removed.
	// The maximum size that metric_log can grow to before old data will be removed.
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// (Number) The maximum time that metric_log records will be retained before removal.
	// The maximum time that metric_log records will be retained before removal.
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// (Boolean) Enable or disable opentelemetry_span_log system table.
	// Enable or disable opentelemetry_span_log system table.
	OpentelemetrySpanLogEnabled *bool `json:"opentelemetrySpanLogEnabled,omitempty" tf:"opentelemetry_span_log_enabled,omitempty"`

	// (Number) The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	OpentelemetrySpanLogRetentionSize *float64 `json:"opentelemetrySpanLogRetentionSize,omitempty" tf:"opentelemetry_span_log_retention_size,omitempty"`

	// (Number) The maximum time that opentelemetry_span_log records will be retained before removal.
	// The maximum time that opentelemetry_span_log records will be retained before removal.
	OpentelemetrySpanLogRetentionTime *float64 `json:"opentelemetrySpanLogRetentionTime,omitempty" tf:"opentelemetry_span_log_retention_time,omitempty"`

	// (Number) The maximum size that part_log can grow to before old data will be removed.
	// The maximum size that part_log can grow to before old data will be removed.
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// (Number) The maximum time that part_log records will be retained before removal.
	// The maximum time that part_log records will be retained before removal.
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// (Block List, Max: 1) Query cache configuration. (see below for nested schema)
	// Query cache configuration.
	QueryCache []QueryCacheObservation `json:"queryCache,omitempty" tf:"query_cache,omitempty"`

	// (Number) The maximum size that query_log can grow to before old data will be removed.
	// The maximum size that query_log can grow to before old data will be removed.
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// (Number) The maximum time that query_log records will be retained before removal.
	// The maximum time that query_log records will be retained before removal.
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// (Block List) Query masking rules configuration. (see below for nested schema)
	// Query masking rules configuration.
	QueryMaskingRules []QueryMaskingRulesObservation `json:"queryMaskingRules,omitempty" tf:"query_masking_rules,omitempty"`

	// (Boolean) Enable or disable query_thread_log system table.
	// Enable or disable query_thread_log system table.
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// (Number) The maximum size that query_thread_log can grow to before old data will be removed.
	// The maximum size that query_thread_log can grow to before old data will be removed.
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// (Number) The maximum time that query_thread_log records will be retained before removal.
	// The maximum time that query_thread_log records will be retained before removal.
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// (Boolean) Enable or disable query_views_log system table.
	// Enable or disable query_views_log system table.
	QueryViewsLogEnabled *bool `json:"queryViewsLogEnabled,omitempty" tf:"query_views_log_enabled,omitempty"`

	// (Number) The maximum size that query_views_log can grow to before old data will be removed.
	// The maximum size that query_views_log can grow to before old data will be removed.
	QueryViewsLogRetentionSize *float64 `json:"queryViewsLogRetentionSize,omitempty" tf:"query_views_log_retention_size,omitempty"`

	// (Number) The maximum time that query_views_log records will be retained before removal.
	// The maximum time that query_views_log records will be retained before removal.
	QueryViewsLogRetentionTime *float64 `json:"queryViewsLogRetentionTime,omitempty" tf:"query_views_log_retention_time,omitempty"`

	// (Block List, Max: 1) RabbitMQ connection configuration. (see below for nested schema)
	// RabbitMQ connection configuration.
	Rabbitmq []RabbitmqObservation `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// (Boolean) Enable or disable session_log system table.
	// Enable or disable session_log system table.
	SessionLogEnabled *bool `json:"sessionLogEnabled,omitempty" tf:"session_log_enabled,omitempty"`

	// (Number) The maximum size that session_log can grow to before old data will be removed.
	// The maximum size that session_log can grow to before old data will be removed.
	SessionLogRetentionSize *float64 `json:"sessionLogRetentionSize,omitempty" tf:"session_log_retention_size,omitempty"`

	// (Number) The maximum time that session_log records will be retained before removal.
	// The maximum time that session_log records will be retained before removal.
	SessionLogRetentionTime *float64 `json:"sessionLogRetentionTime,omitempty" tf:"session_log_retention_time,omitempty"`

	// (Boolean) Enable or disable text_log system table.
	// Enable or disable text_log system table.
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// (String) Logging level for text_log system table.
	// Logging level for text_log system table.
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// (Number) The maximum size that text_log can grow to before old data will be removed.
	// The maximum size that text_log can grow to before old data will be removed.
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// (Number) The maximum time that text_log records will be retained before removal.
	// The maximum time that text_log records will be retained before removal.
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// (String) The server's time zone.
	// The server's time zone.
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (Number) Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// (Boolean) Enable or disable trace_log system table.
	// Enable or disable trace_log system table.
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// (Number) The maximum size that trace_log can grow to before old data will be removed.
	// The maximum size that trace_log can grow to before old data will be removed.
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// (Number) The maximum time that trace_log records will be retained before removal.
	// The maximum time that trace_log records will be retained before removal.
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// (Number) Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`

	// (Boolean) Enable or disable zookeeper_log system table.
	// Enable or disable zookeeper_log system table.
	ZookeeperLogEnabled *bool `json:"zookeeperLogEnabled,omitempty" tf:"zookeeper_log_enabled,omitempty"`

	// (Number) The maximum size that zookeeper_log can grow to before old data will be removed.
	// The maximum size that zookeeper_log can grow to before old data will be removed.
	ZookeeperLogRetentionSize *float64 `json:"zookeeperLogRetentionSize,omitempty" tf:"zookeeper_log_retention_size,omitempty"`

	// (Number) The maximum time that zookeeper_log records will be retained before removal.
	// The maximum time that zookeeper_log records will be retained before removal.
	ZookeeperLogRetentionTime *float64 `json:"zookeeperLogRetentionTime,omitempty" tf:"zookeeper_log_retention_time,omitempty"`
}

type ConfigParameters struct {

	// (Boolean) Enable or disable asynchronous_insert_log system table.
	// Enable or disable asynchronous_insert_log system table.
	// +kubebuilder:validation:Optional
	AsynchronousInsertLogEnabled *bool `json:"asynchronousInsertLogEnabled,omitempty" tf:"asynchronous_insert_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	AsynchronousInsertLogRetentionSize *float64 `json:"asynchronousInsertLogRetentionSize,omitempty" tf:"asynchronous_insert_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_insert_log records will be retained before removal.
	// The maximum time that asynchronous_insert_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	AsynchronousInsertLogRetentionTime *float64 `json:"asynchronousInsertLogRetentionTime,omitempty" tf:"asynchronous_insert_log_retention_time,omitempty"`

	// (Boolean) Enable or disable asynchronous_metric_log system table.
	// Enable or disable asynchronous_metric_log system table.
	// +kubebuilder:validation:Optional
	AsynchronousMetricLogEnabled *bool `json:"asynchronousMetricLogEnabled,omitempty" tf:"asynchronous_metric_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	AsynchronousMetricLogRetentionSize *float64 `json:"asynchronousMetricLogRetentionSize,omitempty" tf:"asynchronous_metric_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_metric_log records will be retained before removal.
	// The maximum time that asynchronous_metric_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	AsynchronousMetricLogRetentionTime *float64 `json:"asynchronousMetricLogRetentionTime,omitempty" tf:"asynchronous_metric_log_retention_time,omitempty"`

	// engine tables in the background.
	// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
	// +kubebuilder:validation:Optional
	BackgroundBufferFlushSchedulePoolSize *float64 `json:"backgroundBufferFlushSchedulePoolSize,omitempty" tf:"background_buffer_flush_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
	// +kubebuilder:validation:Optional
	BackgroundCommonPoolSize *float64 `json:"backgroundCommonPoolSize,omitempty" tf:"background_common_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for executing distributed sends.
	// The maximum number of threads that will be used for executing distributed sends.
	// +kubebuilder:validation:Optional
	BackgroundDistributedSchedulePoolSize *float64 `json:"backgroundDistributedSchedulePoolSize,omitempty" tf:"background_distributed_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
	// +kubebuilder:validation:Optional
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// (Number) Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// +kubebuilder:validation:Optional
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// (Number) The maximum number of threads that will be used for executing background operations for message streaming.
	// The maximum number of threads that will be used for executing background operations for message streaming.
	// +kubebuilder:validation:Optional
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
	// +kubebuilder:validation:Optional
	BackgroundMovePoolSize *float64 `json:"backgroundMovePoolSize,omitempty" tf:"background_move_pool_size,omitempty"`

	// engine tables.
	// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
	// +kubebuilder:validation:Optional
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// +kubebuilder:validation:Optional
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// (Block List) Data compression configuration. (see below for nested schema)
	// Data compression configuration.
	// +kubebuilder:validation:Optional
	Compression []CompressionParameters `json:"compression,omitempty" tf:"compression,omitempty"`

	// (String) Default database name.
	// Default database name.
	// +kubebuilder:validation:Optional
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// (Boolean) Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// +kubebuilder:validation:Optional
	DictionariesLazyLoad *bool `json:"dictionariesLazyLoad,omitempty" tf:"dictionaries_lazy_load,omitempty"`

	// (Boolean) Enable or disable geobase.
	// Enable or disable geobase.
	// +kubebuilder:validation:Optional
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// (String) Address of the archive with the user geobase in Object Storage.
	// Address of the archive with the user geobase in Object Storage.
	// +kubebuilder:validation:Optional
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// (Block List) Graphite rollup configuration. (see below for nested schema)
	// Graphite rollup configuration.
	// +kubebuilder:validation:Optional
	GraphiteRollup []GraphiteRollupParameters `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// (Block List, Max: 1) JDBC bridge configuration. (see below for nested schema)
	// JDBC bridge configuration.
	// +kubebuilder:validation:Optional
	JdbcBridge []JdbcBridgeParameters `json:"jdbcBridge,omitempty" tf:"jdbc_bridge,omitempty"`

	// (Block List, Max: 1) Kafka connection configuration. (see below for nested schema)
	// Kafka connection configuration.
	// +kubebuilder:validation:Optional
	Kafka []KafkaParameters `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// (Block List) Kafka topic connection configuration. (see below for nested schema)
	// Kafka topic connection configuration.
	// +kubebuilder:validation:Optional
	KafkaTopic []KafkaTopicParameters `json:"kafkaTopic,omitempty" tf:"kafka_topic,omitempty"`

	// (Number) The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// +kubebuilder:validation:Optional
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// (String) Logging level.
	// Logging level.
	// +kubebuilder:validation:Optional
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// (Number) Maximum size of cache for marks
	// Maximum size of cache for marks
	// +kubebuilder:validation:Optional
	MarkCacheSize *float64 `json:"markCacheSize,omitempty" tf:"mark_cache_size,omitempty"`

	// (Number) Limit on total number of concurrently executed queries.
	// Limit on total number of concurrently executed queries.
	// +kubebuilder:validation:Optional
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// (Number) Max server connections.
	// Max server connections.
	// +kubebuilder:validation:Optional
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// (Number) Restriction on dropping partitions.
	// Restriction on dropping partitions.
	// +kubebuilder:validation:Optional
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// (Number) Restriction on deleting tables.
	// Restriction on deleting tables.
	// +kubebuilder:validation:Optional
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// (Block List, Max: 1) MergeTree engine configuration. (see below for nested schema)
	// MergeTree engine configuration.
	// +kubebuilder:validation:Optional
	MergeTree []MergeTreeParameters `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// (Boolean) Enable or disable metric_log system table.
	// Enable or disable metric_log system table.
	// +kubebuilder:validation:Optional
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// (Number) The maximum size that metric_log can grow to before old data will be removed.
	// The maximum size that metric_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// (Number) The maximum time that metric_log records will be retained before removal.
	// The maximum time that metric_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// (Boolean) Enable or disable opentelemetry_span_log system table.
	// Enable or disable opentelemetry_span_log system table.
	// +kubebuilder:validation:Optional
	OpentelemetrySpanLogEnabled *bool `json:"opentelemetrySpanLogEnabled,omitempty" tf:"opentelemetry_span_log_enabled,omitempty"`

	// (Number) The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	OpentelemetrySpanLogRetentionSize *float64 `json:"opentelemetrySpanLogRetentionSize,omitempty" tf:"opentelemetry_span_log_retention_size,omitempty"`

	// (Number) The maximum time that opentelemetry_span_log records will be retained before removal.
	// The maximum time that opentelemetry_span_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	OpentelemetrySpanLogRetentionTime *float64 `json:"opentelemetrySpanLogRetentionTime,omitempty" tf:"opentelemetry_span_log_retention_time,omitempty"`

	// (Number) The maximum size that part_log can grow to before old data will be removed.
	// The maximum size that part_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// (Number) The maximum time that part_log records will be retained before removal.
	// The maximum time that part_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// (Block List, Max: 1) Query cache configuration. (see below for nested schema)
	// Query cache configuration.
	// +kubebuilder:validation:Optional
	QueryCache []QueryCacheParameters `json:"queryCache,omitempty" tf:"query_cache,omitempty"`

	// (Number) The maximum size that query_log can grow to before old data will be removed.
	// The maximum size that query_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// (Number) The maximum time that query_log records will be retained before removal.
	// The maximum time that query_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// (Block List) Query masking rules configuration. (see below for nested schema)
	// Query masking rules configuration.
	// +kubebuilder:validation:Optional
	QueryMaskingRules []QueryMaskingRulesParameters `json:"queryMaskingRules,omitempty" tf:"query_masking_rules,omitempty"`

	// (Boolean) Enable or disable query_thread_log system table.
	// Enable or disable query_thread_log system table.
	// +kubebuilder:validation:Optional
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// (Number) The maximum size that query_thread_log can grow to before old data will be removed.
	// The maximum size that query_thread_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// (Number) The maximum time that query_thread_log records will be retained before removal.
	// The maximum time that query_thread_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// (Boolean) Enable or disable query_views_log system table.
	// Enable or disable query_views_log system table.
	// +kubebuilder:validation:Optional
	QueryViewsLogEnabled *bool `json:"queryViewsLogEnabled,omitempty" tf:"query_views_log_enabled,omitempty"`

	// (Number) The maximum size that query_views_log can grow to before old data will be removed.
	// The maximum size that query_views_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	QueryViewsLogRetentionSize *float64 `json:"queryViewsLogRetentionSize,omitempty" tf:"query_views_log_retention_size,omitempty"`

	// (Number) The maximum time that query_views_log records will be retained before removal.
	// The maximum time that query_views_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	QueryViewsLogRetentionTime *float64 `json:"queryViewsLogRetentionTime,omitempty" tf:"query_views_log_retention_time,omitempty"`

	// (Block List, Max: 1) RabbitMQ connection configuration. (see below for nested schema)
	// RabbitMQ connection configuration.
	// +kubebuilder:validation:Optional
	Rabbitmq []RabbitmqParameters `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// (Boolean) Enable or disable session_log system table.
	// Enable or disable session_log system table.
	// +kubebuilder:validation:Optional
	SessionLogEnabled *bool `json:"sessionLogEnabled,omitempty" tf:"session_log_enabled,omitempty"`

	// (Number) The maximum size that session_log can grow to before old data will be removed.
	// The maximum size that session_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	SessionLogRetentionSize *float64 `json:"sessionLogRetentionSize,omitempty" tf:"session_log_retention_size,omitempty"`

	// (Number) The maximum time that session_log records will be retained before removal.
	// The maximum time that session_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	SessionLogRetentionTime *float64 `json:"sessionLogRetentionTime,omitempty" tf:"session_log_retention_time,omitempty"`

	// (Boolean) Enable or disable text_log system table.
	// Enable or disable text_log system table.
	// +kubebuilder:validation:Optional
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// (String) Logging level for text_log system table.
	// Logging level for text_log system table.
	// +kubebuilder:validation:Optional
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// (Number) The maximum size that text_log can grow to before old data will be removed.
	// The maximum size that text_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// (Number) The maximum time that text_log records will be retained before removal.
	// The maximum time that text_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// (String) The server's time zone.
	// The server's time zone.
	// +kubebuilder:validation:Optional
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (Number) Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// +kubebuilder:validation:Optional
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// (Boolean) Enable or disable trace_log system table.
	// Enable or disable trace_log system table.
	// +kubebuilder:validation:Optional
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// (Number) The maximum size that trace_log can grow to before old data will be removed.
	// The maximum size that trace_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// (Number) The maximum time that trace_log records will be retained before removal.
	// The maximum time that trace_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// (Number) Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// +kubebuilder:validation:Optional
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`

	// (Boolean) Enable or disable zookeeper_log system table.
	// Enable or disable zookeeper_log system table.
	// +kubebuilder:validation:Optional
	ZookeeperLogEnabled *bool `json:"zookeeperLogEnabled,omitempty" tf:"zookeeper_log_enabled,omitempty"`

	// (Number) The maximum size that zookeeper_log can grow to before old data will be removed.
	// The maximum size that zookeeper_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	ZookeeperLogRetentionSize *float64 `json:"zookeeperLogRetentionSize,omitempty" tf:"zookeeper_log_retention_size,omitempty"`

	// (Number) The maximum time that zookeeper_log records will be retained before removal.
	// The maximum time that zookeeper_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	ZookeeperLogRetentionTime *float64 `json:"zookeeperLogRetentionTime,omitempty" tf:"zookeeper_log_retention_time,omitempty"`
}

type DatabaseInitParameters struct {

	// (String) The resource name.
	// The name of the database.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type DatabaseObservation struct {

	// (String) The resource name.
	// The name of the database.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type DatabaseParameters struct {

	// (String) The resource name.
	// The name of the database.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`
}

type FormatSchemaInitParameters struct {

	// (String) The resource name.
	// The name of the format schema.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the format schema.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type FormatSchemaObservation struct {

	// (String) The resource name.
	// The name of the format schema.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the format schema.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type FormatSchemaParameters struct {

	// (String) The resource name.
	// The name of the format schema.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the format schema.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	URI *string `json:"uri" tf:"uri,omitempty"`
}

type GraphiteRollupInitParameters struct {

	// (String) The resource name.
	// Graphite rollup configuration name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// The name of the column storing the metric name (Graphite sensor). Default value: Path.
	PathColumnName *string `json:"pathColumnName,omitempty" tf:"path_column_name,omitempty"`

	// (Block List) Set of thinning rules. (see below for nested schema)
	// Set of thinning rules.
	Pattern []PatternInitParameters `json:"pattern,omitempty" tf:"pattern,omitempty"`

	// (String) The name of the column storing the time of measuring the metric. Default value: Time.
	// The name of the column storing the time of measuring the metric. Default value: Time.
	TimeColumnName *string `json:"timeColumnName,omitempty" tf:"time_column_name,omitempty"`

	// (String) The name of the column storing the value of the metric at the time set in time_column_name. Default value: Value.
	// The name of the column storing the value of the metric at the time set in `time_column_name`. Default value: Value.
	ValueColumnName *string `json:"valueColumnName,omitempty" tf:"value_column_name,omitempty"`

	// (String) The name of the column storing the version of the metric. Default value: Timestamp.
	// The name of the column storing the version of the metric. Default value: Timestamp.
	VersionColumnName *string `json:"versionColumnName,omitempty" tf:"version_column_name,omitempty"`
}

type GraphiteRollupObservation struct {

	// (String) The resource name.
	// Graphite rollup configuration name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// The name of the column storing the metric name (Graphite sensor). Default value: Path.
	PathColumnName *string `json:"pathColumnName,omitempty" tf:"path_column_name,omitempty"`

	// (Block List) Set of thinning rules. (see below for nested schema)
	// Set of thinning rules.
	Pattern []PatternObservation `json:"pattern,omitempty" tf:"pattern,omitempty"`

	// (String) The name of the column storing the time of measuring the metric. Default value: Time.
	// The name of the column storing the time of measuring the metric. Default value: Time.
	TimeColumnName *string `json:"timeColumnName,omitempty" tf:"time_column_name,omitempty"`

	// (String) The name of the column storing the value of the metric at the time set in time_column_name. Default value: Value.
	// The name of the column storing the value of the metric at the time set in `time_column_name`. Default value: Value.
	ValueColumnName *string `json:"valueColumnName,omitempty" tf:"value_column_name,omitempty"`

	// (String) The name of the column storing the version of the metric. Default value: Timestamp.
	// The name of the column storing the version of the metric. Default value: Timestamp.
	VersionColumnName *string `json:"versionColumnName,omitempty" tf:"version_column_name,omitempty"`
}

type GraphiteRollupParameters struct {

	// (String) The resource name.
	// Graphite rollup configuration name.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// +kubebuilder:validation:Optional
	PathColumnName *string `json:"pathColumnName,omitempty" tf:"path_column_name,omitempty"`

	// (Block List) Set of thinning rules. (see below for nested schema)
	// Set of thinning rules.
	// +kubebuilder:validation:Optional
	Pattern []PatternParameters `json:"pattern,omitempty" tf:"pattern,omitempty"`

	// (String) The name of the column storing the time of measuring the metric. Default value: Time.
	// The name of the column storing the time of measuring the metric. Default value: Time.
	// +kubebuilder:validation:Optional
	TimeColumnName *string `json:"timeColumnName,omitempty" tf:"time_column_name,omitempty"`

	// (String) The name of the column storing the value of the metric at the time set in time_column_name. Default value: Value.
	// The name of the column storing the value of the metric at the time set in `time_column_name`. Default value: Value.
	// +kubebuilder:validation:Optional
	ValueColumnName *string `json:"valueColumnName,omitempty" tf:"value_column_name,omitempty"`

	// (String) The name of the column storing the version of the metric. Default value: Timestamp.
	// The name of the column storing the version of the metric. Default value: Timestamp.
	// +kubebuilder:validation:Optional
	VersionColumnName *string `json:"versionColumnName,omitempty" tf:"version_column_name,omitempty"`
}

type HostInitParameters struct {

	// (Boolean) Sets whether the host should get a public IP address on creation. Can be either true or false.
	// Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (String) The name of the shard to which the host belongs.
	// The name of the shard to which the host belongs.
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// (String) The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Subnet
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// Reference to a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDRef *v1.Reference `json:"subnetIdRef,omitempty" tf:"-"`

	// Selector for a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDSelector *v1.Selector `json:"subnetIdSelector,omitempty" tf:"-"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// The type of the host to be deployed. Can be either `CLICKHOUSE` or `ZOOKEEPER`.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) The availability zone where resource is located. If it is not provided, the default provider zone will be used.
	// The [availability zone](https://yandex.cloud/docs/overview/concepts/geo-scope) where resource is located. If it is not provided, the default provider zone will be used.
	Zone *string `json:"zone,omitempty" tf:"zone,omitempty"`
}

type HostObservation struct {

	// (Boolean) Sets whether the host should get a public IP address on creation. Can be either true or false.
	// Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (String) The fully qualified domain name of the host.
	// The fully qualified domain name of the host.
	Fqdn *string `json:"fqdn,omitempty" tf:"fqdn,omitempty"`

	// (String) The name of the shard to which the host belongs.
	// The name of the shard to which the host belongs.
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// (String) The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// The type of the host to be deployed. Can be either `CLICKHOUSE` or `ZOOKEEPER`.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) The availability zone where resource is located. If it is not provided, the default provider zone will be used.
	// The [availability zone](https://yandex.cloud/docs/overview/concepts/geo-scope) where resource is located. If it is not provided, the default provider zone will be used.
	Zone *string `json:"zone,omitempty" tf:"zone,omitempty"`
}

type HostParameters struct {

	// (Boolean) Sets whether the host should get a public IP address on creation. Can be either true or false.
	// Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
	// +kubebuilder:validation:Optional
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (String) The name of the shard to which the host belongs.
	// The name of the shard to which the host belongs.
	// +kubebuilder:validation:Optional
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// (String) The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Subnet
	// +kubebuilder:validation:Optional
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// Reference to a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDRef *v1.Reference `json:"subnetIdRef,omitempty" tf:"-"`

	// Selector for a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDSelector *v1.Selector `json:"subnetIdSelector,omitempty" tf:"-"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// The type of the host to be deployed. Can be either `CLICKHOUSE` or `ZOOKEEPER`.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// (String) The availability zone where resource is located. If it is not provided, the default provider zone will be used.
	// The [availability zone](https://yandex.cloud/docs/overview/concepts/geo-scope) where resource is located. If it is not provided, the default provider zone will be used.
	// +kubebuilder:validation:Optional
	Zone *string `json:"zone" tf:"zone,omitempty"`
}

type JdbcBridgeInitParameters struct {

	// (Block List, Min: 1) A host of the ClickHouse cluster. (see below for nested schema)
	// Host of jdbc bridge.
	Host *string `json:"host,omitempty" tf:"host,omitempty"`

	// (Number) Port of jdbc bridge. Default value: 9019.
	// Port of jdbc bridge. Default value: 9019.
	Port *float64 `json:"port,omitempty" tf:"port,omitempty"`
}

type JdbcBridgeObservation struct {

	// (Block List, Min: 1) A host of the ClickHouse cluster. (see below for nested schema)
	// Host of jdbc bridge.
	Host *string `json:"host,omitempty" tf:"host,omitempty"`

	// (Number) Port of jdbc bridge. Default value: 9019.
	// Port of jdbc bridge. Default value: 9019.
	Port *float64 `json:"port,omitempty" tf:"port,omitempty"`
}

type JdbcBridgeParameters struct {

	// (Block List, Min: 1) A host of the ClickHouse cluster. (see below for nested schema)
	// Host of jdbc bridge.
	// +kubebuilder:validation:Optional
	Host *string `json:"host" tf:"host,omitempty"`

	// (Number) Port of jdbc bridge. Default value: 9019.
	// Port of jdbc bridge. Default value: 9019.
	// +kubebuilder:validation:Optional
	Port *float64 `json:"port,omitempty" tf:"port,omitempty"`
}

type KafkaInitParameters struct {

	// automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// Maximum allowed time between calls to consume messages (e.g., `rd_kafka_consumer_poll()` for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String, Sensitive) User password on kafka server.
	// User password on kafka server.
	SaslPasswordSecretRef *v1.SecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// (String) Username on kafka server.
	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type KafkaObservation struct {

	// automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// Maximum allowed time between calls to consume messages (e.g., `rd_kafka_consumer_poll()` for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String) Username on kafka server.
	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type KafkaParameters struct {

	// automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// +kubebuilder:validation:Optional
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	// +kubebuilder:validation:Optional
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	// +kubebuilder:validation:Optional
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// Maximum allowed time between calls to consume messages (e.g., `rd_kafka_consumer_poll()` for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// +kubebuilder:validation:Optional
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	// +kubebuilder:validation:Optional
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String, Sensitive) User password on kafka server.
	// User password on kafka server.
	// +kubebuilder:validation:Optional
	SaslPasswordSecretRef *v1.SecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// (String) Username on kafka server.
	// Username on kafka server.
	// +kubebuilder:validation:Optional
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	// +kubebuilder:validation:Optional
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// +kubebuilder:validation:Optional
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type KafkaTopicInitParameters struct {

	// (String) The resource name.
	// Kafka topic name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Kafka connection settings. (see below for nested schema)
	// Kafka connection settings.
	Settings []SettingsInitParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type KafkaTopicObservation struct {

	// (String) The resource name.
	// Kafka topic name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Kafka connection settings. (see below for nested schema)
	// Kafka connection settings.
	Settings []SettingsObservation `json:"settings,omitempty" tf:"settings,omitempty"`
}

type KafkaTopicParameters struct {

	// (String) The resource name.
	// Kafka topic name.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (Block List, Max: 1) Kafka connection settings. (see below for nested schema)
	// Kafka connection settings.
	// +kubebuilder:validation:Optional
	Settings []SettingsParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type MLModelInitParameters struct {

	// (String) The resource name.
	// The name of the ml model.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the model.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Model file URL. You can only use models stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type MLModelObservation struct {

	// (String) The resource name.
	// The name of the ml model.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the model.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Model file URL. You can only use models stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type MLModelParameters struct {

	// (String) The resource name.
	// The name of the ml model.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the model.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Model file URL. You can only use models stored in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	URI *string `json:"uri" tf:"uri,omitempty"`
}

type MaintenanceWindowInitParameters struct {

	// (String) Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// 24) for maintenance window if window type is weekly.
	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MaintenanceWindowObservation struct {

	// (String) Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// 24) for maintenance window if window type is weekly.
	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MaintenanceWindowParameters struct {

	// (String) Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
	// +kubebuilder:validation:Optional
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// 24) for maintenance window if window type is weekly.
	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	// +kubebuilder:validation:Optional
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type MergeTreeInitParameters struct {

	// (Boolean) When this setting has a value greater than zero only a single replica starts the merge immediately if merged part on shared storage and allow_remote_fs_zero_copy_replication is enabled.
	// When this setting has a value greater than zero only a single replica starts the merge immediately if merged part on shared storage and allow_remote_fs_zero_copy_replication is enabled.
	AllowRemoteFsZeroCopyReplication *bool `json:"allowRemoteFsZeroCopyReplication,omitempty" tf:"allow_remote_fs_zero_copy_replication,omitempty"`

	// (Boolean) Enables the check at table creation, that the data type of a column for sampling or sampling expression is correct. The data type must be one of unsigned integer types: UInt8, UInt16, UInt32, UInt64. Default value: true.
	// Enables the check at table creation, that the data type of a column for sampling or sampling expression is correct. The data type must be one of unsigned integer types: UInt8, UInt16, UInt32, UInt64. Default value: true.
	CheckSampleColumnIsCorrect *bool `json:"checkSampleColumnIsCorrect,omitempty" tf:"check_sample_column_is_correct,omitempty"`

	// (Number) Minimum period to clean old queue logs, blocks hashes and parts.
	// Minimum period to clean old queue logs, blocks hashes and parts.
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// (Number) If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	InactivePartsToDelayInsert *float64 `json:"inactivePartsToDelayInsert,omitempty" tf:"inactive_parts_to_delay_insert,omitempty"`

	// (Number) If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts exception.
	// If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the `Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts` exception.
	InactivePartsToThrowInsert *float64 `json:"inactivePartsToThrowInsert,omitempty" tf:"inactive_parts_to_throw_insert,omitempty"`

	// (Number) The too many parts check according to parts_to_delay_insert and parts_to_throw_insert will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	// The `too many parts` check according to `parts_to_delay_insert` and `parts_to_throw_insert` will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// - roughly corresponds to the maximum possible part size created by an automatic background merge.
	// The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. max_bytes_to_merge_at_max_space_in_pool -- roughly corresponds to the maximum possible part size created by an automatic background merge.
	MaxBytesToMergeAtMaxSpaceInPool *float64 `json:"maxBytesToMergeAtMaxSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_max_space_in_pool,omitempty"`

	// (Number) Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// (Number) Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	MaxCleanupDelayPeriod *float64 `json:"maxCleanupDelayPeriod,omitempty" tf:"max_cleanup_delay_period,omitempty"`

	// scale clusters. Default value: 60000 milliseconds (60 seconds).
	// Maximum sleep time for merge selecting, a lower setting will trigger selecting tasks in background_schedule_pool frequently which result in large amount of requests to zookeeper in large-scale clusters. Default value: 60000 milliseconds (60 seconds).
	MaxMergeSelectingSleepMs *float64 `json:"maxMergeSelectingSleepMs,omitempty" tf:"max_merge_selecting_sleep_ms,omitempty"`

	// (Number) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// (Number) Maximum number of parts in all partitions.
	// Maximum number of parts in all partitions.
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// (Number) Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// (Number) The number of rows that are read from the merged parts into memory. Default value: 8192.
	// The number of rows that are read from the merged parts into memory. Default value: 8192.
	MergeMaxBlockSize *float64 `json:"mergeMaxBlockSize,omitempty" tf:"merge_max_block_size,omitempty"`

	// scale clusters.
	// Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters.
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// (Boolean) Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// (Number) Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// Merge parts if every part in the range is older than the value of `min_age_to_force_merge_seconds`.
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// (Number) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// (Number) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// (Number) When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid Too many parts. Default value: 20.
	// When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid `Too many parts`. Default value: 20.
	NumberOfFreeEntriesInPoolToExecuteMutation *float64 `json:"numberOfFreeEntriesInPoolToExecuteMutation,omitempty" tf:"number_of_free_entries_in_pool_to_execute_mutation,omitempty"`

	// (Number) Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// (Number) Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// (Number) Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// (Number) Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// (Number) Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// copy replication when a replica is located on a remote filesystem.
	// Enables zero-copy replication when a replica is located on a remote filesystem.
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type MergeTreeObservation struct {

	// (Boolean) When this setting has a value greater than zero only a single replica starts the merge immediately if merged part on shared storage and allow_remote_fs_zero_copy_replication is enabled.
	// When this setting has a value greater than zero only a single replica starts the merge immediately if merged part on shared storage and allow_remote_fs_zero_copy_replication is enabled.
	AllowRemoteFsZeroCopyReplication *bool `json:"allowRemoteFsZeroCopyReplication,omitempty" tf:"allow_remote_fs_zero_copy_replication,omitempty"`

	// (Boolean) Enables the check at table creation, that the data type of a column for sampling or sampling expression is correct. The data type must be one of unsigned integer types: UInt8, UInt16, UInt32, UInt64. Default value: true.
	// Enables the check at table creation, that the data type of a column for sampling or sampling expression is correct. The data type must be one of unsigned integer types: UInt8, UInt16, UInt32, UInt64. Default value: true.
	CheckSampleColumnIsCorrect *bool `json:"checkSampleColumnIsCorrect,omitempty" tf:"check_sample_column_is_correct,omitempty"`

	// (Number) Minimum period to clean old queue logs, blocks hashes and parts.
	// Minimum period to clean old queue logs, blocks hashes and parts.
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// (Number) If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	InactivePartsToDelayInsert *float64 `json:"inactivePartsToDelayInsert,omitempty" tf:"inactive_parts_to_delay_insert,omitempty"`

	// (Number) If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts exception.
	// If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the `Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts` exception.
	InactivePartsToThrowInsert *float64 `json:"inactivePartsToThrowInsert,omitempty" tf:"inactive_parts_to_throw_insert,omitempty"`

	// (Number) The too many parts check according to parts_to_delay_insert and parts_to_throw_insert will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	// The `too many parts` check according to `parts_to_delay_insert` and `parts_to_throw_insert` will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// - roughly corresponds to the maximum possible part size created by an automatic background merge.
	// The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. max_bytes_to_merge_at_max_space_in_pool -- roughly corresponds to the maximum possible part size created by an automatic background merge.
	MaxBytesToMergeAtMaxSpaceInPool *float64 `json:"maxBytesToMergeAtMaxSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_max_space_in_pool,omitempty"`

	// (Number) Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// (Number) Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	MaxCleanupDelayPeriod *float64 `json:"maxCleanupDelayPeriod,omitempty" tf:"max_cleanup_delay_period,omitempty"`

	// scale clusters. Default value: 60000 milliseconds (60 seconds).
	// Maximum sleep time for merge selecting, a lower setting will trigger selecting tasks in background_schedule_pool frequently which result in large amount of requests to zookeeper in large-scale clusters. Default value: 60000 milliseconds (60 seconds).
	MaxMergeSelectingSleepMs *float64 `json:"maxMergeSelectingSleepMs,omitempty" tf:"max_merge_selecting_sleep_ms,omitempty"`

	// (Number) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// (Number) Maximum number of parts in all partitions.
	// Maximum number of parts in all partitions.
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// (Number) Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// (Number) The number of rows that are read from the merged parts into memory. Default value: 8192.
	// The number of rows that are read from the merged parts into memory. Default value: 8192.
	MergeMaxBlockSize *float64 `json:"mergeMaxBlockSize,omitempty" tf:"merge_max_block_size,omitempty"`

	// scale clusters.
	// Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters.
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// (Boolean) Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// (Number) Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// Merge parts if every part in the range is older than the value of `min_age_to_force_merge_seconds`.
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// (Number) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// (Number) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// (Number) When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid Too many parts. Default value: 20.
	// When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid `Too many parts`. Default value: 20.
	NumberOfFreeEntriesInPoolToExecuteMutation *float64 `json:"numberOfFreeEntriesInPoolToExecuteMutation,omitempty" tf:"number_of_free_entries_in_pool_to_execute_mutation,omitempty"`

	// (Number) Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// (Number) Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// (Number) Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// (Number) Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// (Number) Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// copy replication when a replica is located on a remote filesystem.
	// Enables zero-copy replication when a replica is located on a remote filesystem.
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type MergeTreeParameters struct {

	// (Boolean) When this setting has a value greater than zero only a single replica starts the merge immediately if merged part on shared storage and allow_remote_fs_zero_copy_replication is enabled.
	// When this setting has a value greater than zero only a single replica starts the merge immediately if merged part on shared storage and allow_remote_fs_zero_copy_replication is enabled.
	// +kubebuilder:validation:Optional
	AllowRemoteFsZeroCopyReplication *bool `json:"allowRemoteFsZeroCopyReplication,omitempty" tf:"allow_remote_fs_zero_copy_replication,omitempty"`

	// (Boolean) Enables the check at table creation, that the data type of a column for sampling or sampling expression is correct. The data type must be one of unsigned integer types: UInt8, UInt16, UInt32, UInt64. Default value: true.
	// Enables the check at table creation, that the data type of a column for sampling or sampling expression is correct. The data type must be one of unsigned integer types: UInt8, UInt16, UInt32, UInt64. Default value: true.
	// +kubebuilder:validation:Optional
	CheckSampleColumnIsCorrect *bool `json:"checkSampleColumnIsCorrect,omitempty" tf:"check_sample_column_is_correct,omitempty"`

	// (Number) Minimum period to clean old queue logs, blocks hashes and parts.
	// Minimum period to clean old queue logs, blocks hashes and parts.
	// +kubebuilder:validation:Optional
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// (Number) If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// +kubebuilder:validation:Optional
	InactivePartsToDelayInsert *float64 `json:"inactivePartsToDelayInsert,omitempty" tf:"inactive_parts_to_delay_insert,omitempty"`

	// (Number) If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts exception.
	// If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the `Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts` exception.
	// +kubebuilder:validation:Optional
	InactivePartsToThrowInsert *float64 `json:"inactivePartsToThrowInsert,omitempty" tf:"inactive_parts_to_throw_insert,omitempty"`

	// (Number) The too many parts check according to parts_to_delay_insert and parts_to_throw_insert will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	// The `too many parts` check according to `parts_to_delay_insert` and `parts_to_throw_insert` will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	// +kubebuilder:validation:Optional
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// - roughly corresponds to the maximum possible part size created by an automatic background merge.
	// The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. max_bytes_to_merge_at_max_space_in_pool -- roughly corresponds to the maximum possible part size created by an automatic background merge.
	// +kubebuilder:validation:Optional
	MaxBytesToMergeAtMaxSpaceInPool *float64 `json:"maxBytesToMergeAtMaxSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_max_space_in_pool,omitempty"`

	// (Number) Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// +kubebuilder:validation:Optional
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// (Number) Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// +kubebuilder:validation:Optional
	MaxCleanupDelayPeriod *float64 `json:"maxCleanupDelayPeriod,omitempty" tf:"max_cleanup_delay_period,omitempty"`

	// scale clusters. Default value: 60000 milliseconds (60 seconds).
	// Maximum sleep time for merge selecting, a lower setting will trigger selecting tasks in background_schedule_pool frequently which result in large amount of requests to zookeeper in large-scale clusters. Default value: 60000 milliseconds (60 seconds).
	// +kubebuilder:validation:Optional
	MaxMergeSelectingSleepMs *float64 `json:"maxMergeSelectingSleepMs,omitempty" tf:"max_merge_selecting_sleep_ms,omitempty"`

	// (Number) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// +kubebuilder:validation:Optional
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// (Number) Maximum number of parts in all partitions.
	// Maximum number of parts in all partitions.
	// +kubebuilder:validation:Optional
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// (Number) Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// +kubebuilder:validation:Optional
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// (Number) The number of rows that are read from the merged parts into memory. Default value: 8192.
	// The number of rows that are read from the merged parts into memory. Default value: 8192.
	// +kubebuilder:validation:Optional
	MergeMaxBlockSize *float64 `json:"mergeMaxBlockSize,omitempty" tf:"merge_max_block_size,omitempty"`

	// scale clusters.
	// Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters.
	// +kubebuilder:validation:Optional
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// +kubebuilder:validation:Optional
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// +kubebuilder:validation:Optional
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// (Boolean) Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// +kubebuilder:validation:Optional
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// (Number) Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// Merge parts if every part in the range is older than the value of `min_age_to_force_merge_seconds`.
	// +kubebuilder:validation:Optional
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// (Number) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// +kubebuilder:validation:Optional
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// (Number) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// +kubebuilder:validation:Optional
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// (Number) When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid Too many parts. Default value: 20.
	// When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid `Too many parts`. Default value: 20.
	// +kubebuilder:validation:Optional
	NumberOfFreeEntriesInPoolToExecuteMutation *float64 `json:"numberOfFreeEntriesInPoolToExecuteMutation,omitempty" tf:"number_of_free_entries_in_pool_to_execute_mutation,omitempty"`

	// (Number) Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// +kubebuilder:validation:Optional
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// (Number) Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// +kubebuilder:validation:Optional
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// (Number) Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// +kubebuilder:validation:Optional
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// (Number) Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// +kubebuilder:validation:Optional
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// (Number) Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	// +kubebuilder:validation:Optional
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// copy replication when a replica is located on a remote filesystem.
	// Enables zero-copy replication when a replica is located on a remote filesystem.
	// +kubebuilder:validation:Optional
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type PatternInitParameters struct {

	// (String) Aggregation function name.
	// Aggregation function name.
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (String) Regular expression that the metric name must match.
	// Regular expression that the metric name must match.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (Block List) Retain parameters. (see below for nested schema)
	// Retain parameters.
	Retention []RetentionInitParameters `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternObservation struct {

	// (String) Aggregation function name.
	// Aggregation function name.
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (String) Regular expression that the metric name must match.
	// Regular expression that the metric name must match.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (Block List) Retain parameters. (see below for nested schema)
	// Retain parameters.
	Retention []RetentionObservation `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternParameters struct {

	// (String) Aggregation function name.
	// Aggregation function name.
	// +kubebuilder:validation:Optional
	Function *string `json:"function" tf:"function,omitempty"`

	// (String) Regular expression that the metric name must match.
	// Regular expression that the metric name must match.
	// +kubebuilder:validation:Optional
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (Block List) Retain parameters. (see below for nested schema)
	// Retain parameters.
	// +kubebuilder:validation:Optional
	Retention []RetentionParameters `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PermissionInitParameters struct {

	// (String) The name of the database that the permission grants access to.
	// The name of the database that the permission grants access to.
	DatabaseName *string `json:"databaseName,omitempty" tf:"database_name,omitempty"`
}

type PermissionObservation struct {

	// (String) The name of the database that the permission grants access to.
	// The name of the database that the permission grants access to.
	DatabaseName *string `json:"databaseName,omitempty" tf:"database_name,omitempty"`
}

type PermissionParameters struct {

	// (String) The name of the database that the permission grants access to.
	// The name of the database that the permission grants access to.
	// +kubebuilder:validation:Optional
	DatabaseName *string `json:"databaseName" tf:"database_name,omitempty"`
}

type QueryCacheInitParameters struct {

	// (Number) The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// The maximum number of SELECT query results stored in the cache. Default value: 1024.
	MaxEntries *float64 `json:"maxEntries,omitempty" tf:"max_entries,omitempty"`

	// (Number) The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	MaxEntrySizeInBytes *float64 `json:"maxEntrySizeInBytes,omitempty" tf:"max_entry_size_in_bytes,omitempty"`

	// (Number) The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	MaxEntrySizeInRows *float64 `json:"maxEntrySizeInRows,omitempty" tf:"max_entry_size_in_rows,omitempty"`

	// (Number) The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	MaxSizeInBytes *float64 `json:"maxSizeInBytes,omitempty" tf:"max_size_in_bytes,omitempty"`
}

type QueryCacheObservation struct {

	// (Number) The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// The maximum number of SELECT query results stored in the cache. Default value: 1024.
	MaxEntries *float64 `json:"maxEntries,omitempty" tf:"max_entries,omitempty"`

	// (Number) The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	MaxEntrySizeInBytes *float64 `json:"maxEntrySizeInBytes,omitempty" tf:"max_entry_size_in_bytes,omitempty"`

	// (Number) The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	MaxEntrySizeInRows *float64 `json:"maxEntrySizeInRows,omitempty" tf:"max_entry_size_in_rows,omitempty"`

	// (Number) The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	MaxSizeInBytes *float64 `json:"maxSizeInBytes,omitempty" tf:"max_size_in_bytes,omitempty"`
}

type QueryCacheParameters struct {

	// (Number) The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// +kubebuilder:validation:Optional
	MaxEntries *float64 `json:"maxEntries,omitempty" tf:"max_entries,omitempty"`

	// (Number) The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// +kubebuilder:validation:Optional
	MaxEntrySizeInBytes *float64 `json:"maxEntrySizeInBytes,omitempty" tf:"max_entry_size_in_bytes,omitempty"`

	// (Number) The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// +kubebuilder:validation:Optional
	MaxEntrySizeInRows *float64 `json:"maxEntrySizeInRows,omitempty" tf:"max_entry_size_in_rows,omitempty"`

	// (Number) The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// +kubebuilder:validation:Optional
	MaxSizeInBytes *float64 `json:"maxSizeInBytes,omitempty" tf:"max_size_in_bytes,omitempty"`
}

type QueryMaskingRulesInitParameters struct {

	// (String) The resource name.
	// Name for the rule.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Regular expression that the metric name must match.
	// RE2 compatible regular expression.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (String) Substitution string for sensitive data. Default value: six asterisks.
	// Substitution string for sensitive data. Default value: six asterisks.
	Replace *string `json:"replace,omitempty" tf:"replace,omitempty"`
}

type QueryMaskingRulesObservation struct {

	// (String) The resource name.
	// Name for the rule.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Regular expression that the metric name must match.
	// RE2 compatible regular expression.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (String) Substitution string for sensitive data. Default value: six asterisks.
	// Substitution string for sensitive data. Default value: six asterisks.
	Replace *string `json:"replace,omitempty" tf:"replace,omitempty"`
}

type QueryMaskingRulesParameters struct {

	// (String) The resource name.
	// Name for the rule.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Regular expression that the metric name must match.
	// RE2 compatible regular expression.
	// +kubebuilder:validation:Optional
	Regexp *string `json:"regexp" tf:"regexp,omitempty"`

	// (String) Substitution string for sensitive data. Default value: six asterisks.
	// Substitution string for sensitive data. Default value: six asterisks.
	// +kubebuilder:validation:Optional
	Replace *string `json:"replace,omitempty" tf:"replace,omitempty"`
}

type QuotaInitParameters struct {

	// (Number) The number of queries that threw exception.
	// The number of queries that threw exception.
	Errors *float64 `json:"errors,omitempty" tf:"errors,omitempty"`

	// (Number) The total query execution time, in milliseconds (wall time).
	// The total query execution time, in milliseconds (wall time).
	ExecutionTime *float64 `json:"executionTime,omitempty" tf:"execution_time,omitempty"`

	// (Number) Duration of interval for quota in milliseconds.
	// Duration of interval for quota in milliseconds.
	IntervalDuration *float64 `json:"intervalDuration,omitempty" tf:"interval_duration,omitempty"`

	// (Number) The total number of queries.
	// The total number of queries.
	Queries *float64 `json:"queries,omitempty" tf:"queries,omitempty"`

	// (Number) The total number of source rows read from tables for running the query, on all remote servers.
	// The total number of source rows read from tables for running the query, on all remote servers.
	ReadRows *float64 `json:"readRows,omitempty" tf:"read_rows,omitempty"`

	// (Number) The total number of rows given as the result.
	// The total number of rows given as the result.
	ResultRows *float64 `json:"resultRows,omitempty" tf:"result_rows,omitempty"`
}

type QuotaObservation struct {

	// (Number) The number of queries that threw exception.
	// The number of queries that threw exception.
	Errors *float64 `json:"errors,omitempty" tf:"errors,omitempty"`

	// (Number) The total query execution time, in milliseconds (wall time).
	// The total query execution time, in milliseconds (wall time).
	ExecutionTime *float64 `json:"executionTime,omitempty" tf:"execution_time,omitempty"`

	// (Number) Duration of interval for quota in milliseconds.
	// Duration of interval for quota in milliseconds.
	IntervalDuration *float64 `json:"intervalDuration,omitempty" tf:"interval_duration,omitempty"`

	// (Number) The total number of queries.
	// The total number of queries.
	Queries *float64 `json:"queries,omitempty" tf:"queries,omitempty"`

	// (Number) The total number of source rows read from tables for running the query, on all remote servers.
	// The total number of source rows read from tables for running the query, on all remote servers.
	ReadRows *float64 `json:"readRows,omitempty" tf:"read_rows,omitempty"`

	// (Number) The total number of rows given as the result.
	// The total number of rows given as the result.
	ResultRows *float64 `json:"resultRows,omitempty" tf:"result_rows,omitempty"`
}

type QuotaParameters struct {

	// (Number) The number of queries that threw exception.
	// The number of queries that threw exception.
	// +kubebuilder:validation:Optional
	Errors *float64 `json:"errors,omitempty" tf:"errors,omitempty"`

	// (Number) The total query execution time, in milliseconds (wall time).
	// The total query execution time, in milliseconds (wall time).
	// +kubebuilder:validation:Optional
	ExecutionTime *float64 `json:"executionTime,omitempty" tf:"execution_time,omitempty"`

	// (Number) Duration of interval for quota in milliseconds.
	// Duration of interval for quota in milliseconds.
	// +kubebuilder:validation:Optional
	IntervalDuration *float64 `json:"intervalDuration" tf:"interval_duration,omitempty"`

	// (Number) The total number of queries.
	// The total number of queries.
	// +kubebuilder:validation:Optional
	Queries *float64 `json:"queries,omitempty" tf:"queries,omitempty"`

	// (Number) The total number of source rows read from tables for running the query, on all remote servers.
	// The total number of source rows read from tables for running the query, on all remote servers.
	// +kubebuilder:validation:Optional
	ReadRows *float64 `json:"readRows,omitempty" tf:"read_rows,omitempty"`

	// (Number) The total number of rows given as the result.
	// The total number of rows given as the result.
	// +kubebuilder:validation:Optional
	ResultRows *float64 `json:"resultRows,omitempty" tf:"result_rows,omitempty"`
}

type RabbitmqInitParameters struct {

	// (String, Sensitive) RabbitMQ user password.
	// RabbitMQ user password.
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// (String) RabbitMQ username.
	// RabbitMQ username.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// (String) RabbitMQ vhost. Default: \.
	// RabbitMQ vhost. Default: `\`.
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type RabbitmqObservation struct {

	// (String) RabbitMQ username.
	// RabbitMQ username.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// (String) RabbitMQ vhost. Default: \.
	// RabbitMQ vhost. Default: `\`.
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type RabbitmqParameters struct {

	// (String, Sensitive) RabbitMQ user password.
	// RabbitMQ user password.
	// +kubebuilder:validation:Optional
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// (String) RabbitMQ username.
	// RabbitMQ username.
	// +kubebuilder:validation:Optional
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// (String) RabbitMQ vhost. Default: \.
	// RabbitMQ vhost. Default: `\`.
	// +kubebuilder:validation:Optional
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type ResourcesInitParameters struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ClickHouse host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ClickHouse hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ResourcesObservation struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ClickHouse host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ClickHouse hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ResourcesParameters struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ClickHouse host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ClickHouse hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type RetentionInitParameters struct {

	// (Number) Minimum data age in seconds.
	// Minimum data age in seconds.
	Age *float64 `json:"age,omitempty" tf:"age,omitempty"`

	// (Number) Accuracy of determining the age of the data in seconds.
	// Accuracy of determining the age of the data in seconds.
	Precision *float64 `json:"precision,omitempty" tf:"precision,omitempty"`
}

type RetentionObservation struct {

	// (Number) Minimum data age in seconds.
	// Minimum data age in seconds.
	Age *float64 `json:"age,omitempty" tf:"age,omitempty"`

	// (Number) Accuracy of determining the age of the data in seconds.
	// Accuracy of determining the age of the data in seconds.
	Precision *float64 `json:"precision,omitempty" tf:"precision,omitempty"`
}

type RetentionParameters struct {

	// (Number) Minimum data age in seconds.
	// Minimum data age in seconds.
	// +kubebuilder:validation:Optional
	Age *float64 `json:"age" tf:"age,omitempty"`

	// (Number) Accuracy of determining the age of the data in seconds.
	// Accuracy of determining the age of the data in seconds.
	// +kubebuilder:validation:Optional
	Precision *float64 `json:"precision" tf:"precision,omitempty"`
}

type SettingsInitParameters struct {

	// automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// Maximum allowed time between calls to consume messages (e.g., `rd_kafka_consumer_poll()` for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String, Sensitive) User password on kafka server.
	// User password on kafka server.
	SaslPasswordSecretRef *v1.SecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// (String) Username on kafka server.
	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type SettingsObservation struct {

	// automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// Maximum allowed time between calls to consume messages (e.g., `rd_kafka_consumer_poll()` for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String) Username on kafka server.
	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type SettingsParameters struct {

	// automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error (ERR__AUTO_OFFSET_RESET) which is retrieved by consuming messages and checking 'message->err'.
	// +kubebuilder:validation:Optional
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	// +kubebuilder:validation:Optional
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	// +kubebuilder:validation:Optional
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// Maximum allowed time between calls to consume messages (e.g., `rd_kafka_consumer_poll()` for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// +kubebuilder:validation:Optional
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	// +kubebuilder:validation:Optional
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String, Sensitive) User password on kafka server.
	// User password on kafka server.
	// +kubebuilder:validation:Optional
	SaslPasswordSecretRef *v1.SecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// (String) Username on kafka server.
	// Username on kafka server.
	// +kubebuilder:validation:Optional
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	// +kubebuilder:validation:Optional
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// +kubebuilder:validation:Optional
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type ShardGroupInitParameters struct {

	// (String) The resource description.
	// Description of the shard group.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) The resource name.
	// The name of the shard group, used as cluster name in Distributed tables.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (List of String) List of shards names that belong to the shard group.
	// List of shards names that belong to the shard group.
	ShardNames []*string `json:"shardNames,omitempty" tf:"shard_names,omitempty"`
}

type ShardGroupObservation struct {

	// (String) The resource description.
	// Description of the shard group.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) The resource name.
	// The name of the shard group, used as cluster name in Distributed tables.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (List of String) List of shards names that belong to the shard group.
	// List of shards names that belong to the shard group.
	ShardNames []*string `json:"shardNames,omitempty" tf:"shard_names,omitempty"`
}

type ShardGroupParameters struct {

	// (String) The resource description.
	// Description of the shard group.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) The resource name.
	// The name of the shard group, used as cluster name in Distributed tables.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (List of String) List of shards names that belong to the shard group.
	// List of shards names that belong to the shard group.
	// +kubebuilder:validation:Optional
	ShardNames []*string `json:"shardNames" tf:"shard_names,omitempty"`
}

type ShardInitParameters struct {

	// (String) The resource name.
	// The name of shard.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster.
	Resources []ShardResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`

	// (Number) The weight of shard.
	// The weight of shard.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardObservation struct {

	// (String) The resource name.
	// The name of shard.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster.
	Resources []ShardResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`

	// (Number) The weight of shard.
	// The weight of shard.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardParameters struct {

	// (String) The resource name.
	// The name of shard.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster.
	// +kubebuilder:validation:Optional
	Resources []ShardResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`

	// (Number) The weight of shard.
	// The weight of shard.
	// +kubebuilder:validation:Optional
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardResourcesInitParameters struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ClickHouse host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ClickHouse hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ShardResourcesObservation struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ClickHouse host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ClickHouse hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ShardResourcesParameters struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ClickHouse host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ClickHouse hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type UserInitParameters struct {

	// (Boolean) Generate password using Connection Manager. Allowed values: true or false. It's used only during user creation and is ignored during updating.
	// Generate password using Connection Manager. Allowed values: `true` or `false`. It's used only during user creation and is ignored during updating.
	//
	// ~> **Must specify either password or generate_password**.
	GeneratePassword *bool `json:"generatePassword,omitempty" tf:"generate_password,omitempty"`

	// (String) The resource name.
	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String, Sensitive) RabbitMQ user password.
	// The password of the user.
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// (Block Set) Set of permissions granted to the user. (see below for nested schema)
	// Set of permissions granted to the user.
	Permission []PermissionInitParameters `json:"permission,omitempty" tf:"permission,omitempty"`

	// (Block Set) Set of user quotas. (see below for nested schema)
	// Set of user quotas.
	Quota []QuotaInitParameters `json:"quota,omitempty" tf:"quota,omitempty"`

	// (Block List, Max: 1) Kafka connection settings. (see below for nested schema)
	// Custom settings for user.
	Settings []UserSettingsInitParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type UserObservation struct {

	// (Map of String) Connection Manager connection configuration. Filled in by the server automatically.
	// Connection Manager connection configuration. Filled in by the server automatically.
	// +mapType=granular
	ConnectionManager map[string]*string `json:"connectionManager,omitempty" tf:"connection_manager,omitempty"`

	// (Boolean) Generate password using Connection Manager. Allowed values: true or false. It's used only during user creation and is ignored during updating.
	// Generate password using Connection Manager. Allowed values: `true` or `false`. It's used only during user creation and is ignored during updating.
	//
	// ~> **Must specify either password or generate_password**.
	GeneratePassword *bool `json:"generatePassword,omitempty" tf:"generate_password,omitempty"`

	// (String) The resource name.
	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block Set) Set of permissions granted to the user. (see below for nested schema)
	// Set of permissions granted to the user.
	Permission []PermissionObservation `json:"permission,omitempty" tf:"permission,omitempty"`

	// (Block Set) Set of user quotas. (see below for nested schema)
	// Set of user quotas.
	Quota []QuotaObservation `json:"quota,omitempty" tf:"quota,omitempty"`

	// (Block List, Max: 1) Kafka connection settings. (see below for nested schema)
	// Custom settings for user.
	Settings []UserSettingsObservation `json:"settings,omitempty" tf:"settings,omitempty"`
}

type UserParameters struct {

	// (Boolean) Generate password using Connection Manager. Allowed values: true or false. It's used only during user creation and is ignored during updating.
	// Generate password using Connection Manager. Allowed values: `true` or `false`. It's used only during user creation and is ignored during updating.
	//
	// ~> **Must specify either password or generate_password**.
	// +kubebuilder:validation:Optional
	GeneratePassword *bool `json:"generatePassword,omitempty" tf:"generate_password,omitempty"`

	// (String) The resource name.
	// The name of the user.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String, Sensitive) RabbitMQ user password.
	// The password of the user.
	// +kubebuilder:validation:Optional
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// (Block Set) Set of permissions granted to the user. (see below for nested schema)
	// Set of permissions granted to the user.
	// +kubebuilder:validation:Optional
	Permission []PermissionParameters `json:"permission,omitempty" tf:"permission,omitempty"`

	// (Block Set) Set of user quotas. (see below for nested schema)
	// Set of user quotas.
	// +kubebuilder:validation:Optional
	Quota []QuotaParameters `json:"quota,omitempty" tf:"quota,omitempty"`

	// (Block List, Max: 1) Kafka connection settings. (see below for nested schema)
	// Custom settings for user.
	// +kubebuilder:validation:Optional
	Settings []UserSettingsParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type UserSettingsInitParameters struct {

	// (Boolean) Include CORS headers in HTTP responses.
	// Include CORS headers in HTTP responses.
	AddHTTPCorsHeader *bool `json:"addHttpCorsHeader,omitempty" tf:"add_http_cors_header,omitempty"`

	// (Boolean) Allows or denies DDL queries.
	// Allows or denies DDL queries.
	AllowDdl *bool `json:"allowDdl,omitempty" tf:"allow_ddl,omitempty"`

	// (Boolean) Enables introspections functions for query profiling.
	// Enables introspections functions for query profiling.
	AllowIntrospectionFunctions *bool `json:"allowIntrospectionFunctions,omitempty" tf:"allow_introspection_functions,omitempty"`

	// (Boolean) Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	// Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	AllowSuspiciousLowCardinalityTypes *bool `json:"allowSuspiciousLowCardinalityTypes,omitempty" tf:"allow_suspicious_low_cardinality_types,omitempty"`

	// (Boolean) Enables legacy ClickHouse server behavior in ANY INNER|LEFT JOIN operations.
	// Enables legacy ClickHouse server behavior in ANY INNER|LEFT JOIN operations.
	AnyJoinDistinctRightTableKeys *bool `json:"anyJoinDistinctRightTableKeys,omitempty" tf:"any_join_distinct_right_table_keys,omitempty"`

	// (Boolean) Enables asynchronous inserts. Disabled by default.
	// Enables asynchronous inserts. Disabled by default.
	AsyncInsert *bool `json:"asyncInsert,omitempty" tf:"async_insert,omitempty"`

	// (Number) The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	// The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	AsyncInsertBusyTimeout *float64 `json:"asyncInsertBusyTimeout,omitempty" tf:"async_insert_busy_timeout,omitempty"`

	// (Number) The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	// The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	AsyncInsertMaxDataSize *float64 `json:"asyncInsertMaxDataSize,omitempty" tf:"async_insert_max_data_size,omitempty"`

	// (Number) The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	// The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	AsyncInsertStaleTimeout *float64 `json:"asyncInsertStaleTimeout,omitempty" tf:"async_insert_stale_timeout,omitempty"`

	// (Number) The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	// The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// only queries (e.g. SELECT) when a client closes the connection without waiting for the response. Default value: false.
	// Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response. Default value: false.
	CancelHTTPReadonlyQueriesOnClientClose *bool `json:"cancelHttpReadonlyQueriesOnClientClose,omitempty" tf:"cancel_http_readonly_queries_on_client_close,omitempty"`

	// (Boolean) Enable compilation of queries.
	// Enable compilation of queries.
	Compile *bool `json:"compile,omitempty" tf:"compile,omitempty"`

	// (Boolean) Turn on expression compilation.
	// Turn on expression compilation.
	CompileExpressions *bool `json:"compileExpressions,omitempty" tf:"compile_expressions,omitempty"`

	// (Number) Connect timeout in milliseconds on the socket used for communicating with the client.
	// Connect timeout in milliseconds on the socket used for communicating with the client.
	ConnectTimeout *float64 `json:"connectTimeout,omitempty" tf:"connect_timeout,omitempty"`

	// (Number) The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	// The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	ConnectTimeoutWithFailover *float64 `json:"connectTimeoutWithFailover,omitempty" tf:"connect_timeout_with_failover,omitempty"`

	// (String) Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	CountDistinctImplementation *string `json:"countDistinctImplementation,omitempty" tf:"count_distinct_implementation,omitempty"`

	// (String) Allows choosing a parser of the text representation of date and time, one of: best_effort, basic, best_effort_us. Default value: basic. Cloud default value: best_effort.
	// Allows choosing a parser of the text representation of date and time, one of: `best_effort`, `basic`, `best_effort_us`. Default value: `basic`. Cloud default value: `best_effort`.
	DateTimeInputFormat *string `json:"dateTimeInputFormat,omitempty" tf:"date_time_input_format,omitempty"`

	// (String) Allows choosing different output formats of the text representation of date and time, one of: simple, iso, unix_timestamp. Default value: simple.
	// Allows choosing different output formats of the text representation of date and time, one of: `simple`, `iso`, `unix_timestamp`. Default value: `simple`.
	DateTimeOutputFormat *string `json:"dateTimeOutputFormat,omitempty" tf:"date_time_output_format,omitempty"`

	// (Boolean) Enables or disables the deduplication check for materialized views that receive data from Replicated tables.
	// Enables or disables the deduplication check for materialized views that receive data from `Replicated` tables.
	DeduplicateBlocksInDependentMaterializedViews *bool `json:"deduplicateBlocksInDependentMaterializedViews,omitempty" tf:"deduplicate_blocks_in_dependent_materialized_views,omitempty"`

	// (String) Sets behavior on overflow when using DISTINCT. Possible values:
	// Sets behavior on overflow when using DISTINCT. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	DistinctOverflowMode *string `json:"distinctOverflowMode,omitempty" tf:"distinct_overflow_mode,omitempty"`

	// (Boolean) Determine the behavior of distributed subqueries.
	// Determine the behavior of distributed subqueries.
	DistributedAggregationMemoryEfficient *bool `json:"distributedAggregationMemoryEfficient,omitempty" tf:"distributed_aggregation_memory_efficient,omitempty"`

	// (Number) Timeout for DDL queries, in milliseconds.
	// Timeout for DDL queries, in milliseconds.
	DistributedDdlTaskTimeout *float64 `json:"distributedDdlTaskTimeout,omitempty" tf:"distributed_ddl_task_timeout,omitempty"`

	// (String) Changes the behavior of distributed subqueries.
	// Changes the behavior of distributed subqueries.
	DistributedProductMode *string `json:"distributedProductMode,omitempty" tf:"distributed_product_mode,omitempty"`

	// (Boolean) Allows to return empty result.
	// Allows to return empty result.
	EmptyResultForAggregationByEmptySet *bool `json:"emptyResultForAggregationByEmptySet,omitempty" tf:"empty_result_for_aggregation_by_empty_set,omitempty"`

	// (Boolean) Enables or disables data compression in the response to an HTTP request.
	// Enables or disables data compression in the response to an HTTP request.
	EnableHTTPCompression *bool `json:"enableHttpCompression,omitempty" tf:"enable_http_compression,omitempty"`

	// of-date replica if updated data is not available.
	// Forces a query to an out-of-date replica if updated data is not available.
	FallbackToStaleReplicasForDistributedQueries *bool `json:"fallbackToStaleReplicasForDistributedQueries,omitempty" tf:"fallback_to_stale_replicas_for_distributed_queries,omitempty"`

	// (Boolean) Sets the data format of a nested columns.
	// Sets the data format of a nested columns.
	FlattenNested *bool `json:"flattenNested,omitempty" tf:"flatten_nested,omitempty"`

	// (Boolean) Disables query execution if the index can’t be used by date.
	// Disables query execution if the index can’t be used by date.
	ForceIndexByDate *bool `json:"forceIndexByDate,omitempty" tf:"force_index_by_date,omitempty"`

	// (Boolean) Disables query execution if indexing by the primary key is not possible.
	// Disables query execution if indexing by the primary key is not possible.
	ForcePrimaryKey *bool `json:"forcePrimaryKey,omitempty" tf:"force_primary_key,omitempty"`

	// (String) Regular expression (for Regexp format).
	// Regular expression (for Regexp format).
	FormatRegexp *string `json:"formatRegexp,omitempty" tf:"format_regexp,omitempty"`

	// (Boolean) Skip lines unmatched by regular expression.
	// Skip lines unmatched by regular expression.
	FormatRegexpSkipUnmatched *bool `json:"formatRegexpSkipUnmatched,omitempty" tf:"format_regexp_skip_unmatched,omitempty"`

	// (String) Sets behavior on overflow while GROUP BY operation. Possible values:
	// Sets behavior on overflow while GROUP BY operation. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// * `any` - perform approximate GROUP BY operation by continuing aggregation for the keys that got into the set, but don’t add new keys to the set.
	GroupByOverflowMode *string `json:"groupByOverflowMode,omitempty" tf:"group_by_overflow_mode,omitempty"`

	// level aggregation should be used.
	// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
	GroupByTwoLevelThreshold *float64 `json:"groupByTwoLevelThreshold,omitempty" tf:"group_by_two_level_threshold,omitempty"`

	// level aggregation should be used.
	// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
	GroupByTwoLevelThresholdBytes *float64 `json:"groupByTwoLevelThresholdBytes,omitempty" tf:"group_by_two_level_threshold_bytes,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	HTTPConnectionTimeout *float64 `json:"httpConnectionTimeout,omitempty" tf:"http_connection_timeout,omitempty"`

	// ClickHouse-Progress.
	// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
	HTTPHeadersProgressInterval *float64 `json:"httpHeadersProgressInterval,omitempty" tf:"http_headers_progress_interval,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	HTTPReceiveTimeout *float64 `json:"httpReceiveTimeout,omitempty" tf:"http_receive_timeout,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	HTTPSendTimeout *float64 `json:"httpSendTimeout,omitempty" tf:"http_send_timeout,omitempty"`

	// (Number) Connection timeout for establishing connection with replica for Hedged requests. Default value: 50 milliseconds.
	// Connection timeout for establishing connection with replica for Hedged requests. Default value: 50 milliseconds.
	HedgedConnectionTimeoutMs *float64 `json:"hedgedConnectionTimeoutMs,omitempty" tf:"hedged_connection_timeout_ms,omitempty"`

	// (Number) Timeout to close idle TCP connections after specified number of seconds. Default value: 3600 seconds.
	// Timeout to close idle TCP connections after specified number of seconds. Default value: 3600 seconds.
	IdleConnectionTimeout *float64 `json:"idleConnectionTimeout,omitempty" tf:"idle_connection_timeout,omitempty"`

	// (Boolean) When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	InputFormatDefaultsForOmittedFields *bool `json:"inputFormatDefaultsForOmittedFields,omitempty" tf:"input_format_defaults_for_omitted_fields,omitempty"`

	// (Boolean) Enables or disables the insertion of JSON data with nested objects.
	// Enables or disables the insertion of JSON data with nested objects.
	InputFormatImportNestedJSON *bool `json:"inputFormatImportNestedJson,omitempty" tf:"input_format_import_nested_json,omitempty"`

	// (Boolean) Enables or disables the initialization of NULL fields with default values, if data type of these fields is not nullable.
	// Enables or disables the initialization of NULL fields with default values, if data type of these fields is not nullable.
	InputFormatNullAsDefault *bool `json:"inputFormatNullAsDefault,omitempty" tf:"input_format_null_as_default,omitempty"`

	// preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	// Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	InputFormatParallelParsing *bool `json:"inputFormatParallelParsing,omitempty" tf:"input_format_parallel_parsing,omitempty"`

	// (Boolean) Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	InputFormatValuesInterpretExpressions *bool `json:"inputFormatValuesInterpretExpressions,omitempty" tf:"input_format_values_interpret_expressions,omitempty"`

	// (Boolean) Enables or disables checking the column order when inserting data.
	// Enables or disables checking the column order when inserting data.
	InputFormatWithNamesUseHeader *bool `json:"inputFormatWithNamesUseHeader,omitempty" tf:"input_format_with_names_use_header,omitempty"`

	// (Number) The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	// The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	InsertKeeperMaxRetries *float64 `json:"insertKeeperMaxRetries,omitempty" tf:"insert_keeper_max_retries,omitempty"`

	// (Boolean) Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	// Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	InsertNullAsDefault *bool `json:"insertNullAsDefault,omitempty" tf:"insert_null_as_default,omitempty"`

	// (Number) Enables the quorum writes.
	// Enables the quorum writes.
	InsertQuorum *float64 `json:"insertQuorum,omitempty" tf:"insert_quorum,omitempty"`

	// (Boolean) Enables or disables parallelism for quorum INSERT queries.
	// Enables or disables parallelism for quorum INSERT queries.
	InsertQuorumParallel *bool `json:"insertQuorumParallel,omitempty" tf:"insert_quorum_parallel,omitempty"`

	// (Number) Write to a quorum timeout in milliseconds.
	// Write to a quorum timeout in milliseconds.
	InsertQuorumTimeout *float64 `json:"insertQuorumTimeout,omitempty" tf:"insert_quorum_timeout,omitempty"`

	// (List of String) Specifies which JOIN algorithm is used. Possible values:
	// Specifies which JOIN algorithm is used. Possible values:
	// * `hash` - hash join algorithm is used. The most generic implementation that supports all combinations of kind and strictness and multiple join keys that are combined with OR in the JOIN ON section.
	// * `parallel_hash` - a variation of hash join that splits the data into buckets and builds several hash tables instead of one concurrently to speed up this process.
	// * `partial_merge` - a variation of the sort-merge algorithm, where only the right table is fully sorted.
	// * `direct` - this algorithm can be applied when the storage for the right table supports key-value requests.
	// * `auto` - when set to auto, hash join is tried first, and the algorithm is switched on the fly to another algorithm if the memory limit is violated.
	// * `full_sorting_merge` - sort-merge algorithm with full sorting joined tables before joining.
	// * `prefer_partial_merge` - clickHouse always tries to use partial_merge join if possible, otherwise, it uses hash. Deprecated, same as partial_merge,hash.
	JoinAlgorithm []*string `json:"joinAlgorithm,omitempty" tf:"join_algorithm,omitempty"`

	// (String) Sets behavior on overflow in JOIN. Possible values:
	// Sets behavior on overflow in JOIN. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	JoinOverflowMode *string `json:"joinOverflowMode,omitempty" tf:"join_overflow_mode,omitempty"`

	// (Boolean) Sets the type of JOIN behavior. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	// Sets the type of JOIN behavior. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	JoinUseNulls *bool `json:"joinUseNulls,omitempty" tf:"join_use_nulls,omitempty"`

	// (Boolean) Require aliases for subselects and table functions in FROM that more than one table is present.
	// Require aliases for subselects and table functions in FROM that more than one table is present.
	JoinedSubqueryRequiresAlias *bool `json:"joinedSubqueryRequiresAlias,omitempty" tf:"joined_subquery_requires_alias,omitempty"`

	// (String) Specifies the algorithm of replicas selection that is used for distributed query processing, one of: random, nearest_hostname, in_order, first_or_random, round_robin. Default value: random.
	// Specifies the algorithm of replicas selection that is used for distributed query processing, one of: random, nearest_hostname, in_order, first_or_random, round_robin. Default value: random.
	LoadBalancing *string `json:"loadBalancing,omitempty" tf:"load_balancing,omitempty"`

	// (String) Method of reading data from local filesystem. Possible values:
	// Method of reading data from local filesystem. Possible values:
	// * `read` - abort query execution, return an error.
	// * `pread` - abort query execution, return an error.
	// * `pread_threadpool` - stop query execution, return partial result. If the parameter is set to 0 (default), no hops is allowed.
	LocalFilesystemReadMethod *string `json:"localFilesystemReadMethod,omitempty" tf:"local_filesystem_read_method,omitempty"`

	// (Boolean) Setting up query threads logging. Query threads log into the system.query_thread_log table. This setting has effect only when log_queries is true. Queries’ threads run by ClickHouse with this setup are logged according to the rules in the query_thread_log server configuration parameter. Default value: true.
	// Setting up query threads logging. Query threads log into the system.query_thread_log table. This setting has effect only when log_queries is true. Queries’ threads run by ClickHouse with this setup are logged according to the rules in the query_thread_log server configuration parameter. Default value: `true`.
	LogQueryThreads *bool `json:"logQueryThreads,omitempty" tf:"log_query_threads,omitempty"`

	// (Boolean) Allows or restricts using the LowCardinality data type with the Native format.
	// Allows or restricts using the LowCardinality data type with the Native format.
	LowCardinalityAllowInNativeFormat *bool `json:"lowCardinalityAllowInNativeFormat,omitempty" tf:"low_cardinality_allow_in_native_format,omitempty"`

	// (Number) Maximum abstract syntax tree depth.
	// Maximum abstract syntax tree depth.
	MaxAstDepth *float64 `json:"maxAstDepth,omitempty" tf:"max_ast_depth,omitempty"`

	// (Number) Maximum abstract syntax tree elements.
	// Maximum abstract syntax tree elements.
	MaxAstElements *float64 `json:"maxAstElements,omitempty" tf:"max_ast_elements,omitempty"`

	// (Number) A recommendation for what size of the block (in a count of rows) to load from tables.
	// A recommendation for what size of the block (in a count of rows) to load from tables.
	MaxBlockSize *float64 `json:"maxBlockSize,omitempty" tf:"max_block_size,omitempty"`

	// (Number) Limit in bytes for using memory for GROUP BY before using swap on disk.
	// Limit in bytes for using memory for GROUP BY before using swap on disk.
	MaxBytesBeforeExternalGroupBy *float64 `json:"maxBytesBeforeExternalGroupBy,omitempty" tf:"max_bytes_before_external_group_by,omitempty"`

	// (Number) This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	MaxBytesBeforeExternalSort *float64 `json:"maxBytesBeforeExternalSort,omitempty" tf:"max_bytes_before_external_sort,omitempty"`

	// (Number) Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	MaxBytesInDistinct *float64 `json:"maxBytesInDistinct,omitempty" tf:"max_bytes_in_distinct,omitempty"`

	// (Number) Limit on maximum size of the hash table for JOIN, in bytes.
	// Limit on maximum size of the hash table for JOIN, in bytes.
	MaxBytesInJoin *float64 `json:"maxBytesInJoin,omitempty" tf:"max_bytes_in_join,omitempty"`

	// (Number) Limit on the number of bytes in the set resulting from the execution of the IN section.
	// Limit on the number of bytes in the set resulting from the execution of the IN section.
	MaxBytesInSet *float64 `json:"maxBytesInSet,omitempty" tf:"max_bytes_in_set,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	MaxBytesToRead *float64 `json:"maxBytesToRead,omitempty" tf:"max_bytes_to_read,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	MaxBytesToSort *float64 `json:"maxBytesToSort,omitempty" tf:"max_bytes_to_sort,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxBytesToTransfer *float64 `json:"maxBytesToTransfer,omitempty" tf:"max_bytes_to_transfer,omitempty"`

	// (Number) Limits the maximum number of columns that can be read from a table in a single query.
	// Limits the maximum number of columns that can be read from a table in a single query.
	MaxColumnsToRead *float64 `json:"maxColumnsToRead,omitempty" tf:"max_columns_to_read,omitempty"`

	// (Number) The maximum number of concurrent requests per user. Default value: 0 (no limit).
	// The maximum number of concurrent requests per user. Default value: 0 (no limit).
	MaxConcurrentQueriesForUser *float64 `json:"maxConcurrentQueriesForUser,omitempty" tf:"max_concurrent_queries_for_user,omitempty"`

	// (Number) Limits the maximum query execution time in milliseconds.
	// Limits the maximum query execution time in milliseconds.
	MaxExecutionTime *float64 `json:"maxExecutionTime,omitempty" tf:"max_execution_time,omitempty"`

	// (Number) Maximum abstract syntax tree depth after after expansion of aliases.
	// Maximum abstract syntax tree depth after after expansion of aliases.
	MaxExpandedAstElements *float64 `json:"maxExpandedAstElements,omitempty" tf:"max_expanded_ast_elements,omitempty"`

	// (Number) Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	// Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	MaxFinalThreads *float64 `json:"maxFinalThreads,omitempty" tf:"max_final_threads,omitempty"`

	// engine tables.
	// Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
	MaxHTTPGetRedirects *float64 `json:"maxHttpGetRedirects,omitempty" tf:"max_http_get_redirects,omitempty"`

	// (Number) The size of blocks (in a count of rows) to form for insertion into a table.
	// The size of blocks (in a count of rows) to form for insertion into a table.
	MaxInsertBlockSize *float64 `json:"maxInsertBlockSize,omitempty" tf:"max_insert_block_size,omitempty"`

	// (Number) The maximum number of threads to execute the INSERT SELECT query. Default value: 0.
	// The maximum number of threads to execute the INSERT SELECT query. Default value: 0.
	MaxInsertThreads *float64 `json:"maxInsertThreads,omitempty" tf:"max_insert_threads,omitempty"`

	// (Number) Limits the maximum memory usage (in bytes) for processing queries on a single server.
	// Limits the maximum memory usage (in bytes) for processing queries on a single server.
	MaxMemoryUsage *float64 `json:"maxMemoryUsage,omitempty" tf:"max_memory_usage,omitempty"`

	// (Number) Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	MaxMemoryUsageForUser *float64 `json:"maxMemoryUsageForUser,omitempty" tf:"max_memory_usage_for_user,omitempty"`

	// (Number) Limits the speed of the data exchange over the network in bytes per second.
	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidth *float64 `json:"maxNetworkBandwidth,omitempty" tf:"max_network_bandwidth,omitempty"`

	// (Number) Limits the speed of the data exchange over the network in bytes per second.
	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidthForUser *float64 `json:"maxNetworkBandwidthForUser,omitempty" tf:"max_network_bandwidth_for_user,omitempty"`

	// (Number) Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	// Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	MaxParserDepth *float64 `json:"maxParserDepth,omitempty" tf:"max_parser_depth,omitempty"`

	// (Number) The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	MaxQuerySize *float64 `json:"maxQuerySize,omitempty" tf:"max_query_size,omitempty"`

	// (Number) The maximum size of the buffer to read from the filesystem.
	// The maximum size of the buffer to read from the filesystem.
	MaxReadBufferSize *float64 `json:"maxReadBufferSize,omitempty" tf:"max_read_buffer_size,omitempty"`

	// (Number) Disables lagging replicas for distributed queries.
	// Disables lagging replicas for distributed queries.
	MaxReplicaDelayForDistributedQueries *float64 `json:"maxReplicaDelayForDistributedQueries,omitempty" tf:"max_replica_delay_for_distributed_queries,omitempty"`

	// (Number) Limits the number of bytes in the result.
	// Limits the number of bytes in the result.
	MaxResultBytes *float64 `json:"maxResultBytes,omitempty" tf:"max_result_bytes,omitempty"`

	// (Number) Limits the number of rows in the result.
	// Limits the number of rows in the result.
	MaxResultRows *float64 `json:"maxResultRows,omitempty" tf:"max_result_rows,omitempty"`

	// (Number) Limits the maximum number of different rows when using DISTINCT.
	// Limits the maximum number of different rows when using DISTINCT.
	MaxRowsInDistinct *float64 `json:"maxRowsInDistinct,omitempty" tf:"max_rows_in_distinct,omitempty"`

	// (Number) Limit on maximum size of the hash table for JOIN, in rows.
	// Limit on maximum size of the hash table for JOIN, in rows.
	MaxRowsInJoin *float64 `json:"maxRowsInJoin,omitempty" tf:"max_rows_in_join,omitempty"`

	// (Number) Limit on the number of rows in the set resulting from the execution of the IN section.
	// Limit on the number of rows in the set resulting from the execution of the IN section.
	MaxRowsInSet *float64 `json:"maxRowsInSet,omitempty" tf:"max_rows_in_set,omitempty"`

	// (Number) Limits the maximum number of unique keys received from aggregation function.
	// Limits the maximum number of unique keys received from aggregation function.
	MaxRowsToGroupBy *float64 `json:"maxRowsToGroupBy,omitempty" tf:"max_rows_to_group_by,omitempty"`

	// (Number) Limits the maximum number of rows that can be read from a table when running a query.
	// Limits the maximum number of rows that can be read from a table when running a query.
	MaxRowsToRead *float64 `json:"maxRowsToRead,omitempty" tf:"max_rows_to_read,omitempty"`

	// (Number) Limits the maximum number of rows that can be read from a table for sorting.
	// Limits the maximum number of rows that can be read from a table for sorting.
	MaxRowsToSort *float64 `json:"maxRowsToSort,omitempty" tf:"max_rows_to_sort,omitempty"`

	// (Number) Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxRowsToTransfer *float64 `json:"maxRowsToTransfer,omitempty" tf:"max_rows_to_transfer,omitempty"`

	// (Number) Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	MaxTemporaryColumns *float64 `json:"maxTemporaryColumns,omitempty" tf:"max_temporary_columns,omitempty"`

	// (Number) The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForQuery *float64 `json:"maxTemporaryDataOnDiskSizeForQuery,omitempty" tf:"max_temporary_data_on_disk_size_for_query,omitempty"`

	// (Number) The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForUser *float64 `json:"maxTemporaryDataOnDiskSizeForUser,omitempty" tf:"max_temporary_data_on_disk_size_for_user,omitempty"`

	// (Number) Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	MaxTemporaryNonConstColumns *float64 `json:"maxTemporaryNonConstColumns,omitempty" tf:"max_temporary_non_const_columns,omitempty"`

	// (Number) The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	MaxThreads *float64 `json:"maxThreads,omitempty" tf:"max_threads,omitempty"`

	// (Number) It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominator *float64 `json:"memoryOvercommitRatioDenominator,omitempty" tf:"memory_overcommit_ratio_denominator,omitempty"`

	// (Number) It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominatorForUser *float64 `json:"memoryOvercommitRatioDenominatorForUser,omitempty" tf:"memory_overcommit_ratio_denominator_for_user,omitempty"`

	// (Number) Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	// Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	MemoryProfilerSampleProbability *float64 `json:"memoryProfilerSampleProbability,omitempty" tf:"memory_profiler_sample_probability,omitempty"`

	// (Number) Memory profiler step (in bytes). If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	// Memory profiler step (in bytes). If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	MemoryProfilerStep *float64 `json:"memoryProfilerStep,omitempty" tf:"memory_profiler_step,omitempty"`

	// (Number) Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	// Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	MemoryUsageOvercommitMaxWaitMicroseconds *float64 `json:"memoryUsageOvercommitMaxWaitMicroseconds,omitempty" tf:"memory_usage_overcommit_max_wait_microseconds,omitempty"`

	// (Number) If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxBytesToUseCache *float64 `json:"mergeTreeMaxBytesToUseCache,omitempty" tf:"merge_tree_max_bytes_to_use_cache,omitempty"`

	// (Number) If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxRowsToUseCache *float64 `json:"mergeTreeMaxRowsToUseCache,omitempty" tf:"merge_tree_max_rows_to_use_cache,omitempty"`

	// engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	MergeTreeMinBytesForConcurrentRead *float64 `json:"mergeTreeMinBytesForConcurrentRead,omitempty" tf:"merge_tree_min_bytes_for_concurrent_read,omitempty"`

	// (Number) If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	MergeTreeMinRowsForConcurrentRead *float64 `json:"mergeTreeMinRowsForConcurrentRead,omitempty" tf:"merge_tree_min_rows_for_concurrent_read,omitempty"`

	// (Number) The minimum data volume required for using direct I/O access to the storage disk.
	// The minimum data volume required for using direct I/O access to the storage disk.
	MinBytesToUseDirectIo *float64 `json:"minBytesToUseDirectIo,omitempty" tf:"min_bytes_to_use_direct_io,omitempty"`

	// (Number) How many times to potentially use a compiled chunk of code before running compilation.
	// How many times to potentially use a compiled chunk of code before running compilation.
	MinCountToCompile *float64 `json:"minCountToCompile,omitempty" tf:"min_count_to_compile,omitempty"`

	// (Number) A query waits for expression compilation process to complete prior to continuing execution.
	// A query waits for expression compilation process to complete prior to continuing execution.
	MinCountToCompileExpression *float64 `json:"minCountToCompileExpression,omitempty" tf:"min_count_to_compile_expression,omitempty"`

	// (Number) Minimal execution speed in rows per second.
	// Minimal execution speed in rows per second.
	MinExecutionSpeed *float64 `json:"minExecutionSpeed,omitempty" tf:"min_execution_speed,omitempty"`

	// (Number) Minimal execution speed in bytes per second.
	// Minimal execution speed in bytes per second.
	MinExecutionSpeedBytes *float64 `json:"minExecutionSpeedBytes,omitempty" tf:"min_execution_speed_bytes,omitempty"`

	// (Number) Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeBytes *float64 `json:"minInsertBlockSizeBytes,omitempty" tf:"min_insert_block_size_bytes,omitempty"`

	// (Number) Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeRows *float64 `json:"minInsertBlockSizeRows,omitempty" tf:"min_insert_block_size_rows,omitempty"`

	// (Boolean) If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	OutputFormatJSONQuote64BitIntegers *bool `json:"outputFormatJsonQuote64BitIntegers,omitempty" tf:"output_format_json_quote_64bit_integers,omitempty"`

	// nan, +inf, -inf outputs in JSON output format.
	// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
	OutputFormatJSONQuoteDenormals *bool `json:"outputFormatJsonQuoteDenormals,omitempty" tf:"output_format_json_quote_denormals,omitempty"`

	// (Boolean) Enables/disables preferable using the localhost replica when processing distributed queries. Default value: true.
	// Enables/disables preferable using the localhost replica when processing distributed queries. Default value: true.
	PreferLocalhostReplica *bool `json:"preferLocalhostReplica,omitempty" tf:"prefer_localhost_replica,omitempty"`

	// (Number) Query priority.
	// Query priority.
	Priority *float64 `json:"priority,omitempty" tf:"priority,omitempty"`

	// (String) Quota accounting mode.
	// Quota accounting mode.
	QuotaMode *string `json:"quotaMode,omitempty" tf:"quota_mode,omitempty"`

	// (String) Sets behavior on overflow while read. Possible values:
	// Sets behavior on overflow while read. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	ReadOverflowMode *string `json:"readOverflowMode,omitempty" tf:"read_overflow_mode,omitempty"`

	// (Number) Restricts permissions for reading data, write data and change settings queries.
	// Restricts permissions for reading data, write data and change settings queries.
	Readonly *float64 `json:"readonly,omitempty" tf:"readonly,omitempty"`

	// (Number) Receive timeout in milliseconds on the socket used for communicating with the client.
	// Receive timeout in milliseconds on the socket used for communicating with the client.
	ReceiveTimeout *float64 `json:"receiveTimeout,omitempty" tf:"receive_timeout,omitempty"`

	// (String) Method of reading data from remote filesystem, one of: read, threadpool.
	// Method of reading data from remote filesystem, one of: `read`, `threadpool`.
	RemoteFilesystemReadMethod *string `json:"remoteFilesystemReadMethod,omitempty" tf:"remote_filesystem_read_method,omitempty"`

	// (Number) For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	ReplicationAlterPartitionsSync *float64 `json:"replicationAlterPartitionsSync,omitempty" tf:"replication_alter_partitions_sync,omitempty"`

	// (String) Sets behavior on overflow in result. Possible values:
	// Sets behavior on overflow in result. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	ResultOverflowMode *string `json:"resultOverflowMode,omitempty" tf:"result_overflow_mode,omitempty"`

	// (Boolean) Enables or disables sequential consistency for SELECT queries.
	// Enables or disables sequential consistency for SELECT queries.
	SelectSequentialConsistency *bool `json:"selectSequentialConsistency,omitempty" tf:"select_sequential_consistency,omitempty"`

	// ClickHouse-Progress HTTP response headers in clickhouse-server responses.
	// Enables or disables `X-ClickHouse-Progress` HTTP response headers in clickhouse-server responses.
	SendProgressInHTTPHeaders *bool `json:"sendProgressInHttpHeaders,omitempty" tf:"send_progress_in_http_headers,omitempty"`

	// (Number) Send timeout in milliseconds on the socket used for communicating with the client.
	// Send timeout in milliseconds on the socket used for communicating with the client.
	SendTimeout *float64 `json:"sendTimeout,omitempty" tf:"send_timeout,omitempty"`

	// (String) Sets behavior on overflow in the set resulting. Possible values:
	// Sets behavior on overflow in the set resulting. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	SetOverflowMode *string `json:"setOverflowMode,omitempty" tf:"set_overflow_mode,omitempty"`

	// (Boolean) Enables or disables silently skipping of unavailable shards.
	// Enables or disables silently skipping of unavailable shards.
	SkipUnavailableShards *bool `json:"skipUnavailableShards,omitempty" tf:"skip_unavailable_shards,omitempty"`

	// (String) Sets behavior on overflow while sort. Possible values:
	// Sets behavior on overflow while sort. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	SortOverflowMode *string `json:"sortOverflowMode,omitempty" tf:"sort_overflow_mode,omitempty"`

	// (Number) Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter. Must be at least 1000.
	// Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter. Must be at least 1000.
	TimeoutBeforeCheckingExecutionSpeed *float64 `json:"timeoutBeforeCheckingExecutionSpeed,omitempty" tf:"timeout_before_checking_execution_speed,omitempty"`

	// (String) Sets behavior on overflow. Possible values:
	// Sets behavior on overflow. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	TimeoutOverflowMode *string `json:"timeoutOverflowMode,omitempty" tf:"timeout_overflow_mode,omitempty"`

	// (String) Sets behavior on overflow. Possible values:
	// Sets behavior on overflow. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	TransferOverflowMode *string `json:"transferOverflowMode,omitempty" tf:"transfer_overflow_mode,omitempty"`

	// (Boolean) Enables equality of NULL values for IN operator.
	// Enables equality of NULL values for IN operator.
	TransformNullIn *bool `json:"transformNullIn,omitempty" tf:"transform_null_in,omitempty"`

	// (Boolean) Enables hedged requests logic for remote queries. It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within hedged_connection_timeout or no data was received within receive_data_timeout. Query uses the first connection which send non empty progress packet (or data packet, if allow_changing_replica_until_first_data_packet); other connections are cancelled. Queries with max_parallel_replicas > 1 are supported. Default value: true.
	// Enables hedged requests logic for remote queries. It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within hedged_connection_timeout or no data was received within receive_data_timeout. Query uses the first connection which send non empty progress packet (or data packet, if allow_changing_replica_until_first_data_packet); other connections are cancelled. Queries with max_parallel_replicas > 1 are supported. Default value: true.
	UseHedgedRequests *bool `json:"useHedgedRequests,omitempty" tf:"use_hedged_requests,omitempty"`

	// (Boolean) Whether to use a cache of uncompressed blocks.
	// Whether to use a cache of uncompressed blocks.
	UseUncompressedCache *bool `json:"useUncompressedCache,omitempty" tf:"use_uncompressed_cache,omitempty"`

	// (Boolean) Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	// Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	WaitForAsyncInsert *bool `json:"waitForAsyncInsert,omitempty" tf:"wait_for_async_insert,omitempty"`

	// (Number) The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	// The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	WaitForAsyncInsertTimeout *float64 `json:"waitForAsyncInsertTimeout,omitempty" tf:"wait_for_async_insert_timeout,omitempty"`
}

type UserSettingsObservation struct {

	// (Boolean) Include CORS headers in HTTP responses.
	// Include CORS headers in HTTP responses.
	AddHTTPCorsHeader *bool `json:"addHttpCorsHeader,omitempty" tf:"add_http_cors_header,omitempty"`

	// (Boolean) Allows or denies DDL queries.
	// Allows or denies DDL queries.
	AllowDdl *bool `json:"allowDdl,omitempty" tf:"allow_ddl,omitempty"`

	// (Boolean) Enables introspections functions for query profiling.
	// Enables introspections functions for query profiling.
	AllowIntrospectionFunctions *bool `json:"allowIntrospectionFunctions,omitempty" tf:"allow_introspection_functions,omitempty"`

	// (Boolean) Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	// Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	AllowSuspiciousLowCardinalityTypes *bool `json:"allowSuspiciousLowCardinalityTypes,omitempty" tf:"allow_suspicious_low_cardinality_types,omitempty"`

	// (Boolean) Enables legacy ClickHouse server behavior in ANY INNER|LEFT JOIN operations.
	// Enables legacy ClickHouse server behavior in ANY INNER|LEFT JOIN operations.
	AnyJoinDistinctRightTableKeys *bool `json:"anyJoinDistinctRightTableKeys,omitempty" tf:"any_join_distinct_right_table_keys,omitempty"`

	// (Boolean) Enables asynchronous inserts. Disabled by default.
	// Enables asynchronous inserts. Disabled by default.
	AsyncInsert *bool `json:"asyncInsert,omitempty" tf:"async_insert,omitempty"`

	// (Number) The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	// The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	AsyncInsertBusyTimeout *float64 `json:"asyncInsertBusyTimeout,omitempty" tf:"async_insert_busy_timeout,omitempty"`

	// (Number) The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	// The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	AsyncInsertMaxDataSize *float64 `json:"asyncInsertMaxDataSize,omitempty" tf:"async_insert_max_data_size,omitempty"`

	// (Number) The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	// The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	AsyncInsertStaleTimeout *float64 `json:"asyncInsertStaleTimeout,omitempty" tf:"async_insert_stale_timeout,omitempty"`

	// (Number) The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	// The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// only queries (e.g. SELECT) when a client closes the connection without waiting for the response. Default value: false.
	// Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response. Default value: false.
	CancelHTTPReadonlyQueriesOnClientClose *bool `json:"cancelHttpReadonlyQueriesOnClientClose,omitempty" tf:"cancel_http_readonly_queries_on_client_close,omitempty"`

	// (Boolean) Enable compilation of queries.
	// Enable compilation of queries.
	Compile *bool `json:"compile,omitempty" tf:"compile,omitempty"`

	// (Boolean) Turn on expression compilation.
	// Turn on expression compilation.
	CompileExpressions *bool `json:"compileExpressions,omitempty" tf:"compile_expressions,omitempty"`

	// (Number) Connect timeout in milliseconds on the socket used for communicating with the client.
	// Connect timeout in milliseconds on the socket used for communicating with the client.
	ConnectTimeout *float64 `json:"connectTimeout,omitempty" tf:"connect_timeout,omitempty"`

	// (Number) The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	// The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	ConnectTimeoutWithFailover *float64 `json:"connectTimeoutWithFailover,omitempty" tf:"connect_timeout_with_failover,omitempty"`

	// (String) Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	CountDistinctImplementation *string `json:"countDistinctImplementation,omitempty" tf:"count_distinct_implementation,omitempty"`

	// (String) Allows choosing a parser of the text representation of date and time, one of: best_effort, basic, best_effort_us. Default value: basic. Cloud default value: best_effort.
	// Allows choosing a parser of the text representation of date and time, one of: `best_effort`, `basic`, `best_effort_us`. Default value: `basic`. Cloud default value: `best_effort`.
	DateTimeInputFormat *string `json:"dateTimeInputFormat,omitempty" tf:"date_time_input_format,omitempty"`

	// (String) Allows choosing different output formats of the text representation of date and time, one of: simple, iso, unix_timestamp. Default value: simple.
	// Allows choosing different output formats of the text representation of date and time, one of: `simple`, `iso`, `unix_timestamp`. Default value: `simple`.
	DateTimeOutputFormat *string `json:"dateTimeOutputFormat,omitempty" tf:"date_time_output_format,omitempty"`

	// (Boolean) Enables or disables the deduplication check for materialized views that receive data from Replicated tables.
	// Enables or disables the deduplication check for materialized views that receive data from `Replicated` tables.
	DeduplicateBlocksInDependentMaterializedViews *bool `json:"deduplicateBlocksInDependentMaterializedViews,omitempty" tf:"deduplicate_blocks_in_dependent_materialized_views,omitempty"`

	// (String) Sets behavior on overflow when using DISTINCT. Possible values:
	// Sets behavior on overflow when using DISTINCT. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	DistinctOverflowMode *string `json:"distinctOverflowMode,omitempty" tf:"distinct_overflow_mode,omitempty"`

	// (Boolean) Determine the behavior of distributed subqueries.
	// Determine the behavior of distributed subqueries.
	DistributedAggregationMemoryEfficient *bool `json:"distributedAggregationMemoryEfficient,omitempty" tf:"distributed_aggregation_memory_efficient,omitempty"`

	// (Number) Timeout for DDL queries, in milliseconds.
	// Timeout for DDL queries, in milliseconds.
	DistributedDdlTaskTimeout *float64 `json:"distributedDdlTaskTimeout,omitempty" tf:"distributed_ddl_task_timeout,omitempty"`

	// (String) Changes the behavior of distributed subqueries.
	// Changes the behavior of distributed subqueries.
	DistributedProductMode *string `json:"distributedProductMode,omitempty" tf:"distributed_product_mode,omitempty"`

	// (Boolean) Allows to return empty result.
	// Allows to return empty result.
	EmptyResultForAggregationByEmptySet *bool `json:"emptyResultForAggregationByEmptySet,omitempty" tf:"empty_result_for_aggregation_by_empty_set,omitempty"`

	// (Boolean) Enables or disables data compression in the response to an HTTP request.
	// Enables or disables data compression in the response to an HTTP request.
	EnableHTTPCompression *bool `json:"enableHttpCompression,omitempty" tf:"enable_http_compression,omitempty"`

	// of-date replica if updated data is not available.
	// Forces a query to an out-of-date replica if updated data is not available.
	FallbackToStaleReplicasForDistributedQueries *bool `json:"fallbackToStaleReplicasForDistributedQueries,omitempty" tf:"fallback_to_stale_replicas_for_distributed_queries,omitempty"`

	// (Boolean) Sets the data format of a nested columns.
	// Sets the data format of a nested columns.
	FlattenNested *bool `json:"flattenNested,omitempty" tf:"flatten_nested,omitempty"`

	// (Boolean) Disables query execution if the index can’t be used by date.
	// Disables query execution if the index can’t be used by date.
	ForceIndexByDate *bool `json:"forceIndexByDate,omitempty" tf:"force_index_by_date,omitempty"`

	// (Boolean) Disables query execution if indexing by the primary key is not possible.
	// Disables query execution if indexing by the primary key is not possible.
	ForcePrimaryKey *bool `json:"forcePrimaryKey,omitempty" tf:"force_primary_key,omitempty"`

	// (String) Regular expression (for Regexp format).
	// Regular expression (for Regexp format).
	FormatRegexp *string `json:"formatRegexp,omitempty" tf:"format_regexp,omitempty"`

	// (Boolean) Skip lines unmatched by regular expression.
	// Skip lines unmatched by regular expression.
	FormatRegexpSkipUnmatched *bool `json:"formatRegexpSkipUnmatched,omitempty" tf:"format_regexp_skip_unmatched,omitempty"`

	// (String) Sets behavior on overflow while GROUP BY operation. Possible values:
	// Sets behavior on overflow while GROUP BY operation. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// * `any` - perform approximate GROUP BY operation by continuing aggregation for the keys that got into the set, but don’t add new keys to the set.
	GroupByOverflowMode *string `json:"groupByOverflowMode,omitempty" tf:"group_by_overflow_mode,omitempty"`

	// level aggregation should be used.
	// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
	GroupByTwoLevelThreshold *float64 `json:"groupByTwoLevelThreshold,omitempty" tf:"group_by_two_level_threshold,omitempty"`

	// level aggregation should be used.
	// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
	GroupByTwoLevelThresholdBytes *float64 `json:"groupByTwoLevelThresholdBytes,omitempty" tf:"group_by_two_level_threshold_bytes,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	HTTPConnectionTimeout *float64 `json:"httpConnectionTimeout,omitempty" tf:"http_connection_timeout,omitempty"`

	// ClickHouse-Progress.
	// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
	HTTPHeadersProgressInterval *float64 `json:"httpHeadersProgressInterval,omitempty" tf:"http_headers_progress_interval,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	HTTPReceiveTimeout *float64 `json:"httpReceiveTimeout,omitempty" tf:"http_receive_timeout,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	HTTPSendTimeout *float64 `json:"httpSendTimeout,omitempty" tf:"http_send_timeout,omitempty"`

	// (Number) Connection timeout for establishing connection with replica for Hedged requests. Default value: 50 milliseconds.
	// Connection timeout for establishing connection with replica for Hedged requests. Default value: 50 milliseconds.
	HedgedConnectionTimeoutMs *float64 `json:"hedgedConnectionTimeoutMs,omitempty" tf:"hedged_connection_timeout_ms,omitempty"`

	// (Number) Timeout to close idle TCP connections after specified number of seconds. Default value: 3600 seconds.
	// Timeout to close idle TCP connections after specified number of seconds. Default value: 3600 seconds.
	IdleConnectionTimeout *float64 `json:"idleConnectionTimeout,omitempty" tf:"idle_connection_timeout,omitempty"`

	// (Boolean) When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	InputFormatDefaultsForOmittedFields *bool `json:"inputFormatDefaultsForOmittedFields,omitempty" tf:"input_format_defaults_for_omitted_fields,omitempty"`

	// (Boolean) Enables or disables the insertion of JSON data with nested objects.
	// Enables or disables the insertion of JSON data with nested objects.
	InputFormatImportNestedJSON *bool `json:"inputFormatImportNestedJson,omitempty" tf:"input_format_import_nested_json,omitempty"`

	// (Boolean) Enables or disables the initialization of NULL fields with default values, if data type of these fields is not nullable.
	// Enables or disables the initialization of NULL fields with default values, if data type of these fields is not nullable.
	InputFormatNullAsDefault *bool `json:"inputFormatNullAsDefault,omitempty" tf:"input_format_null_as_default,omitempty"`

	// preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	// Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	InputFormatParallelParsing *bool `json:"inputFormatParallelParsing,omitempty" tf:"input_format_parallel_parsing,omitempty"`

	// (Boolean) Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	InputFormatValuesInterpretExpressions *bool `json:"inputFormatValuesInterpretExpressions,omitempty" tf:"input_format_values_interpret_expressions,omitempty"`

	// (Boolean) Enables or disables checking the column order when inserting data.
	// Enables or disables checking the column order when inserting data.
	InputFormatWithNamesUseHeader *bool `json:"inputFormatWithNamesUseHeader,omitempty" tf:"input_format_with_names_use_header,omitempty"`

	// (Number) The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	// The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	InsertKeeperMaxRetries *float64 `json:"insertKeeperMaxRetries,omitempty" tf:"insert_keeper_max_retries,omitempty"`

	// (Boolean) Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	// Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	InsertNullAsDefault *bool `json:"insertNullAsDefault,omitempty" tf:"insert_null_as_default,omitempty"`

	// (Number) Enables the quorum writes.
	// Enables the quorum writes.
	InsertQuorum *float64 `json:"insertQuorum,omitempty" tf:"insert_quorum,omitempty"`

	// (Boolean) Enables or disables parallelism for quorum INSERT queries.
	// Enables or disables parallelism for quorum INSERT queries.
	InsertQuorumParallel *bool `json:"insertQuorumParallel,omitempty" tf:"insert_quorum_parallel,omitempty"`

	// (Number) Write to a quorum timeout in milliseconds.
	// Write to a quorum timeout in milliseconds.
	InsertQuorumTimeout *float64 `json:"insertQuorumTimeout,omitempty" tf:"insert_quorum_timeout,omitempty"`

	// (List of String) Specifies which JOIN algorithm is used. Possible values:
	// Specifies which JOIN algorithm is used. Possible values:
	// * `hash` - hash join algorithm is used. The most generic implementation that supports all combinations of kind and strictness and multiple join keys that are combined with OR in the JOIN ON section.
	// * `parallel_hash` - a variation of hash join that splits the data into buckets and builds several hash tables instead of one concurrently to speed up this process.
	// * `partial_merge` - a variation of the sort-merge algorithm, where only the right table is fully sorted.
	// * `direct` - this algorithm can be applied when the storage for the right table supports key-value requests.
	// * `auto` - when set to auto, hash join is tried first, and the algorithm is switched on the fly to another algorithm if the memory limit is violated.
	// * `full_sorting_merge` - sort-merge algorithm with full sorting joined tables before joining.
	// * `prefer_partial_merge` - clickHouse always tries to use partial_merge join if possible, otherwise, it uses hash. Deprecated, same as partial_merge,hash.
	JoinAlgorithm []*string `json:"joinAlgorithm,omitempty" tf:"join_algorithm,omitempty"`

	// (String) Sets behavior on overflow in JOIN. Possible values:
	// Sets behavior on overflow in JOIN. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	JoinOverflowMode *string `json:"joinOverflowMode,omitempty" tf:"join_overflow_mode,omitempty"`

	// (Boolean) Sets the type of JOIN behavior. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	// Sets the type of JOIN behavior. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	JoinUseNulls *bool `json:"joinUseNulls,omitempty" tf:"join_use_nulls,omitempty"`

	// (Boolean) Require aliases for subselects and table functions in FROM that more than one table is present.
	// Require aliases for subselects and table functions in FROM that more than one table is present.
	JoinedSubqueryRequiresAlias *bool `json:"joinedSubqueryRequiresAlias,omitempty" tf:"joined_subquery_requires_alias,omitempty"`

	// (String) Specifies the algorithm of replicas selection that is used for distributed query processing, one of: random, nearest_hostname, in_order, first_or_random, round_robin. Default value: random.
	// Specifies the algorithm of replicas selection that is used for distributed query processing, one of: random, nearest_hostname, in_order, first_or_random, round_robin. Default value: random.
	LoadBalancing *string `json:"loadBalancing,omitempty" tf:"load_balancing,omitempty"`

	// (String) Method of reading data from local filesystem. Possible values:
	// Method of reading data from local filesystem. Possible values:
	// * `read` - abort query execution, return an error.
	// * `pread` - abort query execution, return an error.
	// * `pread_threadpool` - stop query execution, return partial result. If the parameter is set to 0 (default), no hops is allowed.
	LocalFilesystemReadMethod *string `json:"localFilesystemReadMethod,omitempty" tf:"local_filesystem_read_method,omitempty"`

	// (Boolean) Setting up query threads logging. Query threads log into the system.query_thread_log table. This setting has effect only when log_queries is true. Queries’ threads run by ClickHouse with this setup are logged according to the rules in the query_thread_log server configuration parameter. Default value: true.
	// Setting up query threads logging. Query threads log into the system.query_thread_log table. This setting has effect only when log_queries is true. Queries’ threads run by ClickHouse with this setup are logged according to the rules in the query_thread_log server configuration parameter. Default value: `true`.
	LogQueryThreads *bool `json:"logQueryThreads,omitempty" tf:"log_query_threads,omitempty"`

	// (Boolean) Allows or restricts using the LowCardinality data type with the Native format.
	// Allows or restricts using the LowCardinality data type with the Native format.
	LowCardinalityAllowInNativeFormat *bool `json:"lowCardinalityAllowInNativeFormat,omitempty" tf:"low_cardinality_allow_in_native_format,omitempty"`

	// (Number) Maximum abstract syntax tree depth.
	// Maximum abstract syntax tree depth.
	MaxAstDepth *float64 `json:"maxAstDepth,omitempty" tf:"max_ast_depth,omitempty"`

	// (Number) Maximum abstract syntax tree elements.
	// Maximum abstract syntax tree elements.
	MaxAstElements *float64 `json:"maxAstElements,omitempty" tf:"max_ast_elements,omitempty"`

	// (Number) A recommendation for what size of the block (in a count of rows) to load from tables.
	// A recommendation for what size of the block (in a count of rows) to load from tables.
	MaxBlockSize *float64 `json:"maxBlockSize,omitempty" tf:"max_block_size,omitempty"`

	// (Number) Limit in bytes for using memory for GROUP BY before using swap on disk.
	// Limit in bytes for using memory for GROUP BY before using swap on disk.
	MaxBytesBeforeExternalGroupBy *float64 `json:"maxBytesBeforeExternalGroupBy,omitempty" tf:"max_bytes_before_external_group_by,omitempty"`

	// (Number) This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	MaxBytesBeforeExternalSort *float64 `json:"maxBytesBeforeExternalSort,omitempty" tf:"max_bytes_before_external_sort,omitempty"`

	// (Number) Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	MaxBytesInDistinct *float64 `json:"maxBytesInDistinct,omitempty" tf:"max_bytes_in_distinct,omitempty"`

	// (Number) Limit on maximum size of the hash table for JOIN, in bytes.
	// Limit on maximum size of the hash table for JOIN, in bytes.
	MaxBytesInJoin *float64 `json:"maxBytesInJoin,omitempty" tf:"max_bytes_in_join,omitempty"`

	// (Number) Limit on the number of bytes in the set resulting from the execution of the IN section.
	// Limit on the number of bytes in the set resulting from the execution of the IN section.
	MaxBytesInSet *float64 `json:"maxBytesInSet,omitempty" tf:"max_bytes_in_set,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	MaxBytesToRead *float64 `json:"maxBytesToRead,omitempty" tf:"max_bytes_to_read,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	MaxBytesToSort *float64 `json:"maxBytesToSort,omitempty" tf:"max_bytes_to_sort,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxBytesToTransfer *float64 `json:"maxBytesToTransfer,omitempty" tf:"max_bytes_to_transfer,omitempty"`

	// (Number) Limits the maximum number of columns that can be read from a table in a single query.
	// Limits the maximum number of columns that can be read from a table in a single query.
	MaxColumnsToRead *float64 `json:"maxColumnsToRead,omitempty" tf:"max_columns_to_read,omitempty"`

	// (Number) The maximum number of concurrent requests per user. Default value: 0 (no limit).
	// The maximum number of concurrent requests per user. Default value: 0 (no limit).
	MaxConcurrentQueriesForUser *float64 `json:"maxConcurrentQueriesForUser,omitempty" tf:"max_concurrent_queries_for_user,omitempty"`

	// (Number) Limits the maximum query execution time in milliseconds.
	// Limits the maximum query execution time in milliseconds.
	MaxExecutionTime *float64 `json:"maxExecutionTime,omitempty" tf:"max_execution_time,omitempty"`

	// (Number) Maximum abstract syntax tree depth after after expansion of aliases.
	// Maximum abstract syntax tree depth after after expansion of aliases.
	MaxExpandedAstElements *float64 `json:"maxExpandedAstElements,omitempty" tf:"max_expanded_ast_elements,omitempty"`

	// (Number) Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	// Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	MaxFinalThreads *float64 `json:"maxFinalThreads,omitempty" tf:"max_final_threads,omitempty"`

	// engine tables.
	// Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
	MaxHTTPGetRedirects *float64 `json:"maxHttpGetRedirects,omitempty" tf:"max_http_get_redirects,omitempty"`

	// (Number) The size of blocks (in a count of rows) to form for insertion into a table.
	// The size of blocks (in a count of rows) to form for insertion into a table.
	MaxInsertBlockSize *float64 `json:"maxInsertBlockSize,omitempty" tf:"max_insert_block_size,omitempty"`

	// (Number) The maximum number of threads to execute the INSERT SELECT query. Default value: 0.
	// The maximum number of threads to execute the INSERT SELECT query. Default value: 0.
	MaxInsertThreads *float64 `json:"maxInsertThreads,omitempty" tf:"max_insert_threads,omitempty"`

	// (Number) Limits the maximum memory usage (in bytes) for processing queries on a single server.
	// Limits the maximum memory usage (in bytes) for processing queries on a single server.
	MaxMemoryUsage *float64 `json:"maxMemoryUsage,omitempty" tf:"max_memory_usage,omitempty"`

	// (Number) Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	MaxMemoryUsageForUser *float64 `json:"maxMemoryUsageForUser,omitempty" tf:"max_memory_usage_for_user,omitempty"`

	// (Number) Limits the speed of the data exchange over the network in bytes per second.
	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidth *float64 `json:"maxNetworkBandwidth,omitempty" tf:"max_network_bandwidth,omitempty"`

	// (Number) Limits the speed of the data exchange over the network in bytes per second.
	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidthForUser *float64 `json:"maxNetworkBandwidthForUser,omitempty" tf:"max_network_bandwidth_for_user,omitempty"`

	// (Number) Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	// Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	MaxParserDepth *float64 `json:"maxParserDepth,omitempty" tf:"max_parser_depth,omitempty"`

	// (Number) The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	MaxQuerySize *float64 `json:"maxQuerySize,omitempty" tf:"max_query_size,omitempty"`

	// (Number) The maximum size of the buffer to read from the filesystem.
	// The maximum size of the buffer to read from the filesystem.
	MaxReadBufferSize *float64 `json:"maxReadBufferSize,omitempty" tf:"max_read_buffer_size,omitempty"`

	// (Number) Disables lagging replicas for distributed queries.
	// Disables lagging replicas for distributed queries.
	MaxReplicaDelayForDistributedQueries *float64 `json:"maxReplicaDelayForDistributedQueries,omitempty" tf:"max_replica_delay_for_distributed_queries,omitempty"`

	// (Number) Limits the number of bytes in the result.
	// Limits the number of bytes in the result.
	MaxResultBytes *float64 `json:"maxResultBytes,omitempty" tf:"max_result_bytes,omitempty"`

	// (Number) Limits the number of rows in the result.
	// Limits the number of rows in the result.
	MaxResultRows *float64 `json:"maxResultRows,omitempty" tf:"max_result_rows,omitempty"`

	// (Number) Limits the maximum number of different rows when using DISTINCT.
	// Limits the maximum number of different rows when using DISTINCT.
	MaxRowsInDistinct *float64 `json:"maxRowsInDistinct,omitempty" tf:"max_rows_in_distinct,omitempty"`

	// (Number) Limit on maximum size of the hash table for JOIN, in rows.
	// Limit on maximum size of the hash table for JOIN, in rows.
	MaxRowsInJoin *float64 `json:"maxRowsInJoin,omitempty" tf:"max_rows_in_join,omitempty"`

	// (Number) Limit on the number of rows in the set resulting from the execution of the IN section.
	// Limit on the number of rows in the set resulting from the execution of the IN section.
	MaxRowsInSet *float64 `json:"maxRowsInSet,omitempty" tf:"max_rows_in_set,omitempty"`

	// (Number) Limits the maximum number of unique keys received from aggregation function.
	// Limits the maximum number of unique keys received from aggregation function.
	MaxRowsToGroupBy *float64 `json:"maxRowsToGroupBy,omitempty" tf:"max_rows_to_group_by,omitempty"`

	// (Number) Limits the maximum number of rows that can be read from a table when running a query.
	// Limits the maximum number of rows that can be read from a table when running a query.
	MaxRowsToRead *float64 `json:"maxRowsToRead,omitempty" tf:"max_rows_to_read,omitempty"`

	// (Number) Limits the maximum number of rows that can be read from a table for sorting.
	// Limits the maximum number of rows that can be read from a table for sorting.
	MaxRowsToSort *float64 `json:"maxRowsToSort,omitempty" tf:"max_rows_to_sort,omitempty"`

	// (Number) Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxRowsToTransfer *float64 `json:"maxRowsToTransfer,omitempty" tf:"max_rows_to_transfer,omitempty"`

	// (Number) Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	MaxTemporaryColumns *float64 `json:"maxTemporaryColumns,omitempty" tf:"max_temporary_columns,omitempty"`

	// (Number) The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForQuery *float64 `json:"maxTemporaryDataOnDiskSizeForQuery,omitempty" tf:"max_temporary_data_on_disk_size_for_query,omitempty"`

	// (Number) The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForUser *float64 `json:"maxTemporaryDataOnDiskSizeForUser,omitempty" tf:"max_temporary_data_on_disk_size_for_user,omitempty"`

	// (Number) Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	MaxTemporaryNonConstColumns *float64 `json:"maxTemporaryNonConstColumns,omitempty" tf:"max_temporary_non_const_columns,omitempty"`

	// (Number) The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	MaxThreads *float64 `json:"maxThreads,omitempty" tf:"max_threads,omitempty"`

	// (Number) It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominator *float64 `json:"memoryOvercommitRatioDenominator,omitempty" tf:"memory_overcommit_ratio_denominator,omitempty"`

	// (Number) It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominatorForUser *float64 `json:"memoryOvercommitRatioDenominatorForUser,omitempty" tf:"memory_overcommit_ratio_denominator_for_user,omitempty"`

	// (Number) Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	// Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	MemoryProfilerSampleProbability *float64 `json:"memoryProfilerSampleProbability,omitempty" tf:"memory_profiler_sample_probability,omitempty"`

	// (Number) Memory profiler step (in bytes). If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	// Memory profiler step (in bytes). If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	MemoryProfilerStep *float64 `json:"memoryProfilerStep,omitempty" tf:"memory_profiler_step,omitempty"`

	// (Number) Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	// Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	MemoryUsageOvercommitMaxWaitMicroseconds *float64 `json:"memoryUsageOvercommitMaxWaitMicroseconds,omitempty" tf:"memory_usage_overcommit_max_wait_microseconds,omitempty"`

	// (Number) If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxBytesToUseCache *float64 `json:"mergeTreeMaxBytesToUseCache,omitempty" tf:"merge_tree_max_bytes_to_use_cache,omitempty"`

	// (Number) If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxRowsToUseCache *float64 `json:"mergeTreeMaxRowsToUseCache,omitempty" tf:"merge_tree_max_rows_to_use_cache,omitempty"`

	// engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	MergeTreeMinBytesForConcurrentRead *float64 `json:"mergeTreeMinBytesForConcurrentRead,omitempty" tf:"merge_tree_min_bytes_for_concurrent_read,omitempty"`

	// (Number) If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	MergeTreeMinRowsForConcurrentRead *float64 `json:"mergeTreeMinRowsForConcurrentRead,omitempty" tf:"merge_tree_min_rows_for_concurrent_read,omitempty"`

	// (Number) The minimum data volume required for using direct I/O access to the storage disk.
	// The minimum data volume required for using direct I/O access to the storage disk.
	MinBytesToUseDirectIo *float64 `json:"minBytesToUseDirectIo,omitempty" tf:"min_bytes_to_use_direct_io,omitempty"`

	// (Number) How many times to potentially use a compiled chunk of code before running compilation.
	// How many times to potentially use a compiled chunk of code before running compilation.
	MinCountToCompile *float64 `json:"minCountToCompile,omitempty" tf:"min_count_to_compile,omitempty"`

	// (Number) A query waits for expression compilation process to complete prior to continuing execution.
	// A query waits for expression compilation process to complete prior to continuing execution.
	MinCountToCompileExpression *float64 `json:"minCountToCompileExpression,omitempty" tf:"min_count_to_compile_expression,omitempty"`

	// (Number) Minimal execution speed in rows per second.
	// Minimal execution speed in rows per second.
	MinExecutionSpeed *float64 `json:"minExecutionSpeed,omitempty" tf:"min_execution_speed,omitempty"`

	// (Number) Minimal execution speed in bytes per second.
	// Minimal execution speed in bytes per second.
	MinExecutionSpeedBytes *float64 `json:"minExecutionSpeedBytes,omitempty" tf:"min_execution_speed_bytes,omitempty"`

	// (Number) Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeBytes *float64 `json:"minInsertBlockSizeBytes,omitempty" tf:"min_insert_block_size_bytes,omitempty"`

	// (Number) Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeRows *float64 `json:"minInsertBlockSizeRows,omitempty" tf:"min_insert_block_size_rows,omitempty"`

	// (Boolean) If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	OutputFormatJSONQuote64BitIntegers *bool `json:"outputFormatJsonQuote64BitIntegers,omitempty" tf:"output_format_json_quote_64bit_integers,omitempty"`

	// nan, +inf, -inf outputs in JSON output format.
	// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
	OutputFormatJSONQuoteDenormals *bool `json:"outputFormatJsonQuoteDenormals,omitempty" tf:"output_format_json_quote_denormals,omitempty"`

	// (Boolean) Enables/disables preferable using the localhost replica when processing distributed queries. Default value: true.
	// Enables/disables preferable using the localhost replica when processing distributed queries. Default value: true.
	PreferLocalhostReplica *bool `json:"preferLocalhostReplica,omitempty" tf:"prefer_localhost_replica,omitempty"`

	// (Number) Query priority.
	// Query priority.
	Priority *float64 `json:"priority,omitempty" tf:"priority,omitempty"`

	// (String) Quota accounting mode.
	// Quota accounting mode.
	QuotaMode *string `json:"quotaMode,omitempty" tf:"quota_mode,omitempty"`

	// (String) Sets behavior on overflow while read. Possible values:
	// Sets behavior on overflow while read. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	ReadOverflowMode *string `json:"readOverflowMode,omitempty" tf:"read_overflow_mode,omitempty"`

	// (Number) Restricts permissions for reading data, write data and change settings queries.
	// Restricts permissions for reading data, write data and change settings queries.
	Readonly *float64 `json:"readonly,omitempty" tf:"readonly,omitempty"`

	// (Number) Receive timeout in milliseconds on the socket used for communicating with the client.
	// Receive timeout in milliseconds on the socket used for communicating with the client.
	ReceiveTimeout *float64 `json:"receiveTimeout,omitempty" tf:"receive_timeout,omitempty"`

	// (String) Method of reading data from remote filesystem, one of: read, threadpool.
	// Method of reading data from remote filesystem, one of: `read`, `threadpool`.
	RemoteFilesystemReadMethod *string `json:"remoteFilesystemReadMethod,omitempty" tf:"remote_filesystem_read_method,omitempty"`

	// (Number) For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	ReplicationAlterPartitionsSync *float64 `json:"replicationAlterPartitionsSync,omitempty" tf:"replication_alter_partitions_sync,omitempty"`

	// (String) Sets behavior on overflow in result. Possible values:
	// Sets behavior on overflow in result. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	ResultOverflowMode *string `json:"resultOverflowMode,omitempty" tf:"result_overflow_mode,omitempty"`

	// (Boolean) Enables or disables sequential consistency for SELECT queries.
	// Enables or disables sequential consistency for SELECT queries.
	SelectSequentialConsistency *bool `json:"selectSequentialConsistency,omitempty" tf:"select_sequential_consistency,omitempty"`

	// ClickHouse-Progress HTTP response headers in clickhouse-server responses.
	// Enables or disables `X-ClickHouse-Progress` HTTP response headers in clickhouse-server responses.
	SendProgressInHTTPHeaders *bool `json:"sendProgressInHttpHeaders,omitempty" tf:"send_progress_in_http_headers,omitempty"`

	// (Number) Send timeout in milliseconds on the socket used for communicating with the client.
	// Send timeout in milliseconds on the socket used for communicating with the client.
	SendTimeout *float64 `json:"sendTimeout,omitempty" tf:"send_timeout,omitempty"`

	// (String) Sets behavior on overflow in the set resulting. Possible values:
	// Sets behavior on overflow in the set resulting. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	SetOverflowMode *string `json:"setOverflowMode,omitempty" tf:"set_overflow_mode,omitempty"`

	// (Boolean) Enables or disables silently skipping of unavailable shards.
	// Enables or disables silently skipping of unavailable shards.
	SkipUnavailableShards *bool `json:"skipUnavailableShards,omitempty" tf:"skip_unavailable_shards,omitempty"`

	// (String) Sets behavior on overflow while sort. Possible values:
	// Sets behavior on overflow while sort. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	SortOverflowMode *string `json:"sortOverflowMode,omitempty" tf:"sort_overflow_mode,omitempty"`

	// (Number) Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter. Must be at least 1000.
	// Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter. Must be at least 1000.
	TimeoutBeforeCheckingExecutionSpeed *float64 `json:"timeoutBeforeCheckingExecutionSpeed,omitempty" tf:"timeout_before_checking_execution_speed,omitempty"`

	// (String) Sets behavior on overflow. Possible values:
	// Sets behavior on overflow. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	TimeoutOverflowMode *string `json:"timeoutOverflowMode,omitempty" tf:"timeout_overflow_mode,omitempty"`

	// (String) Sets behavior on overflow. Possible values:
	// Sets behavior on overflow. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	TransferOverflowMode *string `json:"transferOverflowMode,omitempty" tf:"transfer_overflow_mode,omitempty"`

	// (Boolean) Enables equality of NULL values for IN operator.
	// Enables equality of NULL values for IN operator.
	TransformNullIn *bool `json:"transformNullIn,omitempty" tf:"transform_null_in,omitempty"`

	// (Boolean) Enables hedged requests logic for remote queries. It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within hedged_connection_timeout or no data was received within receive_data_timeout. Query uses the first connection which send non empty progress packet (or data packet, if allow_changing_replica_until_first_data_packet); other connections are cancelled. Queries with max_parallel_replicas > 1 are supported. Default value: true.
	// Enables hedged requests logic for remote queries. It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within hedged_connection_timeout or no data was received within receive_data_timeout. Query uses the first connection which send non empty progress packet (or data packet, if allow_changing_replica_until_first_data_packet); other connections are cancelled. Queries with max_parallel_replicas > 1 are supported. Default value: true.
	UseHedgedRequests *bool `json:"useHedgedRequests,omitempty" tf:"use_hedged_requests,omitempty"`

	// (Boolean) Whether to use a cache of uncompressed blocks.
	// Whether to use a cache of uncompressed blocks.
	UseUncompressedCache *bool `json:"useUncompressedCache,omitempty" tf:"use_uncompressed_cache,omitempty"`

	// (Boolean) Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	// Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	WaitForAsyncInsert *bool `json:"waitForAsyncInsert,omitempty" tf:"wait_for_async_insert,omitempty"`

	// (Number) The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	// The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	WaitForAsyncInsertTimeout *float64 `json:"waitForAsyncInsertTimeout,omitempty" tf:"wait_for_async_insert_timeout,omitempty"`
}

type UserSettingsParameters struct {

	// (Boolean) Include CORS headers in HTTP responses.
	// Include CORS headers in HTTP responses.
	// +kubebuilder:validation:Optional
	AddHTTPCorsHeader *bool `json:"addHttpCorsHeader,omitempty" tf:"add_http_cors_header,omitempty"`

	// (Boolean) Allows or denies DDL queries.
	// Allows or denies DDL queries.
	// +kubebuilder:validation:Optional
	AllowDdl *bool `json:"allowDdl,omitempty" tf:"allow_ddl,omitempty"`

	// (Boolean) Enables introspections functions for query profiling.
	// Enables introspections functions for query profiling.
	// +kubebuilder:validation:Optional
	AllowIntrospectionFunctions *bool `json:"allowIntrospectionFunctions,omitempty" tf:"allow_introspection_functions,omitempty"`

	// (Boolean) Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	// Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	// +kubebuilder:validation:Optional
	AllowSuspiciousLowCardinalityTypes *bool `json:"allowSuspiciousLowCardinalityTypes,omitempty" tf:"allow_suspicious_low_cardinality_types,omitempty"`

	// (Boolean) Enables legacy ClickHouse server behavior in ANY INNER|LEFT JOIN operations.
	// Enables legacy ClickHouse server behavior in ANY INNER|LEFT JOIN operations.
	// +kubebuilder:validation:Optional
	AnyJoinDistinctRightTableKeys *bool `json:"anyJoinDistinctRightTableKeys,omitempty" tf:"any_join_distinct_right_table_keys,omitempty"`

	// (Boolean) Enables asynchronous inserts. Disabled by default.
	// Enables asynchronous inserts. Disabled by default.
	// +kubebuilder:validation:Optional
	AsyncInsert *bool `json:"asyncInsert,omitempty" tf:"async_insert,omitempty"`

	// (Number) The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	// The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	// +kubebuilder:validation:Optional
	AsyncInsertBusyTimeout *float64 `json:"asyncInsertBusyTimeout,omitempty" tf:"async_insert_busy_timeout,omitempty"`

	// (Number) The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	// The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	// +kubebuilder:validation:Optional
	AsyncInsertMaxDataSize *float64 `json:"asyncInsertMaxDataSize,omitempty" tf:"async_insert_max_data_size,omitempty"`

	// (Number) The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	// The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	// +kubebuilder:validation:Optional
	AsyncInsertStaleTimeout *float64 `json:"asyncInsertStaleTimeout,omitempty" tf:"async_insert_stale_timeout,omitempty"`

	// (Number) The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	// The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	// +kubebuilder:validation:Optional
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// only queries (e.g. SELECT) when a client closes the connection without waiting for the response. Default value: false.
	// Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response. Default value: false.
	// +kubebuilder:validation:Optional
	CancelHTTPReadonlyQueriesOnClientClose *bool `json:"cancelHttpReadonlyQueriesOnClientClose,omitempty" tf:"cancel_http_readonly_queries_on_client_close,omitempty"`

	// (Boolean) Enable compilation of queries.
	// Enable compilation of queries.
	// +kubebuilder:validation:Optional
	Compile *bool `json:"compile,omitempty" tf:"compile,omitempty"`

	// (Boolean) Turn on expression compilation.
	// Turn on expression compilation.
	// +kubebuilder:validation:Optional
	CompileExpressions *bool `json:"compileExpressions,omitempty" tf:"compile_expressions,omitempty"`

	// (Number) Connect timeout in milliseconds on the socket used for communicating with the client.
	// Connect timeout in milliseconds on the socket used for communicating with the client.
	// +kubebuilder:validation:Optional
	ConnectTimeout *float64 `json:"connectTimeout,omitempty" tf:"connect_timeout,omitempty"`

	// (Number) The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	// The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	// +kubebuilder:validation:Optional
	ConnectTimeoutWithFailover *float64 `json:"connectTimeoutWithFailover,omitempty" tf:"connect_timeout_with_failover,omitempty"`

	// (String) Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	// +kubebuilder:validation:Optional
	CountDistinctImplementation *string `json:"countDistinctImplementation,omitempty" tf:"count_distinct_implementation,omitempty"`

	// (String) Allows choosing a parser of the text representation of date and time, one of: best_effort, basic, best_effort_us. Default value: basic. Cloud default value: best_effort.
	// Allows choosing a parser of the text representation of date and time, one of: `best_effort`, `basic`, `best_effort_us`. Default value: `basic`. Cloud default value: `best_effort`.
	// +kubebuilder:validation:Optional
	DateTimeInputFormat *string `json:"dateTimeInputFormat,omitempty" tf:"date_time_input_format,omitempty"`

	// (String) Allows choosing different output formats of the text representation of date and time, one of: simple, iso, unix_timestamp. Default value: simple.
	// Allows choosing different output formats of the text representation of date and time, one of: `simple`, `iso`, `unix_timestamp`. Default value: `simple`.
	// +kubebuilder:validation:Optional
	DateTimeOutputFormat *string `json:"dateTimeOutputFormat,omitempty" tf:"date_time_output_format,omitempty"`

	// (Boolean) Enables or disables the deduplication check for materialized views that receive data from Replicated tables.
	// Enables or disables the deduplication check for materialized views that receive data from `Replicated` tables.
	// +kubebuilder:validation:Optional
	DeduplicateBlocksInDependentMaterializedViews *bool `json:"deduplicateBlocksInDependentMaterializedViews,omitempty" tf:"deduplicate_blocks_in_dependent_materialized_views,omitempty"`

	// (String) Sets behavior on overflow when using DISTINCT. Possible values:
	// Sets behavior on overflow when using DISTINCT. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	DistinctOverflowMode *string `json:"distinctOverflowMode,omitempty" tf:"distinct_overflow_mode,omitempty"`

	// (Boolean) Determine the behavior of distributed subqueries.
	// Determine the behavior of distributed subqueries.
	// +kubebuilder:validation:Optional
	DistributedAggregationMemoryEfficient *bool `json:"distributedAggregationMemoryEfficient,omitempty" tf:"distributed_aggregation_memory_efficient,omitempty"`

	// (Number) Timeout for DDL queries, in milliseconds.
	// Timeout for DDL queries, in milliseconds.
	// +kubebuilder:validation:Optional
	DistributedDdlTaskTimeout *float64 `json:"distributedDdlTaskTimeout,omitempty" tf:"distributed_ddl_task_timeout,omitempty"`

	// (String) Changes the behavior of distributed subqueries.
	// Changes the behavior of distributed subqueries.
	// +kubebuilder:validation:Optional
	DistributedProductMode *string `json:"distributedProductMode,omitempty" tf:"distributed_product_mode,omitempty"`

	// (Boolean) Allows to return empty result.
	// Allows to return empty result.
	// +kubebuilder:validation:Optional
	EmptyResultForAggregationByEmptySet *bool `json:"emptyResultForAggregationByEmptySet,omitempty" tf:"empty_result_for_aggregation_by_empty_set,omitempty"`

	// (Boolean) Enables or disables data compression in the response to an HTTP request.
	// Enables or disables data compression in the response to an HTTP request.
	// +kubebuilder:validation:Optional
	EnableHTTPCompression *bool `json:"enableHttpCompression,omitempty" tf:"enable_http_compression,omitempty"`

	// of-date replica if updated data is not available.
	// Forces a query to an out-of-date replica if updated data is not available.
	// +kubebuilder:validation:Optional
	FallbackToStaleReplicasForDistributedQueries *bool `json:"fallbackToStaleReplicasForDistributedQueries,omitempty" tf:"fallback_to_stale_replicas_for_distributed_queries,omitempty"`

	// (Boolean) Sets the data format of a nested columns.
	// Sets the data format of a nested columns.
	// +kubebuilder:validation:Optional
	FlattenNested *bool `json:"flattenNested,omitempty" tf:"flatten_nested,omitempty"`

	// (Boolean) Disables query execution if the index can’t be used by date.
	// Disables query execution if the index can’t be used by date.
	// +kubebuilder:validation:Optional
	ForceIndexByDate *bool `json:"forceIndexByDate,omitempty" tf:"force_index_by_date,omitempty"`

	// (Boolean) Disables query execution if indexing by the primary key is not possible.
	// Disables query execution if indexing by the primary key is not possible.
	// +kubebuilder:validation:Optional
	ForcePrimaryKey *bool `json:"forcePrimaryKey,omitempty" tf:"force_primary_key,omitempty"`

	// (String) Regular expression (for Regexp format).
	// Regular expression (for Regexp format).
	// +kubebuilder:validation:Optional
	FormatRegexp *string `json:"formatRegexp,omitempty" tf:"format_regexp,omitempty"`

	// (Boolean) Skip lines unmatched by regular expression.
	// Skip lines unmatched by regular expression.
	// +kubebuilder:validation:Optional
	FormatRegexpSkipUnmatched *bool `json:"formatRegexpSkipUnmatched,omitempty" tf:"format_regexp_skip_unmatched,omitempty"`

	// (String) Sets behavior on overflow while GROUP BY operation. Possible values:
	// Sets behavior on overflow while GROUP BY operation. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// * `any` - perform approximate GROUP BY operation by continuing aggregation for the keys that got into the set, but don’t add new keys to the set.
	// +kubebuilder:validation:Optional
	GroupByOverflowMode *string `json:"groupByOverflowMode,omitempty" tf:"group_by_overflow_mode,omitempty"`

	// level aggregation should be used.
	// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
	// +kubebuilder:validation:Optional
	GroupByTwoLevelThreshold *float64 `json:"groupByTwoLevelThreshold,omitempty" tf:"group_by_two_level_threshold,omitempty"`

	// level aggregation should be used.
	// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
	// +kubebuilder:validation:Optional
	GroupByTwoLevelThresholdBytes *float64 `json:"groupByTwoLevelThresholdBytes,omitempty" tf:"group_by_two_level_threshold_bytes,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	// +kubebuilder:validation:Optional
	HTTPConnectionTimeout *float64 `json:"httpConnectionTimeout,omitempty" tf:"http_connection_timeout,omitempty"`

	// ClickHouse-Progress.
	// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
	// +kubebuilder:validation:Optional
	HTTPHeadersProgressInterval *float64 `json:"httpHeadersProgressInterval,omitempty" tf:"http_headers_progress_interval,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	// +kubebuilder:validation:Optional
	HTTPReceiveTimeout *float64 `json:"httpReceiveTimeout,omitempty" tf:"http_receive_timeout,omitempty"`

	// (Number) Timeout for HTTP connection in milliseconds.
	// Timeout for HTTP connection in milliseconds.
	// +kubebuilder:validation:Optional
	HTTPSendTimeout *float64 `json:"httpSendTimeout,omitempty" tf:"http_send_timeout,omitempty"`

	// (Number) Connection timeout for establishing connection with replica for Hedged requests. Default value: 50 milliseconds.
	// Connection timeout for establishing connection with replica for Hedged requests. Default value: 50 milliseconds.
	// +kubebuilder:validation:Optional
	HedgedConnectionTimeoutMs *float64 `json:"hedgedConnectionTimeoutMs,omitempty" tf:"hedged_connection_timeout_ms,omitempty"`

	// (Number) Timeout to close idle TCP connections after specified number of seconds. Default value: 3600 seconds.
	// Timeout to close idle TCP connections after specified number of seconds. Default value: 3600 seconds.
	// +kubebuilder:validation:Optional
	IdleConnectionTimeout *float64 `json:"idleConnectionTimeout,omitempty" tf:"idle_connection_timeout,omitempty"`

	// (Boolean) When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	// +kubebuilder:validation:Optional
	InputFormatDefaultsForOmittedFields *bool `json:"inputFormatDefaultsForOmittedFields,omitempty" tf:"input_format_defaults_for_omitted_fields,omitempty"`

	// (Boolean) Enables or disables the insertion of JSON data with nested objects.
	// Enables or disables the insertion of JSON data with nested objects.
	// +kubebuilder:validation:Optional
	InputFormatImportNestedJSON *bool `json:"inputFormatImportNestedJson,omitempty" tf:"input_format_import_nested_json,omitempty"`

	// (Boolean) Enables or disables the initialization of NULL fields with default values, if data type of these fields is not nullable.
	// Enables or disables the initialization of NULL fields with default values, if data type of these fields is not nullable.
	// +kubebuilder:validation:Optional
	InputFormatNullAsDefault *bool `json:"inputFormatNullAsDefault,omitempty" tf:"input_format_null_as_default,omitempty"`

	// preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	// Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	// +kubebuilder:validation:Optional
	InputFormatParallelParsing *bool `json:"inputFormatParallelParsing,omitempty" tf:"input_format_parallel_parsing,omitempty"`

	// (Boolean) Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	// +kubebuilder:validation:Optional
	InputFormatValuesInterpretExpressions *bool `json:"inputFormatValuesInterpretExpressions,omitempty" tf:"input_format_values_interpret_expressions,omitempty"`

	// (Boolean) Enables or disables checking the column order when inserting data.
	// Enables or disables checking the column order when inserting data.
	// +kubebuilder:validation:Optional
	InputFormatWithNamesUseHeader *bool `json:"inputFormatWithNamesUseHeader,omitempty" tf:"input_format_with_names_use_header,omitempty"`

	// (Number) The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	// The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	// +kubebuilder:validation:Optional
	InsertKeeperMaxRetries *float64 `json:"insertKeeperMaxRetries,omitempty" tf:"insert_keeper_max_retries,omitempty"`

	// (Boolean) Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	// Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	// +kubebuilder:validation:Optional
	InsertNullAsDefault *bool `json:"insertNullAsDefault,omitempty" tf:"insert_null_as_default,omitempty"`

	// (Number) Enables the quorum writes.
	// Enables the quorum writes.
	// +kubebuilder:validation:Optional
	InsertQuorum *float64 `json:"insertQuorum,omitempty" tf:"insert_quorum,omitempty"`

	// (Boolean) Enables or disables parallelism for quorum INSERT queries.
	// Enables or disables parallelism for quorum INSERT queries.
	// +kubebuilder:validation:Optional
	InsertQuorumParallel *bool `json:"insertQuorumParallel,omitempty" tf:"insert_quorum_parallel,omitempty"`

	// (Number) Write to a quorum timeout in milliseconds.
	// Write to a quorum timeout in milliseconds.
	// +kubebuilder:validation:Optional
	InsertQuorumTimeout *float64 `json:"insertQuorumTimeout,omitempty" tf:"insert_quorum_timeout,omitempty"`

	// (List of String) Specifies which JOIN algorithm is used. Possible values:
	// Specifies which JOIN algorithm is used. Possible values:
	// * `hash` - hash join algorithm is used. The most generic implementation that supports all combinations of kind and strictness and multiple join keys that are combined with OR in the JOIN ON section.
	// * `parallel_hash` - a variation of hash join that splits the data into buckets and builds several hash tables instead of one concurrently to speed up this process.
	// * `partial_merge` - a variation of the sort-merge algorithm, where only the right table is fully sorted.
	// * `direct` - this algorithm can be applied when the storage for the right table supports key-value requests.
	// * `auto` - when set to auto, hash join is tried first, and the algorithm is switched on the fly to another algorithm if the memory limit is violated.
	// * `full_sorting_merge` - sort-merge algorithm with full sorting joined tables before joining.
	// * `prefer_partial_merge` - clickHouse always tries to use partial_merge join if possible, otherwise, it uses hash. Deprecated, same as partial_merge,hash.
	// +kubebuilder:validation:Optional
	JoinAlgorithm []*string `json:"joinAlgorithm,omitempty" tf:"join_algorithm,omitempty"`

	// (String) Sets behavior on overflow in JOIN. Possible values:
	// Sets behavior on overflow in JOIN. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	JoinOverflowMode *string `json:"joinOverflowMode,omitempty" tf:"join_overflow_mode,omitempty"`

	// (Boolean) Sets the type of JOIN behavior. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	// Sets the type of JOIN behavior. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	// +kubebuilder:validation:Optional
	JoinUseNulls *bool `json:"joinUseNulls,omitempty" tf:"join_use_nulls,omitempty"`

	// (Boolean) Require aliases for subselects and table functions in FROM that more than one table is present.
	// Require aliases for subselects and table functions in FROM that more than one table is present.
	// +kubebuilder:validation:Optional
	JoinedSubqueryRequiresAlias *bool `json:"joinedSubqueryRequiresAlias,omitempty" tf:"joined_subquery_requires_alias,omitempty"`

	// (String) Specifies the algorithm of replicas selection that is used for distributed query processing, one of: random, nearest_hostname, in_order, first_or_random, round_robin. Default value: random.
	// Specifies the algorithm of replicas selection that is used for distributed query processing, one of: random, nearest_hostname, in_order, first_or_random, round_robin. Default value: random.
	// +kubebuilder:validation:Optional
	LoadBalancing *string `json:"loadBalancing,omitempty" tf:"load_balancing,omitempty"`

	// (String) Method of reading data from local filesystem. Possible values:
	// Method of reading data from local filesystem. Possible values:
	// * `read` - abort query execution, return an error.
	// * `pread` - abort query execution, return an error.
	// * `pread_threadpool` - stop query execution, return partial result. If the parameter is set to 0 (default), no hops is allowed.
	// +kubebuilder:validation:Optional
	LocalFilesystemReadMethod *string `json:"localFilesystemReadMethod,omitempty" tf:"local_filesystem_read_method,omitempty"`

	// (Boolean) Setting up query threads logging. Query threads log into the system.query_thread_log table. This setting has effect only when log_queries is true. Queries’ threads run by ClickHouse with this setup are logged according to the rules in the query_thread_log server configuration parameter. Default value: true.
	// Setting up query threads logging. Query threads log into the system.query_thread_log table. This setting has effect only when log_queries is true. Queries’ threads run by ClickHouse with this setup are logged according to the rules in the query_thread_log server configuration parameter. Default value: `true`.
	// +kubebuilder:validation:Optional
	LogQueryThreads *bool `json:"logQueryThreads,omitempty" tf:"log_query_threads,omitempty"`

	// (Boolean) Allows or restricts using the LowCardinality data type with the Native format.
	// Allows or restricts using the LowCardinality data type with the Native format.
	// +kubebuilder:validation:Optional
	LowCardinalityAllowInNativeFormat *bool `json:"lowCardinalityAllowInNativeFormat,omitempty" tf:"low_cardinality_allow_in_native_format,omitempty"`

	// (Number) Maximum abstract syntax tree depth.
	// Maximum abstract syntax tree depth.
	// +kubebuilder:validation:Optional
	MaxAstDepth *float64 `json:"maxAstDepth,omitempty" tf:"max_ast_depth,omitempty"`

	// (Number) Maximum abstract syntax tree elements.
	// Maximum abstract syntax tree elements.
	// +kubebuilder:validation:Optional
	MaxAstElements *float64 `json:"maxAstElements,omitempty" tf:"max_ast_elements,omitempty"`

	// (Number) A recommendation for what size of the block (in a count of rows) to load from tables.
	// A recommendation for what size of the block (in a count of rows) to load from tables.
	// +kubebuilder:validation:Optional
	MaxBlockSize *float64 `json:"maxBlockSize,omitempty" tf:"max_block_size,omitempty"`

	// (Number) Limit in bytes for using memory for GROUP BY before using swap on disk.
	// Limit in bytes for using memory for GROUP BY before using swap on disk.
	// +kubebuilder:validation:Optional
	MaxBytesBeforeExternalGroupBy *float64 `json:"maxBytesBeforeExternalGroupBy,omitempty" tf:"max_bytes_before_external_group_by,omitempty"`

	// (Number) This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	// +kubebuilder:validation:Optional
	MaxBytesBeforeExternalSort *float64 `json:"maxBytesBeforeExternalSort,omitempty" tf:"max_bytes_before_external_sort,omitempty"`

	// (Number) Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	// +kubebuilder:validation:Optional
	MaxBytesInDistinct *float64 `json:"maxBytesInDistinct,omitempty" tf:"max_bytes_in_distinct,omitempty"`

	// (Number) Limit on maximum size of the hash table for JOIN, in bytes.
	// Limit on maximum size of the hash table for JOIN, in bytes.
	// +kubebuilder:validation:Optional
	MaxBytesInJoin *float64 `json:"maxBytesInJoin,omitempty" tf:"max_bytes_in_join,omitempty"`

	// (Number) Limit on the number of bytes in the set resulting from the execution of the IN section.
	// Limit on the number of bytes in the set resulting from the execution of the IN section.
	// +kubebuilder:validation:Optional
	MaxBytesInSet *float64 `json:"maxBytesInSet,omitempty" tf:"max_bytes_in_set,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	// +kubebuilder:validation:Optional
	MaxBytesToRead *float64 `json:"maxBytesToRead,omitempty" tf:"max_bytes_to_read,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	// +kubebuilder:validation:Optional
	MaxBytesToSort *float64 `json:"maxBytesToSort,omitempty" tf:"max_bytes_to_sort,omitempty"`

	// (Number) Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// +kubebuilder:validation:Optional
	MaxBytesToTransfer *float64 `json:"maxBytesToTransfer,omitempty" tf:"max_bytes_to_transfer,omitempty"`

	// (Number) Limits the maximum number of columns that can be read from a table in a single query.
	// Limits the maximum number of columns that can be read from a table in a single query.
	// +kubebuilder:validation:Optional
	MaxColumnsToRead *float64 `json:"maxColumnsToRead,omitempty" tf:"max_columns_to_read,omitempty"`

	// (Number) The maximum number of concurrent requests per user. Default value: 0 (no limit).
	// The maximum number of concurrent requests per user. Default value: 0 (no limit).
	// +kubebuilder:validation:Optional
	MaxConcurrentQueriesForUser *float64 `json:"maxConcurrentQueriesForUser,omitempty" tf:"max_concurrent_queries_for_user,omitempty"`

	// (Number) Limits the maximum query execution time in milliseconds.
	// Limits the maximum query execution time in milliseconds.
	// +kubebuilder:validation:Optional
	MaxExecutionTime *float64 `json:"maxExecutionTime,omitempty" tf:"max_execution_time,omitempty"`

	// (Number) Maximum abstract syntax tree depth after after expansion of aliases.
	// Maximum abstract syntax tree depth after after expansion of aliases.
	// +kubebuilder:validation:Optional
	MaxExpandedAstElements *float64 `json:"maxExpandedAstElements,omitempty" tf:"max_expanded_ast_elements,omitempty"`

	// (Number) Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	// Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	// +kubebuilder:validation:Optional
	MaxFinalThreads *float64 `json:"maxFinalThreads,omitempty" tf:"max_final_threads,omitempty"`

	// engine tables.
	// Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
	// +kubebuilder:validation:Optional
	MaxHTTPGetRedirects *float64 `json:"maxHttpGetRedirects,omitempty" tf:"max_http_get_redirects,omitempty"`

	// (Number) The size of blocks (in a count of rows) to form for insertion into a table.
	// The size of blocks (in a count of rows) to form for insertion into a table.
	// +kubebuilder:validation:Optional
	MaxInsertBlockSize *float64 `json:"maxInsertBlockSize,omitempty" tf:"max_insert_block_size,omitempty"`

	// (Number) The maximum number of threads to execute the INSERT SELECT query. Default value: 0.
	// The maximum number of threads to execute the INSERT SELECT query. Default value: 0.
	// +kubebuilder:validation:Optional
	MaxInsertThreads *float64 `json:"maxInsertThreads,omitempty" tf:"max_insert_threads,omitempty"`

	// (Number) Limits the maximum memory usage (in bytes) for processing queries on a single server.
	// Limits the maximum memory usage (in bytes) for processing queries on a single server.
	// +kubebuilder:validation:Optional
	MaxMemoryUsage *float64 `json:"maxMemoryUsage,omitempty" tf:"max_memory_usage,omitempty"`

	// (Number) Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	// +kubebuilder:validation:Optional
	MaxMemoryUsageForUser *float64 `json:"maxMemoryUsageForUser,omitempty" tf:"max_memory_usage_for_user,omitempty"`

	// (Number) Limits the speed of the data exchange over the network in bytes per second.
	// Limits the speed of the data exchange over the network in bytes per second.
	// +kubebuilder:validation:Optional
	MaxNetworkBandwidth *float64 `json:"maxNetworkBandwidth,omitempty" tf:"max_network_bandwidth,omitempty"`

	// (Number) Limits the speed of the data exchange over the network in bytes per second.
	// Limits the speed of the data exchange over the network in bytes per second.
	// +kubebuilder:validation:Optional
	MaxNetworkBandwidthForUser *float64 `json:"maxNetworkBandwidthForUser,omitempty" tf:"max_network_bandwidth_for_user,omitempty"`

	// (Number) Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	// Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	// +kubebuilder:validation:Optional
	MaxParserDepth *float64 `json:"maxParserDepth,omitempty" tf:"max_parser_depth,omitempty"`

	// (Number) The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	// +kubebuilder:validation:Optional
	MaxQuerySize *float64 `json:"maxQuerySize,omitempty" tf:"max_query_size,omitempty"`

	// (Number) The maximum size of the buffer to read from the filesystem.
	// The maximum size of the buffer to read from the filesystem.
	// +kubebuilder:validation:Optional
	MaxReadBufferSize *float64 `json:"maxReadBufferSize,omitempty" tf:"max_read_buffer_size,omitempty"`

	// (Number) Disables lagging replicas for distributed queries.
	// Disables lagging replicas for distributed queries.
	// +kubebuilder:validation:Optional
	MaxReplicaDelayForDistributedQueries *float64 `json:"maxReplicaDelayForDistributedQueries,omitempty" tf:"max_replica_delay_for_distributed_queries,omitempty"`

	// (Number) Limits the number of bytes in the result.
	// Limits the number of bytes in the result.
	// +kubebuilder:validation:Optional
	MaxResultBytes *float64 `json:"maxResultBytes,omitempty" tf:"max_result_bytes,omitempty"`

	// (Number) Limits the number of rows in the result.
	// Limits the number of rows in the result.
	// +kubebuilder:validation:Optional
	MaxResultRows *float64 `json:"maxResultRows,omitempty" tf:"max_result_rows,omitempty"`

	// (Number) Limits the maximum number of different rows when using DISTINCT.
	// Limits the maximum number of different rows when using DISTINCT.
	// +kubebuilder:validation:Optional
	MaxRowsInDistinct *float64 `json:"maxRowsInDistinct,omitempty" tf:"max_rows_in_distinct,omitempty"`

	// (Number) Limit on maximum size of the hash table for JOIN, in rows.
	// Limit on maximum size of the hash table for JOIN, in rows.
	// +kubebuilder:validation:Optional
	MaxRowsInJoin *float64 `json:"maxRowsInJoin,omitempty" tf:"max_rows_in_join,omitempty"`

	// (Number) Limit on the number of rows in the set resulting from the execution of the IN section.
	// Limit on the number of rows in the set resulting from the execution of the IN section.
	// +kubebuilder:validation:Optional
	MaxRowsInSet *float64 `json:"maxRowsInSet,omitempty" tf:"max_rows_in_set,omitempty"`

	// (Number) Limits the maximum number of unique keys received from aggregation function.
	// Limits the maximum number of unique keys received from aggregation function.
	// +kubebuilder:validation:Optional
	MaxRowsToGroupBy *float64 `json:"maxRowsToGroupBy,omitempty" tf:"max_rows_to_group_by,omitempty"`

	// (Number) Limits the maximum number of rows that can be read from a table when running a query.
	// Limits the maximum number of rows that can be read from a table when running a query.
	// +kubebuilder:validation:Optional
	MaxRowsToRead *float64 `json:"maxRowsToRead,omitempty" tf:"max_rows_to_read,omitempty"`

	// (Number) Limits the maximum number of rows that can be read from a table for sorting.
	// Limits the maximum number of rows that can be read from a table for sorting.
	// +kubebuilder:validation:Optional
	MaxRowsToSort *float64 `json:"maxRowsToSort,omitempty" tf:"max_rows_to_sort,omitempty"`

	// (Number) Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// +kubebuilder:validation:Optional
	MaxRowsToTransfer *float64 `json:"maxRowsToTransfer,omitempty" tf:"max_rows_to_transfer,omitempty"`

	// (Number) Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	// +kubebuilder:validation:Optional
	MaxTemporaryColumns *float64 `json:"maxTemporaryColumns,omitempty" tf:"max_temporary_columns,omitempty"`

	// (Number) The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	// +kubebuilder:validation:Optional
	MaxTemporaryDataOnDiskSizeForQuery *float64 `json:"maxTemporaryDataOnDiskSizeForQuery,omitempty" tf:"max_temporary_data_on_disk_size_for_query,omitempty"`

	// (Number) The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	// +kubebuilder:validation:Optional
	MaxTemporaryDataOnDiskSizeForUser *float64 `json:"maxTemporaryDataOnDiskSizeForUser,omitempty" tf:"max_temporary_data_on_disk_size_for_user,omitempty"`

	// (Number) Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	// +kubebuilder:validation:Optional
	MaxTemporaryNonConstColumns *float64 `json:"maxTemporaryNonConstColumns,omitempty" tf:"max_temporary_non_const_columns,omitempty"`

	// (Number) The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	// +kubebuilder:validation:Optional
	MaxThreads *float64 `json:"maxThreads,omitempty" tf:"max_threads,omitempty"`

	// (Number) It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// +kubebuilder:validation:Optional
	MemoryOvercommitRatioDenominator *float64 `json:"memoryOvercommitRatioDenominator,omitempty" tf:"memory_overcommit_ratio_denominator,omitempty"`

	// (Number) It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// +kubebuilder:validation:Optional
	MemoryOvercommitRatioDenominatorForUser *float64 `json:"memoryOvercommitRatioDenominatorForUser,omitempty" tf:"memory_overcommit_ratio_denominator_for_user,omitempty"`

	// (Number) Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	// Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	// +kubebuilder:validation:Optional
	MemoryProfilerSampleProbability *float64 `json:"memoryProfilerSampleProbability,omitempty" tf:"memory_profiler_sample_probability,omitempty"`

	// (Number) Memory profiler step (in bytes). If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	// Memory profiler step (in bytes). If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	// +kubebuilder:validation:Optional
	MemoryProfilerStep *float64 `json:"memoryProfilerStep,omitempty" tf:"memory_profiler_step,omitempty"`

	// (Number) Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	// Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	// +kubebuilder:validation:Optional
	MemoryUsageOvercommitMaxWaitMicroseconds *float64 `json:"memoryUsageOvercommitMaxWaitMicroseconds,omitempty" tf:"memory_usage_overcommit_max_wait_microseconds,omitempty"`

	// (Number) If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	// +kubebuilder:validation:Optional
	MergeTreeMaxBytesToUseCache *float64 `json:"mergeTreeMaxBytesToUseCache,omitempty" tf:"merge_tree_max_bytes_to_use_cache,omitempty"`

	// (Number) If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	// +kubebuilder:validation:Optional
	MergeTreeMaxRowsToUseCache *float64 `json:"mergeTreeMaxRowsToUseCache,omitempty" tf:"merge_tree_max_rows_to_use_cache,omitempty"`

	// engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	// +kubebuilder:validation:Optional
	MergeTreeMinBytesForConcurrentRead *float64 `json:"mergeTreeMinBytesForConcurrentRead,omitempty" tf:"merge_tree_min_bytes_for_concurrent_read,omitempty"`

	// (Number) If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	// +kubebuilder:validation:Optional
	MergeTreeMinRowsForConcurrentRead *float64 `json:"mergeTreeMinRowsForConcurrentRead,omitempty" tf:"merge_tree_min_rows_for_concurrent_read,omitempty"`

	// (Number) The minimum data volume required for using direct I/O access to the storage disk.
	// The minimum data volume required for using direct I/O access to the storage disk.
	// +kubebuilder:validation:Optional
	MinBytesToUseDirectIo *float64 `json:"minBytesToUseDirectIo,omitempty" tf:"min_bytes_to_use_direct_io,omitempty"`

	// (Number) How many times to potentially use a compiled chunk of code before running compilation.
	// How many times to potentially use a compiled chunk of code before running compilation.
	// +kubebuilder:validation:Optional
	MinCountToCompile *float64 `json:"minCountToCompile,omitempty" tf:"min_count_to_compile,omitempty"`

	// (Number) A query waits for expression compilation process to complete prior to continuing execution.
	// A query waits for expression compilation process to complete prior to continuing execution.
	// +kubebuilder:validation:Optional
	MinCountToCompileExpression *float64 `json:"minCountToCompileExpression,omitempty" tf:"min_count_to_compile_expression,omitempty"`

	// (Number) Minimal execution speed in rows per second.
	// Minimal execution speed in rows per second.
	// +kubebuilder:validation:Optional
	MinExecutionSpeed *float64 `json:"minExecutionSpeed,omitempty" tf:"min_execution_speed,omitempty"`

	// (Number) Minimal execution speed in bytes per second.
	// Minimal execution speed in bytes per second.
	// +kubebuilder:validation:Optional
	MinExecutionSpeedBytes *float64 `json:"minExecutionSpeedBytes,omitempty" tf:"min_execution_speed_bytes,omitempty"`

	// (Number) Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	// +kubebuilder:validation:Optional
	MinInsertBlockSizeBytes *float64 `json:"minInsertBlockSizeBytes,omitempty" tf:"min_insert_block_size_bytes,omitempty"`

	// (Number) Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	// +kubebuilder:validation:Optional
	MinInsertBlockSizeRows *float64 `json:"minInsertBlockSizeRows,omitempty" tf:"min_insert_block_size_rows,omitempty"`

	// (Boolean) If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	// +kubebuilder:validation:Optional
	OutputFormatJSONQuote64BitIntegers *bool `json:"outputFormatJsonQuote64BitIntegers,omitempty" tf:"output_format_json_quote_64bit_integers,omitempty"`

	// nan, +inf, -inf outputs in JSON output format.
	// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
	// +kubebuilder:validation:Optional
	OutputFormatJSONQuoteDenormals *bool `json:"outputFormatJsonQuoteDenormals,omitempty" tf:"output_format_json_quote_denormals,omitempty"`

	// (Boolean) Enables/disables preferable using the localhost replica when processing distributed queries. Default value: true.
	// Enables/disables preferable using the localhost replica when processing distributed queries. Default value: true.
	// +kubebuilder:validation:Optional
	PreferLocalhostReplica *bool `json:"preferLocalhostReplica,omitempty" tf:"prefer_localhost_replica,omitempty"`

	// (Number) Query priority.
	// Query priority.
	// +kubebuilder:validation:Optional
	Priority *float64 `json:"priority,omitempty" tf:"priority,omitempty"`

	// (String) Quota accounting mode.
	// Quota accounting mode.
	// +kubebuilder:validation:Optional
	QuotaMode *string `json:"quotaMode,omitempty" tf:"quota_mode,omitempty"`

	// (String) Sets behavior on overflow while read. Possible values:
	// Sets behavior on overflow while read. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	ReadOverflowMode *string `json:"readOverflowMode,omitempty" tf:"read_overflow_mode,omitempty"`

	// (Number) Restricts permissions for reading data, write data and change settings queries.
	// Restricts permissions for reading data, write data and change settings queries.
	// +kubebuilder:validation:Optional
	Readonly *float64 `json:"readonly,omitempty" tf:"readonly,omitempty"`

	// (Number) Receive timeout in milliseconds on the socket used for communicating with the client.
	// Receive timeout in milliseconds on the socket used for communicating with the client.
	// +kubebuilder:validation:Optional
	ReceiveTimeout *float64 `json:"receiveTimeout,omitempty" tf:"receive_timeout,omitempty"`

	// (String) Method of reading data from remote filesystem, one of: read, threadpool.
	// Method of reading data from remote filesystem, one of: `read`, `threadpool`.
	// +kubebuilder:validation:Optional
	RemoteFilesystemReadMethod *string `json:"remoteFilesystemReadMethod,omitempty" tf:"remote_filesystem_read_method,omitempty"`

	// (Number) For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	// +kubebuilder:validation:Optional
	ReplicationAlterPartitionsSync *float64 `json:"replicationAlterPartitionsSync,omitempty" tf:"replication_alter_partitions_sync,omitempty"`

	// (String) Sets behavior on overflow in result. Possible values:
	// Sets behavior on overflow in result. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	ResultOverflowMode *string `json:"resultOverflowMode,omitempty" tf:"result_overflow_mode,omitempty"`

	// (Boolean) Enables or disables sequential consistency for SELECT queries.
	// Enables or disables sequential consistency for SELECT queries.
	// +kubebuilder:validation:Optional
	SelectSequentialConsistency *bool `json:"selectSequentialConsistency,omitempty" tf:"select_sequential_consistency,omitempty"`

	// ClickHouse-Progress HTTP response headers in clickhouse-server responses.
	// Enables or disables `X-ClickHouse-Progress` HTTP response headers in clickhouse-server responses.
	// +kubebuilder:validation:Optional
	SendProgressInHTTPHeaders *bool `json:"sendProgressInHttpHeaders,omitempty" tf:"send_progress_in_http_headers,omitempty"`

	// (Number) Send timeout in milliseconds on the socket used for communicating with the client.
	// Send timeout in milliseconds on the socket used for communicating with the client.
	// +kubebuilder:validation:Optional
	SendTimeout *float64 `json:"sendTimeout,omitempty" tf:"send_timeout,omitempty"`

	// (String) Sets behavior on overflow in the set resulting. Possible values:
	// Sets behavior on overflow in the set resulting. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	SetOverflowMode *string `json:"setOverflowMode,omitempty" tf:"set_overflow_mode,omitempty"`

	// (Boolean) Enables or disables silently skipping of unavailable shards.
	// Enables or disables silently skipping of unavailable shards.
	// +kubebuilder:validation:Optional
	SkipUnavailableShards *bool `json:"skipUnavailableShards,omitempty" tf:"skip_unavailable_shards,omitempty"`

	// (String) Sets behavior on overflow while sort. Possible values:
	// Sets behavior on overflow while sort. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	SortOverflowMode *string `json:"sortOverflowMode,omitempty" tf:"sort_overflow_mode,omitempty"`

	// (Number) Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter. Must be at least 1000.
	// Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter. Must be at least 1000.
	// +kubebuilder:validation:Optional
	TimeoutBeforeCheckingExecutionSpeed *float64 `json:"timeoutBeforeCheckingExecutionSpeed,omitempty" tf:"timeout_before_checking_execution_speed,omitempty"`

	// (String) Sets behavior on overflow. Possible values:
	// Sets behavior on overflow. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	TimeoutOverflowMode *string `json:"timeoutOverflowMode,omitempty" tf:"timeout_overflow_mode,omitempty"`

	// (String) Sets behavior on overflow. Possible values:
	// Sets behavior on overflow. Possible values:
	// * `throw` - abort query execution, return an error.
	// * `break` - stop query execution, return partial result.
	// +kubebuilder:validation:Optional
	TransferOverflowMode *string `json:"transferOverflowMode,omitempty" tf:"transfer_overflow_mode,omitempty"`

	// (Boolean) Enables equality of NULL values for IN operator.
	// Enables equality of NULL values for IN operator.
	// +kubebuilder:validation:Optional
	TransformNullIn *bool `json:"transformNullIn,omitempty" tf:"transform_null_in,omitempty"`

	// (Boolean) Enables hedged requests logic for remote queries. It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within hedged_connection_timeout or no data was received within receive_data_timeout. Query uses the first connection which send non empty progress packet (or data packet, if allow_changing_replica_until_first_data_packet); other connections are cancelled. Queries with max_parallel_replicas > 1 are supported. Default value: true.
	// Enables hedged requests logic for remote queries. It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within hedged_connection_timeout or no data was received within receive_data_timeout. Query uses the first connection which send non empty progress packet (or data packet, if allow_changing_replica_until_first_data_packet); other connections are cancelled. Queries with max_parallel_replicas > 1 are supported. Default value: true.
	// +kubebuilder:validation:Optional
	UseHedgedRequests *bool `json:"useHedgedRequests,omitempty" tf:"use_hedged_requests,omitempty"`

	// (Boolean) Whether to use a cache of uncompressed blocks.
	// Whether to use a cache of uncompressed blocks.
	// +kubebuilder:validation:Optional
	UseUncompressedCache *bool `json:"useUncompressedCache,omitempty" tf:"use_uncompressed_cache,omitempty"`

	// (Boolean) Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	// Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	// +kubebuilder:validation:Optional
	WaitForAsyncInsert *bool `json:"waitForAsyncInsert,omitempty" tf:"wait_for_async_insert,omitempty"`

	// (Number) The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	// The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	// +kubebuilder:validation:Optional
	WaitForAsyncInsertTimeout *float64 `json:"waitForAsyncInsertTimeout,omitempty" tf:"wait_for_async_insert_timeout,omitempty"`
}

type ZookeeperInitParameters struct {

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to hosts of the ZooKeeper subcluster.
	Resources []ZookeeperResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ZookeeperObservation struct {

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to hosts of the ZooKeeper subcluster.
	Resources []ZookeeperResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ZookeeperParameters struct {

	// (Block List, Max: 1) Resources allocated to hosts of the ClickHouse subcluster. (see below for nested schema)
	// Resources allocated to hosts of the ZooKeeper subcluster.
	// +kubebuilder:validation:Optional
	Resources []ZookeeperResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ZookeeperResourcesInitParameters struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ZooKeeper hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ZooKeeper host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ZookeeperResourcesObservation struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ZooKeeper hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ZooKeeper host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ZookeeperResourcesParameters struct {

	// (Number) Volume of the storage available to a ClickHouse host, in gigabytes.
	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of ClickHouse hosts. For more information see the official documentation.
	// Type of the storage of ZooKeeper hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a ClickHouse host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a ZooKeeper host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

// ClickhouseClusterSpec defines the desired state of ClickhouseCluster
type ClickhouseClusterSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     ClickhouseClusterParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider ClickhouseClusterInitParameters `json:"initProvider,omitempty"`
}

// ClickhouseClusterStatus defines the observed state of ClickhouseCluster.
type ClickhouseClusterStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        ClickhouseClusterObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// ClickhouseCluster is the Schema for the ClickhouseClusters API. Manages a ClickHouse cluster within Yandex Cloud.
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,yandex-cloud}
type ClickhouseCluster struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.environment) || (has(self.initProvider) && has(self.initProvider.environment))",message="spec.forProvider.environment is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.host) || (has(self.initProvider) && has(self.initProvider.host))",message="spec.forProvider.host is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	Spec   ClickhouseClusterSpec   `json:"spec"`
	Status ClickhouseClusterStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// ClickhouseClusterList contains a list of ClickhouseClusters
type ClickhouseClusterList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []ClickhouseCluster `json:"items"`
}

// Repository type metadata.
var (
	ClickhouseCluster_Kind             = "ClickhouseCluster"
	ClickhouseCluster_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: ClickhouseCluster_Kind}.String()
	ClickhouseCluster_KindAPIVersion   = ClickhouseCluster_Kind + "." + CRDGroupVersion.String()
	ClickhouseCluster_GroupVersionKind = CRDGroupVersion.WithKind(ClickhouseCluster_Kind)
)

func init() {
	SchemeBuilder.Register(&ClickhouseCluster{}, &ClickhouseClusterList{})
}
