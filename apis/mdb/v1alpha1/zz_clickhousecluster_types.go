/*
Copyright 2022 YANDEX LLC
This is modified version of the software, made by the Crossplane Authors
and available at: https://github.com/crossplane-contrib/provider-jet-template

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AccessInitParameters struct {

	// Allow access for DataLens. Can be either true or false.
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// Allow access for DataTransfer. Can be either true or false.
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// Allow access for Yandex.Metrika. Can be either true or false.
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// Allow access for Serverless. Can be either true or false.
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// Allow access for Web SQL. Can be either true or false.
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// Allow access for YandexQuery. Can be either true or false.
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type AccessObservation struct {

	// Allow access for DataLens. Can be either true or false.
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// Allow access for DataTransfer. Can be either true or false.
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// Allow access for Yandex.Metrika. Can be either true or false.
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// Allow access for Serverless. Can be either true or false.
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// Allow access for Web SQL. Can be either true or false.
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// Allow access for YandexQuery. Can be either true or false.
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type AccessParameters struct {

	// Allow access for DataLens. Can be either true or false.
	// +kubebuilder:validation:Optional
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// Allow access for DataTransfer. Can be either true or false.
	// +kubebuilder:validation:Optional
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// Allow access for Yandex.Metrika. Can be either true or false.
	// +kubebuilder:validation:Optional
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// Allow access for Serverless. Can be either true or false.
	// +kubebuilder:validation:Optional
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// Allow access for Web SQL. Can be either true or false.
	// +kubebuilder:validation:Optional
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// Allow access for YandexQuery. Can be either true or false.
	// +kubebuilder:validation:Optional
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type BackupWindowStartInitParameters struct {

	// The hour at which backup will be started.
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// The minute at which backup will be started.
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type BackupWindowStartObservation struct {

	// The hour at which backup will be started.
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// The minute at which backup will be started.
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type BackupWindowStartParameters struct {

	// The hour at which backup will be started.
	// +kubebuilder:validation:Optional
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// The minute at which backup will be started.
	// +kubebuilder:validation:Optional
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type ClickhouseClusterInitParameters struct {

	// Access policy to the ClickHouse cluster. The structure is documented below.
	Access []AccessInitParameters `json:"access,omitempty" tf:"access,omitempty"`

	// Time to start the daily backup, in the UTC timezone. The structure is documented below.
	BackupWindowStart []BackupWindowStartInitParameters `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// Configuration of the ClickHouse subcluster. The structure is documented below.
	Clickhouse []ClickhouseInitParameters `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// Minimum data age in seconds.
	CloudStorage []CloudStorageInitParameters `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// Whether to copy schema on new ClickHouse hosts.
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// A database of the ClickHouse cluster. The structure is documented below.
	Database []DatabaseInitParameters `json:"database,omitempty" tf:"database,omitempty"`

	// Inhibits deletion of the cluster.  Can be either true or false.
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// Description of the ClickHouse cluster.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// Deployment environment of the ClickHouse cluster. Can be either PRESTABLE or PRODUCTION.
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// The ID of the folder that the resource belongs to. If it
	// is not provided, the default provider folder is used.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/resourcemanager/v1alpha1.Folder
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// Reference to a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDRef *v1.Reference `json:"folderIdRef,omitempty" tf:"-"`

	// Selector for a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDSelector *v1.Selector `json:"folderIdSelector,omitempty" tf:"-"`

	// A set of protobuf or capnproto format schemas. The structure is documented below.
	FormatSchema []FormatSchemaInitParameters `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// A host of the ClickHouse cluster. The structure is documented below.
	Host []HostInitParameters `json:"host,omitempty" tf:"host,omitempty"`

	// A set of key/value label pairs to assign to the ClickHouse cluster.
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// A group of machine learning models. The structure is documented below
	MLModel []MLModelInitParameters `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	MaintenanceWindow []MaintenanceWindowInitParameters `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// ID of the network, to which the ClickHouse cluster belongs.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Network
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Reference to a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDRef *v1.Reference `json:"networkIdRef,omitempty" tf:"-"`

	// Selector for a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDSelector *v1.Selector `json:"networkIdSelector,omitempty" tf:"-"`

	// Grants admin user database management permission.
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// Enables admin user with user management permission.
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// A set of ids of security groups assigned to hosts of the cluster.
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// ID of the service account used for access to Yandex Object Storage.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/iam/v1alpha1.ServiceAccount
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// Reference to a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDRef *v1.Reference `json:"serviceAccountIdRef,omitempty" tf:"-"`

	// Selector for a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDSelector *v1.Selector `json:"serviceAccountIdSelector,omitempty" tf:"-"`

	Shard []ShardInitParameters `json:"shard,omitempty" tf:"shard,omitempty"`

	// A group of clickhouse shards. The structure is documented below.
	ShardGroup []ShardGroupInitParameters `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// A user of the ClickHouse cluster. The structure is documented below.
	User []UserInitParameters `json:"user,omitempty" tf:"user,omitempty"`

	// Version of the ClickHouse server software.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// Configuration of the ZooKeeper subcluster. The structure is documented below.
	Zookeeper []ZookeeperInitParameters `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterObservation struct {

	// Access policy to the ClickHouse cluster. The structure is documented below.
	Access []AccessObservation `json:"access,omitempty" tf:"access,omitempty"`

	// Time to start the daily backup, in the UTC timezone. The structure is documented below.
	BackupWindowStart []BackupWindowStartObservation `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// Configuration of the ClickHouse subcluster. The structure is documented below.
	Clickhouse []ClickhouseObservation `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// Minimum data age in seconds.
	CloudStorage []CloudStorageObservation `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// Whether to copy schema on new ClickHouse hosts.
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// Timestamp of cluster creation.
	CreatedAt *string `json:"createdAt,omitempty" tf:"created_at,omitempty"`

	// A database of the ClickHouse cluster. The structure is documented below.
	Database []DatabaseObservation `json:"database,omitempty" tf:"database,omitempty"`

	// Inhibits deletion of the cluster.  Can be either true or false.
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// Description of the ClickHouse cluster.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// Deployment environment of the ClickHouse cluster. Can be either PRESTABLE or PRODUCTION.
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// The ID of the folder that the resource belongs to. If it
	// is not provided, the default provider folder is used.
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// A set of protobuf or capnproto format schemas. The structure is documented below.
	FormatSchema []FormatSchemaObservation `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// Aggregated health of the cluster. Can be ALIVE, DEGRADED, DEAD or HEALTH_UNKNOWN.
	// For more information see health field of JSON representation in the official documentation.
	Health *string `json:"health,omitempty" tf:"health,omitempty"`

	// A host of the ClickHouse cluster. The structure is documented below.
	Host []HostObservation `json:"host,omitempty" tf:"host,omitempty"`

	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// A set of key/value label pairs to assign to the ClickHouse cluster.
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// A group of machine learning models. The structure is documented below
	MLModel []MLModelObservation `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	MaintenanceWindow []MaintenanceWindowObservation `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// ID of the network, to which the ClickHouse cluster belongs.
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Grants admin user database management permission.
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// Enables admin user with user management permission.
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// A set of ids of security groups assigned to hosts of the cluster.
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// ID of the service account used for access to Yandex Object Storage.
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	Shard []ShardObservation `json:"shard,omitempty" tf:"shard,omitempty"`

	// A group of clickhouse shards. The structure is documented below.
	ShardGroup []ShardGroupObservation `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// Status of the cluster. Can be CREATING, STARTING, RUNNING, UPDATING, STOPPING, STOPPED, ERROR or STATUS_UNKNOWN.
	// For more information see status field of JSON representation in the official documentation.
	Status *string `json:"status,omitempty" tf:"status,omitempty"`

	// A user of the ClickHouse cluster. The structure is documented below.
	User []UserObservation `json:"user,omitempty" tf:"user,omitempty"`

	// Version of the ClickHouse server software.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// Configuration of the ZooKeeper subcluster. The structure is documented below.
	Zookeeper []ZookeeperObservation `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterParameters struct {

	// Access policy to the ClickHouse cluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Access []AccessParameters `json:"access,omitempty" tf:"access,omitempty"`

	// A password used to authorize as user admin when sql_user_management enabled.
	// +kubebuilder:validation:Optional
	AdminPasswordSecretRef *v1.SecretKeySelector `json:"adminPasswordSecretRef,omitempty" tf:"-"`

	// Time to start the daily backup, in the UTC timezone. The structure is documented below.
	// +kubebuilder:validation:Optional
	BackupWindowStart []BackupWindowStartParameters `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// Configuration of the ClickHouse subcluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Clickhouse []ClickhouseParameters `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// Minimum data age in seconds.
	// +kubebuilder:validation:Optional
	CloudStorage []CloudStorageParameters `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// Whether to copy schema on new ClickHouse hosts.
	// +kubebuilder:validation:Optional
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// A database of the ClickHouse cluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Database []DatabaseParameters `json:"database,omitempty" tf:"database,omitempty"`

	// Inhibits deletion of the cluster.  Can be either true or false.
	// +kubebuilder:validation:Optional
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// Description of the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.
	// +kubebuilder:validation:Optional
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// Deployment environment of the ClickHouse cluster. Can be either PRESTABLE or PRODUCTION.
	// +kubebuilder:validation:Optional
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// The ID of the folder that the resource belongs to. If it
	// is not provided, the default provider folder is used.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/resourcemanager/v1alpha1.Folder
	// +kubebuilder:validation:Optional
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// Reference to a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDRef *v1.Reference `json:"folderIdRef,omitempty" tf:"-"`

	// Selector for a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDSelector *v1.Selector `json:"folderIdSelector,omitempty" tf:"-"`

	// A set of protobuf or capnproto format schemas. The structure is documented below.
	// +kubebuilder:validation:Optional
	FormatSchema []FormatSchemaParameters `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// A host of the ClickHouse cluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Host []HostParameters `json:"host,omitempty" tf:"host,omitempty"`

	// A set of key/value label pairs to assign to the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// A group of machine learning models. The structure is documented below
	// +kubebuilder:validation:Optional
	MLModel []MLModelParameters `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// +kubebuilder:validation:Optional
	MaintenanceWindow []MaintenanceWindowParameters `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// ID of the network, to which the ClickHouse cluster belongs.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Network
	// +kubebuilder:validation:Optional
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Reference to a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDRef *v1.Reference `json:"networkIdRef,omitempty" tf:"-"`

	// Selector for a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDSelector *v1.Selector `json:"networkIdSelector,omitempty" tf:"-"`

	// Grants admin user database management permission.
	// +kubebuilder:validation:Optional
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// Enables admin user with user management permission.
	// +kubebuilder:validation:Optional
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// A set of ids of security groups assigned to hosts of the cluster.
	// +kubebuilder:validation:Optional
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// ID of the service account used for access to Yandex Object Storage.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/iam/v1alpha1.ServiceAccount
	// +kubebuilder:validation:Optional
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// Reference to a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDRef *v1.Reference `json:"serviceAccountIdRef,omitempty" tf:"-"`

	// Selector for a ServiceAccount in iam to populate serviceAccountId.
	// +kubebuilder:validation:Optional
	ServiceAccountIDSelector *v1.Selector `json:"serviceAccountIdSelector,omitempty" tf:"-"`

	// +kubebuilder:validation:Optional
	Shard []ShardParameters `json:"shard,omitempty" tf:"shard,omitempty"`

	// A group of clickhouse shards. The structure is documented below.
	// +kubebuilder:validation:Optional
	ShardGroup []ShardGroupParameters `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// A user of the ClickHouse cluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	User []UserParameters `json:"user,omitempty" tf:"user,omitempty"`

	// Version of the ClickHouse server software.
	// +kubebuilder:validation:Optional
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// Configuration of the ZooKeeper subcluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Zookeeper []ZookeeperParameters `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseInitParameters struct {

	// Main ClickHouse cluster configuration.
	Config []ConfigInitParameters `json:"config,omitempty" tf:"config,omitempty"`

	// Resources allocated to hosts of the ClickHouse subcluster. The structure is documented below.
	Resources []ResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseObservation struct {

	// Main ClickHouse cluster configuration.
	Config []ConfigObservation `json:"config,omitempty" tf:"config,omitempty"`

	// Resources allocated to hosts of the ClickHouse subcluster. The structure is documented below.
	Resources []ResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseParameters struct {

	// Main ClickHouse cluster configuration.
	// +kubebuilder:validation:Optional
	Config []ConfigParameters `json:"config,omitempty" tf:"config,omitempty"`

	// Resources allocated to hosts of the ClickHouse subcluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Resources []ResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type CloudStorageInitParameters struct {

	// Enables temporary storage in the cluster repository of data requested from the object repository.
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// Disables merging of data parts in Yandex Object Storage.
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type CloudStorageObservation struct {

	// Enables temporary storage in the cluster repository of data requested from the object repository.
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// Disables merging of data parts in Yandex Object Storage.
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type CloudStorageParameters struct {

	// Enables temporary storage in the cluster repository of data requested from the object repository.
	// +kubebuilder:validation:Optional
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// +kubebuilder:validation:Optional
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`

	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// +kubebuilder:validation:Optional
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// Disables merging of data parts in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type CompressionInitParameters struct {

	// Compression level for ZSTD method.
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// Method: Compression method. Two methods are available: LZ4 and zstd.
	Method *string `json:"method,omitempty" tf:"method,omitempty"`

	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	MinPartSize *float64 `json:"minPartSize,omitempty" tf:"min_part_size,omitempty"`

	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	MinPartSizeRatio *float64 `json:"minPartSizeRatio,omitempty" tf:"min_part_size_ratio,omitempty"`
}

type CompressionObservation struct {

	// Compression level for ZSTD method.
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// Method: Compression method. Two methods are available: LZ4 and zstd.
	Method *string `json:"method,omitempty" tf:"method,omitempty"`

	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	MinPartSize *float64 `json:"minPartSize,omitempty" tf:"min_part_size,omitempty"`

	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	MinPartSizeRatio *float64 `json:"minPartSizeRatio,omitempty" tf:"min_part_size_ratio,omitempty"`
}

type CompressionParameters struct {

	// Compression level for ZSTD method.
	// +kubebuilder:validation:Optional
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// Method: Compression method. Two methods are available: LZ4 and zstd.
	// +kubebuilder:validation:Optional
	Method *string `json:"method" tf:"method,omitempty"`

	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// +kubebuilder:validation:Optional
	MinPartSize *float64 `json:"minPartSize" tf:"min_part_size,omitempty"`

	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// +kubebuilder:validation:Optional
	MinPartSizeRatio *float64 `json:"minPartSizeRatio" tf:"min_part_size_ratio,omitempty"`
}

type ConfigInitParameters struct {
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// Data compression configuration. The structure is documented below.
	Compression []CompressionInitParameters `json:"compression,omitempty" tf:"compression,omitempty"`

	// A database of the ClickHouse cluster. The structure is documented below.
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// Graphite rollup configuration. The structure is documented below.
	GraphiteRollup []GraphiteRollupInitParameters `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// Kafka connection configuration. The structure is documented below.
	Kafka []KafkaInitParameters `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// Kafka topic connection configuration. The structure is documented below.
	KafkaTopic []KafkaTopicInitParameters `json:"kafkaTopic,omitempty" tf:"kafka_topic,omitempty"`

	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// ClickHouse server parameters. For more information, see
	// the official documentation.
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	MarkCacheSize *float64 `json:"markCacheSize,omitempty" tf:"mark_cache_size,omitempty"`

	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// MergeTree engine configuration. The structure is documented below.
	MergeTree []MergeTreeInitParameters `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// RabbitMQ connection configuration. The structure is documented below.
	Rabbitmq []RabbitmqInitParameters `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`
}

type ConfigObservation struct {
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// Data compression configuration. The structure is documented below.
	Compression []CompressionObservation `json:"compression,omitempty" tf:"compression,omitempty"`

	// A database of the ClickHouse cluster. The structure is documented below.
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// Graphite rollup configuration. The structure is documented below.
	GraphiteRollup []GraphiteRollupObservation `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// Kafka connection configuration. The structure is documented below.
	Kafka []KafkaObservation `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// Kafka topic connection configuration. The structure is documented below.
	KafkaTopic []KafkaTopicObservation `json:"kafkaTopic,omitempty" tf:"kafka_topic,omitempty"`

	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// ClickHouse server parameters. For more information, see
	// the official documentation.
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	MarkCacheSize *float64 `json:"markCacheSize,omitempty" tf:"mark_cache_size,omitempty"`

	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// MergeTree engine configuration. The structure is documented below.
	MergeTree []MergeTreeObservation `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// RabbitMQ connection configuration. The structure is documented below.
	Rabbitmq []RabbitmqObservation `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`
}

type ConfigParameters struct {

	// +kubebuilder:validation:Optional
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// +kubebuilder:validation:Optional
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// +kubebuilder:validation:Optional
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// +kubebuilder:validation:Optional
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// +kubebuilder:validation:Optional
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// Data compression configuration. The structure is documented below.
	// +kubebuilder:validation:Optional
	Compression []CompressionParameters `json:"compression,omitempty" tf:"compression,omitempty"`

	// A database of the ClickHouse cluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// +kubebuilder:validation:Optional
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// +kubebuilder:validation:Optional
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// Graphite rollup configuration. The structure is documented below.
	// +kubebuilder:validation:Optional
	GraphiteRollup []GraphiteRollupParameters `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// Kafka connection configuration. The structure is documented below.
	// +kubebuilder:validation:Optional
	Kafka []KafkaParameters `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// Kafka topic connection configuration. The structure is documented below.
	// +kubebuilder:validation:Optional
	KafkaTopic []KafkaTopicParameters `json:"kafkaTopic,omitempty" tf:"kafka_topic,omitempty"`

	// +kubebuilder:validation:Optional
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// ClickHouse server parameters. For more information, see
	// the official documentation.
	// +kubebuilder:validation:Optional
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// +kubebuilder:validation:Optional
	MarkCacheSize *float64 `json:"markCacheSize,omitempty" tf:"mark_cache_size,omitempty"`

	// +kubebuilder:validation:Optional
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// +kubebuilder:validation:Optional
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// +kubebuilder:validation:Optional
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// +kubebuilder:validation:Optional
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// MergeTree engine configuration. The structure is documented below.
	// +kubebuilder:validation:Optional
	MergeTree []MergeTreeParameters `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// +kubebuilder:validation:Optional
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// +kubebuilder:validation:Optional
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// +kubebuilder:validation:Optional
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// +kubebuilder:validation:Optional
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// +kubebuilder:validation:Optional
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// +kubebuilder:validation:Optional
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// +kubebuilder:validation:Optional
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// +kubebuilder:validation:Optional
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// +kubebuilder:validation:Optional
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// +kubebuilder:validation:Optional
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// RabbitMQ connection configuration. The structure is documented below.
	// +kubebuilder:validation:Optional
	Rabbitmq []RabbitmqParameters `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// +kubebuilder:validation:Optional
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// +kubebuilder:validation:Optional
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// +kubebuilder:validation:Optional
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// +kubebuilder:validation:Optional
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// +kubebuilder:validation:Optional
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// +kubebuilder:validation:Optional
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// +kubebuilder:validation:Optional
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// +kubebuilder:validation:Optional
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// +kubebuilder:validation:Optional
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// +kubebuilder:validation:Optional
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`
}

type DatabaseInitParameters struct {

	// The name of the database.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type DatabaseObservation struct {

	// The name of the database.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type DatabaseParameters struct {

	// The name of the database.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`
}

type FormatSchemaInitParameters struct {

	// The name of the format schema.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Type of the format schema.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type FormatSchemaObservation struct {

	// The name of the format schema.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Type of the format schema.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type FormatSchemaParameters struct {

	// The name of the format schema.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// Type of the format schema.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	URI *string `json:"uri" tf:"uri,omitempty"`
}

type GraphiteRollupInitParameters struct {

	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Set of thinning rules.
	Pattern []PatternInitParameters `json:"pattern,omitempty" tf:"pattern,omitempty"`
}

type GraphiteRollupObservation struct {

	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Set of thinning rules.
	Pattern []PatternObservation `json:"pattern,omitempty" tf:"pattern,omitempty"`
}

type GraphiteRollupParameters struct {

	// The name of the user.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// Set of thinning rules.
	// +kubebuilder:validation:Optional
	Pattern []PatternParameters `json:"pattern,omitempty" tf:"pattern,omitempty"`
}

type HostInitParameters struct {

	// Sets whether the host should get a public IP address on creation. Can be either true or false.
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// The name of the shard to which the host belongs.
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Subnet
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// Reference to a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDRef *v1.Reference `json:"subnetIdRef,omitempty" tf:"-"`

	// Selector for a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDSelector *v1.Selector `json:"subnetIdSelector,omitempty" tf:"-"`

	// The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// The availability zone where the ClickHouse host will be created.
	// For more information see the official documentation.
	Zone *string `json:"zone,omitempty" tf:"zone,omitempty"`
}

type HostObservation struct {

	// Sets whether the host should get a public IP address on creation. Can be either true or false.
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (Computed) The fully qualified domain name of the host.
	Fqdn *string `json:"fqdn,omitempty" tf:"fqdn,omitempty"`

	// The name of the shard to which the host belongs.
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// The availability zone where the ClickHouse host will be created.
	// For more information see the official documentation.
	Zone *string `json:"zone,omitempty" tf:"zone,omitempty"`
}

type HostParameters struct {

	// Sets whether the host should get a public IP address on creation. Can be either true or false.
	// +kubebuilder:validation:Optional
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// The name of the shard to which the host belongs.
	// +kubebuilder:validation:Optional
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
	// +crossplane:generate:reference:type=github.com/yandex-cloud/crossplane-provider-yc/apis/vpc/v1alpha1.Subnet
	// +kubebuilder:validation:Optional
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// Reference to a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDRef *v1.Reference `json:"subnetIdRef,omitempty" tf:"-"`

	// Selector for a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDSelector *v1.Selector `json:"subnetIdSelector,omitempty" tf:"-"`

	// The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// The availability zone where the ClickHouse host will be created.
	// For more information see the official documentation.
	// +kubebuilder:validation:Optional
	Zone *string `json:"zone" tf:"zone,omitempty"`
}

type KafkaInitParameters struct {

	// enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// Maximum allowed time between calls to consume messages (e.g., rd_kafka_consumer_poll()) for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type KafkaObservation struct {

	// enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// Maximum allowed time between calls to consume messages (e.g., rd_kafka_consumer_poll()) for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type KafkaParameters struct {

	// enable verification of SSL certificates.
	// +kubebuilder:validation:Optional
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// Maximum allowed time between calls to consume messages (e.g., rd_kafka_consumer_poll()) for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// +kubebuilder:validation:Optional
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// SASL mechanism used in kafka authentication.
	// +kubebuilder:validation:Optional
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// User password on kafka server.
	// +kubebuilder:validation:Optional
	SaslPasswordSecretRef *v1.SecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// Username on kafka server.
	// +kubebuilder:validation:Optional
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// Security protocol used to connect to kafka server.
	// +kubebuilder:validation:Optional
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// +kubebuilder:validation:Optional
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type KafkaTopicInitParameters struct {

	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Custom settings for user. The list is documented below.
	Settings []SettingsInitParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type KafkaTopicObservation struct {

	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Custom settings for user. The list is documented below.
	Settings []SettingsObservation `json:"settings,omitempty" tf:"settings,omitempty"`
}

type KafkaTopicParameters struct {

	// The name of the user.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// Custom settings for user. The list is documented below.
	// +kubebuilder:validation:Optional
	Settings []SettingsParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type MLModelInitParameters struct {

	// The name of the ml model.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Type of the model.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// Model file URL. You can only use models stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type MLModelObservation struct {

	// The name of the ml model.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Type of the model.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// Model file URL. You can only use models stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type MLModelParameters struct {

	// The name of the ml model.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// Type of the model.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// Model file URL. You can only use models stored in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	URI *string `json:"uri" tf:"uri,omitempty"`
}

type MaintenanceWindowInitParameters struct {

	// Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// Type of maintenance window. Can be either ANYTIME or WEEKLY. A day and hour of window need to be specified with weekly window.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MaintenanceWindowObservation struct {

	// Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// Type of maintenance window. Can be either ANYTIME or WEEKLY. A day and hour of window need to be specified with weekly window.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MaintenanceWindowParameters struct {

	// Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// +kubebuilder:validation:Optional
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	// +kubebuilder:validation:Optional
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// Type of maintenance window. Can be either ANYTIME or WEEKLY. A day and hour of window need to be specified with weekly window.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type MergeTreeInitParameters struct {

	// Minimum period to clean old queue logs, blocks hashes and parts.
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// The too many parts check according to parts_to_delay_insert and parts_to_throw_insert will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// Maximum number of parts in all partitions.
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters.
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type MergeTreeObservation struct {

	// Minimum period to clean old queue logs, blocks hashes and parts.
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// The too many parts check according to parts_to_delay_insert and parts_to_throw_insert will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// Maximum number of parts in all partitions.
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters.
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type MergeTreeParameters struct {

	// Minimum period to clean old queue logs, blocks hashes and parts.
	// +kubebuilder:validation:Optional
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// The too many parts check according to parts_to_delay_insert and parts_to_throw_insert will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.
	// +kubebuilder:validation:Optional
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// +kubebuilder:validation:Optional
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// +kubebuilder:validation:Optional
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// Maximum number of parts in all partitions.
	// +kubebuilder:validation:Optional
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// +kubebuilder:validation:Optional
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters.
	// +kubebuilder:validation:Optional
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// +kubebuilder:validation:Optional
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// +kubebuilder:validation:Optional
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// +kubebuilder:validation:Optional
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// +kubebuilder:validation:Optional
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// +kubebuilder:validation:Optional
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// +kubebuilder:validation:Optional
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// +kubebuilder:validation:Optional
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
	// +kubebuilder:validation:Optional
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// +kubebuilder:validation:Optional
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// +kubebuilder:validation:Optional
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
	// +kubebuilder:validation:Optional
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.
	// +kubebuilder:validation:Optional
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type PatternInitParameters struct {

	// Aggregation function name.
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// Regular expression that the metric name must match.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// Retain parameters.
	Retention []RetentionInitParameters `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternObservation struct {

	// Aggregation function name.
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// Regular expression that the metric name must match.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// Retain parameters.
	Retention []RetentionObservation `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternParameters struct {

	// Aggregation function name.
	// +kubebuilder:validation:Optional
	Function *string `json:"function" tf:"function,omitempty"`

	// Regular expression that the metric name must match.
	// +kubebuilder:validation:Optional
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// Retain parameters.
	// +kubebuilder:validation:Optional
	Retention []RetentionParameters `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PermissionInitParameters struct {

	// The name of the database that the permission grants access to.
	DatabaseName *string `json:"databaseName,omitempty" tf:"database_name,omitempty"`
}

type PermissionObservation struct {

	// The name of the database that the permission grants access to.
	DatabaseName *string `json:"databaseName,omitempty" tf:"database_name,omitempty"`
}

type PermissionParameters struct {

	// The name of the database that the permission grants access to.
	// +kubebuilder:validation:Optional
	DatabaseName *string `json:"databaseName" tf:"database_name,omitempty"`
}

type QuotaInitParameters struct {

	// The number of queries that threw exception.
	Errors *float64 `json:"errors,omitempty" tf:"errors,omitempty"`

	// The total query execution time, in milliseconds (wall time).
	ExecutionTime *float64 `json:"executionTime,omitempty" tf:"execution_time,omitempty"`

	// Duration of interval for quota in milliseconds.
	IntervalDuration *float64 `json:"intervalDuration,omitempty" tf:"interval_duration,omitempty"`

	// The total number of queries.
	Queries *float64 `json:"queries,omitempty" tf:"queries,omitempty"`

	// The total number of source rows read from tables for running the query, on all remote servers.
	ReadRows *float64 `json:"readRows,omitempty" tf:"read_rows,omitempty"`

	// The total number of rows given as the result.
	ResultRows *float64 `json:"resultRows,omitempty" tf:"result_rows,omitempty"`
}

type QuotaObservation struct {

	// The number of queries that threw exception.
	Errors *float64 `json:"errors,omitempty" tf:"errors,omitempty"`

	// The total query execution time, in milliseconds (wall time).
	ExecutionTime *float64 `json:"executionTime,omitempty" tf:"execution_time,omitempty"`

	// Duration of interval for quota in milliseconds.
	IntervalDuration *float64 `json:"intervalDuration,omitempty" tf:"interval_duration,omitempty"`

	// The total number of queries.
	Queries *float64 `json:"queries,omitempty" tf:"queries,omitempty"`

	// The total number of source rows read from tables for running the query, on all remote servers.
	ReadRows *float64 `json:"readRows,omitempty" tf:"read_rows,omitempty"`

	// The total number of rows given as the result.
	ResultRows *float64 `json:"resultRows,omitempty" tf:"result_rows,omitempty"`
}

type QuotaParameters struct {

	// The number of queries that threw exception.
	// +kubebuilder:validation:Optional
	Errors *float64 `json:"errors,omitempty" tf:"errors,omitempty"`

	// The total query execution time, in milliseconds (wall time).
	// +kubebuilder:validation:Optional
	ExecutionTime *float64 `json:"executionTime,omitempty" tf:"execution_time,omitempty"`

	// Duration of interval for quota in milliseconds.
	// +kubebuilder:validation:Optional
	IntervalDuration *float64 `json:"intervalDuration" tf:"interval_duration,omitempty"`

	// The total number of queries.
	// +kubebuilder:validation:Optional
	Queries *float64 `json:"queries,omitempty" tf:"queries,omitempty"`

	// The total number of source rows read from tables for running the query, on all remote servers.
	// +kubebuilder:validation:Optional
	ReadRows *float64 `json:"readRows,omitempty" tf:"read_rows,omitempty"`

	// The total number of rows given as the result.
	// +kubebuilder:validation:Optional
	ResultRows *float64 `json:"resultRows,omitempty" tf:"result_rows,omitempty"`
}

type RabbitmqInitParameters struct {

	// RabbitMQ username.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// RabbitMQ vhost. Default: ”.
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type RabbitmqObservation struct {

	// RabbitMQ username.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// RabbitMQ vhost. Default: ”.
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type RabbitmqParameters struct {

	// The password of the user.
	// +kubebuilder:validation:Optional
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// RabbitMQ username.
	// +kubebuilder:validation:Optional
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// RabbitMQ vhost. Default: ”.
	// +kubebuilder:validation:Optional
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type ResourcesInitParameters struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ResourcesObservation struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ResourcesParameters struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type RetentionInitParameters struct {

	// Minimum data age in seconds.
	Age *float64 `json:"age,omitempty" tf:"age,omitempty"`

	// Accuracy of determining the age of the data in seconds.
	Precision *float64 `json:"precision,omitempty" tf:"precision,omitempty"`
}

type RetentionObservation struct {

	// Minimum data age in seconds.
	Age *float64 `json:"age,omitempty" tf:"age,omitempty"`

	// Accuracy of determining the age of the data in seconds.
	Precision *float64 `json:"precision,omitempty" tf:"precision,omitempty"`
}

type RetentionParameters struct {

	// Minimum data age in seconds.
	// +kubebuilder:validation:Optional
	Age *float64 `json:"age" tf:"age,omitempty"`

	// Accuracy of determining the age of the data in seconds.
	// +kubebuilder:validation:Optional
	Precision *float64 `json:"precision" tf:"precision,omitempty"`
}

type SettingsInitParameters struct {

	// enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// Maximum allowed time between calls to consume messages (e.g., rd_kafka_consumer_poll()) for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type SettingsObservation struct {

	// enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// Maximum allowed time between calls to consume messages (e.g., rd_kafka_consumer_poll()) for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type SettingsParameters struct {

	// enable verification of SSL certificates.
	// +kubebuilder:validation:Optional
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// Maximum allowed time between calls to consume messages (e.g., rd_kafka_consumer_poll()) for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.
	// +kubebuilder:validation:Optional
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// SASL mechanism used in kafka authentication.
	// +kubebuilder:validation:Optional
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// User password on kafka server.
	// +kubebuilder:validation:Optional
	SaslPasswordSecretRef *v1.SecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// Username on kafka server.
	// +kubebuilder:validation:Optional
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// Security protocol used to connect to kafka server.
	// +kubebuilder:validation:Optional
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance.
	// +kubebuilder:validation:Optional
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type ShardGroupInitParameters struct {

	// Description of the shard group.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// The name of the shard group, used as cluster name in Distributed tables.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// List of shards names that belong to the shard group.
	ShardNames []*string `json:"shardNames,omitempty" tf:"shard_names,omitempty"`
}

type ShardGroupObservation struct {

	// Description of the shard group.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// The name of the shard group, used as cluster name in Distributed tables.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// List of shards names that belong to the shard group.
	ShardNames []*string `json:"shardNames,omitempty" tf:"shard_names,omitempty"`
}

type ShardGroupParameters struct {

	// Description of the shard group.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// The name of the shard group, used as cluster name in Distributed tables.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// List of shards names that belong to the shard group.
	// +kubebuilder:validation:Optional
	ShardNames []*string `json:"shardNames" tf:"shard_names,omitempty"`
}

type ShardInitParameters struct {

	// The name of shard.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
	Resources []ShardResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`

	// The weight of shard.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardObservation struct {

	// The name of shard.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
	Resources []ShardResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`

	// The weight of shard.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardParameters struct {

	// The name of shard.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Resources []ShardResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`

	// The weight of shard.
	// +kubebuilder:validation:Optional
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardResourcesInitParameters struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ShardResourcesObservation struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ShardResourcesParameters struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type UserInitParameters struct {

	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Set of permissions granted to the user. The structure is documented below.
	Permission []PermissionInitParameters `json:"permission,omitempty" tf:"permission,omitempty"`

	// Set of user quotas. The structure is documented below.
	Quota []QuotaInitParameters `json:"quota,omitempty" tf:"quota,omitempty"`

	// Custom settings for user. The list is documented below.
	Settings []UserSettingsInitParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type UserObservation struct {

	// The name of the user.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Set of permissions granted to the user. The structure is documented below.
	Permission []PermissionObservation `json:"permission,omitempty" tf:"permission,omitempty"`

	// Set of user quotas. The structure is documented below.
	Quota []QuotaObservation `json:"quota,omitempty" tf:"quota,omitempty"`

	// Custom settings for user. The list is documented below.
	Settings []UserSettingsObservation `json:"settings,omitempty" tf:"settings,omitempty"`
}

type UserParameters struct {

	// The name of the user.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// The password of the user.
	// +kubebuilder:validation:Required
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// Set of permissions granted to the user. The structure is documented below.
	// +kubebuilder:validation:Optional
	Permission []PermissionParameters `json:"permission,omitempty" tf:"permission,omitempty"`

	// Set of user quotas. The structure is documented below.
	// +kubebuilder:validation:Optional
	Quota []QuotaParameters `json:"quota,omitempty" tf:"quota,omitempty"`

	// Custom settings for user. The list is documented below.
	// +kubebuilder:validation:Optional
	Settings []UserSettingsParameters `json:"settings,omitempty" tf:"settings,omitempty"`
}

type UserSettingsInitParameters struct {

	// Include CORS headers in HTTP responces.
	AddHTTPCorsHeader *bool `json:"addHttpCorsHeader,omitempty" tf:"add_http_cors_header,omitempty"`

	// Allows or denies DDL queries.
	AllowDdl *bool `json:"allowDdl,omitempty" tf:"allow_ddl,omitempty"`

	// Enables introspections functions for query profiling.
	AllowIntrospectionFunctions *bool `json:"allowIntrospectionFunctions,omitempty" tf:"allow_introspection_functions,omitempty"`

	// Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	AllowSuspiciousLowCardinalityTypes *bool `json:"allowSuspiciousLowCardinalityTypes,omitempty" tf:"allow_suspicious_low_cardinality_types,omitempty"`

	// Enables asynchronous inserts. Disabled by default.
	AsyncInsert *bool `json:"asyncInsert,omitempty" tf:"async_insert,omitempty"`

	// The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	AsyncInsertBusyTimeout *float64 `json:"asyncInsertBusyTimeout,omitempty" tf:"async_insert_busy_timeout,omitempty"`

	// The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	AsyncInsertMaxDataSize *float64 `json:"asyncInsertMaxDataSize,omitempty" tf:"async_insert_max_data_size,omitempty"`

	// The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	AsyncInsertStaleTimeout *float64 `json:"asyncInsertStaleTimeout,omitempty" tf:"async_insert_stale_timeout,omitempty"`

	// The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response.
	// Default value: false.
	CancelHTTPReadonlyQueriesOnClientClose *bool `json:"cancelHttpReadonlyQueriesOnClientClose,omitempty" tf:"cancel_http_readonly_queries_on_client_close,omitempty"`

	// Enable compilation of queries.
	Compile *bool `json:"compile,omitempty" tf:"compile,omitempty"`

	// Turn on expression compilation.
	CompileExpressions *bool `json:"compileExpressions,omitempty" tf:"compile_expressions,omitempty"`

	// Connect timeout in milliseconds on the socket used for communicating with the client.
	ConnectTimeout *float64 `json:"connectTimeout,omitempty" tf:"connect_timeout,omitempty"`

	// The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	ConnectTimeoutWithFailover *float64 `json:"connectTimeoutWithFailover,omitempty" tf:"connect_timeout_with_failover,omitempty"`

	// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	CountDistinctImplementation *string `json:"countDistinctImplementation,omitempty" tf:"count_distinct_implementation,omitempty"`

	// Sets behaviour on overflow when using DISTINCT. Possible values:
	DistinctOverflowMode *string `json:"distinctOverflowMode,omitempty" tf:"distinct_overflow_mode,omitempty"`

	// Determine the behavior of distributed subqueries.
	DistributedAggregationMemoryEfficient *bool `json:"distributedAggregationMemoryEfficient,omitempty" tf:"distributed_aggregation_memory_efficient,omitempty"`

	// Timeout for DDL queries, in milliseconds.
	DistributedDdlTaskTimeout *float64 `json:"distributedDdlTaskTimeout,omitempty" tf:"distributed_ddl_task_timeout,omitempty"`

	// Changes the behaviour of distributed subqueries.
	DistributedProductMode *string `json:"distributedProductMode,omitempty" tf:"distributed_product_mode,omitempty"`

	// Allows to retunr empty result.
	EmptyResultForAggregationByEmptySet *bool `json:"emptyResultForAggregationByEmptySet,omitempty" tf:"empty_result_for_aggregation_by_empty_set,omitempty"`

	// Enables or disables data compression in the response to an HTTP request.
	EnableHTTPCompression *bool `json:"enableHttpCompression,omitempty" tf:"enable_http_compression,omitempty"`

	// Forces a query to an out-of-date replica if updated data is not available.
	FallbackToStaleReplicasForDistributedQueries *bool `json:"fallbackToStaleReplicasForDistributedQueries,omitempty" tf:"fallback_to_stale_replicas_for_distributed_queries,omitempty"`

	// Sets the data format of a nested columns.
	FlattenNested *bool `json:"flattenNested,omitempty" tf:"flatten_nested,omitempty"`

	// Disables query execution if the index can’t be used by date.
	ForceIndexByDate *bool `json:"forceIndexByDate,omitempty" tf:"force_index_by_date,omitempty"`

	// Disables query execution if indexing by the primary key is not possible.
	ForcePrimaryKey *bool `json:"forcePrimaryKey,omitempty" tf:"force_primary_key,omitempty"`

	// Sets behaviour on overflow while GROUP BY operation. Possible values:
	GroupByOverflowMode *string `json:"groupByOverflowMode,omitempty" tf:"group_by_overflow_mode,omitempty"`

	// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
	GroupByTwoLevelThreshold *float64 `json:"groupByTwoLevelThreshold,omitempty" tf:"group_by_two_level_threshold,omitempty"`

	// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
	GroupByTwoLevelThresholdBytes *float64 `json:"groupByTwoLevelThresholdBytes,omitempty" tf:"group_by_two_level_threshold_bytes,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	HTTPConnectionTimeout *float64 `json:"httpConnectionTimeout,omitempty" tf:"http_connection_timeout,omitempty"`

	// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
	HTTPHeadersProgressInterval *float64 `json:"httpHeadersProgressInterval,omitempty" tf:"http_headers_progress_interval,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	HTTPReceiveTimeout *float64 `json:"httpReceiveTimeout,omitempty" tf:"http_receive_timeout,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	HTTPSendTimeout *float64 `json:"httpSendTimeout,omitempty" tf:"http_send_timeout,omitempty"`

	// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	InputFormatDefaultsForOmittedFields *bool `json:"inputFormatDefaultsForOmittedFields,omitempty" tf:"input_format_defaults_for_omitted_fields,omitempty"`

	// Enables or disables the insertion of JSON data with nested objects.
	InputFormatImportNestedJSON *bool `json:"inputFormatImportNestedJson,omitempty" tf:"input_format_import_nested_json,omitempty"`

	// Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	InputFormatParallelParsing *bool `json:"inputFormatParallelParsing,omitempty" tf:"input_format_parallel_parsing,omitempty"`

	// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	InputFormatValuesInterpretExpressions *bool `json:"inputFormatValuesInterpretExpressions,omitempty" tf:"input_format_values_interpret_expressions,omitempty"`

	// The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	InsertKeeperMaxRetries *float64 `json:"insertKeeperMaxRetries,omitempty" tf:"insert_keeper_max_retries,omitempty"`

	// Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	InsertNullAsDefault *bool `json:"insertNullAsDefault,omitempty" tf:"insert_null_as_default,omitempty"`

	// Enables the quorum writes.
	InsertQuorum *float64 `json:"insertQuorum,omitempty" tf:"insert_quorum,omitempty"`

	// Write to a quorum timeout in milliseconds.
	InsertQuorumTimeout *float64 `json:"insertQuorumTimeout,omitempty" tf:"insert_quorum_timeout,omitempty"`

	// Sets behaviour on overflow in JOIN. Possible values:
	JoinOverflowMode *string `json:"joinOverflowMode,omitempty" tf:"join_overflow_mode,omitempty"`

	// Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	JoinUseNulls *bool `json:"joinUseNulls,omitempty" tf:"join_use_nulls,omitempty"`

	// Require aliases for subselects and table functions in FROM that more than one table is present.
	JoinedSubqueryRequiresAlias *bool `json:"joinedSubqueryRequiresAlias,omitempty" tf:"joined_subquery_requires_alias,omitempty"`

	// Method of reading data from local filesystem. Possible values:
	LocalFilesystemReadMethod *string `json:"localFilesystemReadMethod,omitempty" tf:"local_filesystem_read_method,omitempty"`

	// Allows or restricts using the LowCardinality data type with the Native format.
	LowCardinalityAllowInNativeFormat *bool `json:"lowCardinalityAllowInNativeFormat,omitempty" tf:"low_cardinality_allow_in_native_format,omitempty"`

	// Maximum abstract syntax tree depth.
	MaxAstDepth *float64 `json:"maxAstDepth,omitempty" tf:"max_ast_depth,omitempty"`

	// Maximum abstract syntax tree elements.
	MaxAstElements *float64 `json:"maxAstElements,omitempty" tf:"max_ast_elements,omitempty"`

	// A recommendation for what size of the block (in a count of rows) to load from tables.
	MaxBlockSize *float64 `json:"maxBlockSize,omitempty" tf:"max_block_size,omitempty"`

	// Limit in bytes for using memoru for GROUP BY before using swap on disk.
	MaxBytesBeforeExternalGroupBy *float64 `json:"maxBytesBeforeExternalGroupBy,omitempty" tf:"max_bytes_before_external_group_by,omitempty"`

	// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	MaxBytesBeforeExternalSort *float64 `json:"maxBytesBeforeExternalSort,omitempty" tf:"max_bytes_before_external_sort,omitempty"`

	// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	MaxBytesInDistinct *float64 `json:"maxBytesInDistinct,omitempty" tf:"max_bytes_in_distinct,omitempty"`

	// Limit on maximum size of the hash table for JOIN, in bytes.
	MaxBytesInJoin *float64 `json:"maxBytesInJoin,omitempty" tf:"max_bytes_in_join,omitempty"`

	// Limit on the number of bytes in the set resulting from the execution of the IN section.
	MaxBytesInSet *float64 `json:"maxBytesInSet,omitempty" tf:"max_bytes_in_set,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	MaxBytesToRead *float64 `json:"maxBytesToRead,omitempty" tf:"max_bytes_to_read,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	MaxBytesToSort *float64 `json:"maxBytesToSort,omitempty" tf:"max_bytes_to_sort,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxBytesToTransfer *float64 `json:"maxBytesToTransfer,omitempty" tf:"max_bytes_to_transfer,omitempty"`

	// Limits the maximum number of columns that can be read from a table in a single query.
	MaxColumnsToRead *float64 `json:"maxColumnsToRead,omitempty" tf:"max_columns_to_read,omitempty"`

	// The maximum number of concurrent requests per user. Default value: 0 (no limit).
	MaxConcurrentQueriesForUser *float64 `json:"maxConcurrentQueriesForUser,omitempty" tf:"max_concurrent_queries_for_user,omitempty"`

	// Limits the maximum query execution time in milliseconds.
	MaxExecutionTime *float64 `json:"maxExecutionTime,omitempty" tf:"max_execution_time,omitempty"`

	// Maximum abstract syntax tree depth after after expansion of aliases.
	MaxExpandedAstElements *float64 `json:"maxExpandedAstElements,omitempty" tf:"max_expanded_ast_elements,omitempty"`

	// Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	MaxFinalThreads *float64 `json:"maxFinalThreads,omitempty" tf:"max_final_threads,omitempty"`

	// Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
	MaxHTTPGetRedirects *float64 `json:"maxHttpGetRedirects,omitempty" tf:"max_http_get_redirects,omitempty"`

	// The size of blocks (in a count of rows) to form for insertion into a table.
	MaxInsertBlockSize *float64 `json:"maxInsertBlockSize,omitempty" tf:"max_insert_block_size,omitempty"`

	// Limits the maximum memory usage (in bytes) for processing queries on a single server.
	MaxMemoryUsage *float64 `json:"maxMemoryUsage,omitempty" tf:"max_memory_usage,omitempty"`

	// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	MaxMemoryUsageForUser *float64 `json:"maxMemoryUsageForUser,omitempty" tf:"max_memory_usage_for_user,omitempty"`

	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidth *float64 `json:"maxNetworkBandwidth,omitempty" tf:"max_network_bandwidth,omitempty"`

	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidthForUser *float64 `json:"maxNetworkBandwidthForUser,omitempty" tf:"max_network_bandwidth_for_user,omitempty"`

	// Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	MaxParserDepth *float64 `json:"maxParserDepth,omitempty" tf:"max_parser_depth,omitempty"`

	// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	MaxQuerySize *float64 `json:"maxQuerySize,omitempty" tf:"max_query_size,omitempty"`

	// The maximum size of the buffer to read from the filesystem.
	MaxReadBufferSize *float64 `json:"maxReadBufferSize,omitempty" tf:"max_read_buffer_size,omitempty"`

	// Disables lagging replicas for distributed queries.
	MaxReplicaDelayForDistributedQueries *float64 `json:"maxReplicaDelayForDistributedQueries,omitempty" tf:"max_replica_delay_for_distributed_queries,omitempty"`

	// Limits the number of bytes in the result.
	MaxResultBytes *float64 `json:"maxResultBytes,omitempty" tf:"max_result_bytes,omitempty"`

	// Limits the number of rows in the result.
	MaxResultRows *float64 `json:"maxResultRows,omitempty" tf:"max_result_rows,omitempty"`

	// Limits the maximum number of different rows when using DISTINCT.
	MaxRowsInDistinct *float64 `json:"maxRowsInDistinct,omitempty" tf:"max_rows_in_distinct,omitempty"`

	// Limit on maximum size of the hash table for JOIN, in rows.
	MaxRowsInJoin *float64 `json:"maxRowsInJoin,omitempty" tf:"max_rows_in_join,omitempty"`

	// Limit on the number of rows in the set resulting from the execution of the IN section.
	MaxRowsInSet *float64 `json:"maxRowsInSet,omitempty" tf:"max_rows_in_set,omitempty"`

	// Limits the maximum number of unique keys received from aggregation function.
	MaxRowsToGroupBy *float64 `json:"maxRowsToGroupBy,omitempty" tf:"max_rows_to_group_by,omitempty"`

	// Limits the maximum number of rows that can be read from a table when running a query.
	MaxRowsToRead *float64 `json:"maxRowsToRead,omitempty" tf:"max_rows_to_read,omitempty"`

	// Limits the maximum number of rows that can be read from a table for sorting.
	MaxRowsToSort *float64 `json:"maxRowsToSort,omitempty" tf:"max_rows_to_sort,omitempty"`

	// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxRowsToTransfer *float64 `json:"maxRowsToTransfer,omitempty" tf:"max_rows_to_transfer,omitempty"`

	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	MaxTemporaryColumns *float64 `json:"maxTemporaryColumns,omitempty" tf:"max_temporary_columns,omitempty"`

	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForQuery *float64 `json:"maxTemporaryDataOnDiskSizeForQuery,omitempty" tf:"max_temporary_data_on_disk_size_for_query,omitempty"`

	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForUser *float64 `json:"maxTemporaryDataOnDiskSizeForUser,omitempty" tf:"max_temporary_data_on_disk_size_for_user,omitempty"`

	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	MaxTemporaryNonConstColumns *float64 `json:"maxTemporaryNonConstColumns,omitempty" tf:"max_temporary_non_const_columns,omitempty"`

	// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	MaxThreads *float64 `json:"maxThreads,omitempty" tf:"max_threads,omitempty"`

	// It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominator *float64 `json:"memoryOvercommitRatioDenominator,omitempty" tf:"memory_overcommit_ratio_denominator,omitempty"`

	// It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominatorForUser *float64 `json:"memoryOvercommitRatioDenominatorForUser,omitempty" tf:"memory_overcommit_ratio_denominator_for_user,omitempty"`

	// Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	MemoryProfilerSampleProbability *float64 `json:"memoryProfilerSampleProbability,omitempty" tf:"memory_profiler_sample_probability,omitempty"`

	// Memory profiler step (in bytes).  If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	MemoryProfilerStep *float64 `json:"memoryProfilerStep,omitempty" tf:"memory_profiler_step,omitempty"`

	// Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	MemoryUsageOvercommitMaxWaitMicroseconds *float64 `json:"memoryUsageOvercommitMaxWaitMicroseconds,omitempty" tf:"memory_usage_overcommit_max_wait_microseconds,omitempty"`

	// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxBytesToUseCache *float64 `json:"mergeTreeMaxBytesToUseCache,omitempty" tf:"merge_tree_max_bytes_to_use_cache,omitempty"`

	// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxRowsToUseCache *float64 `json:"mergeTreeMaxRowsToUseCache,omitempty" tf:"merge_tree_max_rows_to_use_cache,omitempty"`

	// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	MergeTreeMinBytesForConcurrentRead *float64 `json:"mergeTreeMinBytesForConcurrentRead,omitempty" tf:"merge_tree_min_bytes_for_concurrent_read,omitempty"`

	// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	MergeTreeMinRowsForConcurrentRead *float64 `json:"mergeTreeMinRowsForConcurrentRead,omitempty" tf:"merge_tree_min_rows_for_concurrent_read,omitempty"`

	// The minimum data volume required for using direct I/O access to the storage disk.
	MinBytesToUseDirectIo *float64 `json:"minBytesToUseDirectIo,omitempty" tf:"min_bytes_to_use_direct_io,omitempty"`

	// How many times to potentially use a compiled chunk of code before running compilation.
	MinCountToCompile *float64 `json:"minCountToCompile,omitempty" tf:"min_count_to_compile,omitempty"`

	// A query waits for expression compilation process to complete prior to continuing execution.
	MinCountToCompileExpression *float64 `json:"minCountToCompileExpression,omitempty" tf:"min_count_to_compile_expression,omitempty"`

	// Minimal execution speed in rows per second.
	MinExecutionSpeed *float64 `json:"minExecutionSpeed,omitempty" tf:"min_execution_speed,omitempty"`

	// Minimal execution speed in bytes per second.
	MinExecutionSpeedBytes *float64 `json:"minExecutionSpeedBytes,omitempty" tf:"min_execution_speed_bytes,omitempty"`

	// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeBytes *float64 `json:"minInsertBlockSizeBytes,omitempty" tf:"min_insert_block_size_bytes,omitempty"`

	// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeRows *float64 `json:"minInsertBlockSizeRows,omitempty" tf:"min_insert_block_size_rows,omitempty"`

	// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	OutputFormatJSONQuote64BitIntegers *bool `json:"outputFormatJsonQuote64BitIntegers,omitempty" tf:"output_format_json_quote_64bit_integers,omitempty"`

	// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
	OutputFormatJSONQuoteDenormals *bool `json:"outputFormatJsonQuoteDenormals,omitempty" tf:"output_format_json_quote_denormals,omitempty"`

	// Query priority.
	Priority *float64 `json:"priority,omitempty" tf:"priority,omitempty"`

	// Quota accounting mode.
	QuotaMode *string `json:"quotaMode,omitempty" tf:"quota_mode,omitempty"`

	// Sets behaviour on overflow while read. Possible values:
	ReadOverflowMode *string `json:"readOverflowMode,omitempty" tf:"read_overflow_mode,omitempty"`

	// Restricts permissions for reading data, write data and change settings queries.
	Readonly *float64 `json:"readonly,omitempty" tf:"readonly,omitempty"`

	// Receive timeout in milliseconds on the socket used for communicating with the client.
	ReceiveTimeout *float64 `json:"receiveTimeout,omitempty" tf:"receive_timeout,omitempty"`

	// Method of reading data from remote filesystem, one of: read, threadpool.
	RemoteFilesystemReadMethod *string `json:"remoteFilesystemReadMethod,omitempty" tf:"remote_filesystem_read_method,omitempty"`

	// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	ReplicationAlterPartitionsSync *float64 `json:"replicationAlterPartitionsSync,omitempty" tf:"replication_alter_partitions_sync,omitempty"`

	// Sets behaviour on overflow in result. Possible values:
	ResultOverflowMode *string `json:"resultOverflowMode,omitempty" tf:"result_overflow_mode,omitempty"`

	// Enables or disables sequential consistency for SELECT queries.
	SelectSequentialConsistency *bool `json:"selectSequentialConsistency,omitempty" tf:"select_sequential_consistency,omitempty"`

	// Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
	SendProgressInHTTPHeaders *bool `json:"sendProgressInHttpHeaders,omitempty" tf:"send_progress_in_http_headers,omitempty"`

	// Send timeout in milliseconds on the socket used for communicating with the client.
	SendTimeout *float64 `json:"sendTimeout,omitempty" tf:"send_timeout,omitempty"`

	// Sets behaviour on overflow in the set resulting. Possible values:
	SetOverflowMode *string `json:"setOverflowMode,omitempty" tf:"set_overflow_mode,omitempty"`

	// Enables or disables silently skipping of unavailable shards.
	SkipUnavailableShards *bool `json:"skipUnavailableShards,omitempty" tf:"skip_unavailable_shards,omitempty"`

	// Sets behaviour on overflow while sort. Possible values:
	SortOverflowMode *string `json:"sortOverflowMode,omitempty" tf:"sort_overflow_mode,omitempty"`

	// Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter.
	// Must be at least 1000.
	TimeoutBeforeCheckingExecutionSpeed *float64 `json:"timeoutBeforeCheckingExecutionSpeed,omitempty" tf:"timeout_before_checking_execution_speed,omitempty"`

	// Sets behaviour on overflow. Possible values:
	TimeoutOverflowMode *string `json:"timeoutOverflowMode,omitempty" tf:"timeout_overflow_mode,omitempty"`

	// Sets behaviour on overflow. Possible values:
	TransferOverflowMode *string `json:"transferOverflowMode,omitempty" tf:"transfer_overflow_mode,omitempty"`

	// Enables equality of NULL values for IN operator.
	TransformNullIn *bool `json:"transformNullIn,omitempty" tf:"transform_null_in,omitempty"`

	// Whether to use a cache of uncompressed blocks.
	UseUncompressedCache *bool `json:"useUncompressedCache,omitempty" tf:"use_uncompressed_cache,omitempty"`

	// Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	WaitForAsyncInsert *bool `json:"waitForAsyncInsert,omitempty" tf:"wait_for_async_insert,omitempty"`

	// The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	WaitForAsyncInsertTimeout *float64 `json:"waitForAsyncInsertTimeout,omitempty" tf:"wait_for_async_insert_timeout,omitempty"`
}

type UserSettingsObservation struct {

	// Include CORS headers in HTTP responces.
	AddHTTPCorsHeader *bool `json:"addHttpCorsHeader,omitempty" tf:"add_http_cors_header,omitempty"`

	// Allows or denies DDL queries.
	AllowDdl *bool `json:"allowDdl,omitempty" tf:"allow_ddl,omitempty"`

	// Enables introspections functions for query profiling.
	AllowIntrospectionFunctions *bool `json:"allowIntrospectionFunctions,omitempty" tf:"allow_introspection_functions,omitempty"`

	// Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	AllowSuspiciousLowCardinalityTypes *bool `json:"allowSuspiciousLowCardinalityTypes,omitempty" tf:"allow_suspicious_low_cardinality_types,omitempty"`

	// Enables asynchronous inserts. Disabled by default.
	AsyncInsert *bool `json:"asyncInsert,omitempty" tf:"async_insert,omitempty"`

	// The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	AsyncInsertBusyTimeout *float64 `json:"asyncInsertBusyTimeout,omitempty" tf:"async_insert_busy_timeout,omitempty"`

	// The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	AsyncInsertMaxDataSize *float64 `json:"asyncInsertMaxDataSize,omitempty" tf:"async_insert_max_data_size,omitempty"`

	// The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	AsyncInsertStaleTimeout *float64 `json:"asyncInsertStaleTimeout,omitempty" tf:"async_insert_stale_timeout,omitempty"`

	// The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response.
	// Default value: false.
	CancelHTTPReadonlyQueriesOnClientClose *bool `json:"cancelHttpReadonlyQueriesOnClientClose,omitempty" tf:"cancel_http_readonly_queries_on_client_close,omitempty"`

	// Enable compilation of queries.
	Compile *bool `json:"compile,omitempty" tf:"compile,omitempty"`

	// Turn on expression compilation.
	CompileExpressions *bool `json:"compileExpressions,omitempty" tf:"compile_expressions,omitempty"`

	// Connect timeout in milliseconds on the socket used for communicating with the client.
	ConnectTimeout *float64 `json:"connectTimeout,omitempty" tf:"connect_timeout,omitempty"`

	// The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	ConnectTimeoutWithFailover *float64 `json:"connectTimeoutWithFailover,omitempty" tf:"connect_timeout_with_failover,omitempty"`

	// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	CountDistinctImplementation *string `json:"countDistinctImplementation,omitempty" tf:"count_distinct_implementation,omitempty"`

	// Sets behaviour on overflow when using DISTINCT. Possible values:
	DistinctOverflowMode *string `json:"distinctOverflowMode,omitempty" tf:"distinct_overflow_mode,omitempty"`

	// Determine the behavior of distributed subqueries.
	DistributedAggregationMemoryEfficient *bool `json:"distributedAggregationMemoryEfficient,omitempty" tf:"distributed_aggregation_memory_efficient,omitempty"`

	// Timeout for DDL queries, in milliseconds.
	DistributedDdlTaskTimeout *float64 `json:"distributedDdlTaskTimeout,omitempty" tf:"distributed_ddl_task_timeout,omitempty"`

	// Changes the behaviour of distributed subqueries.
	DistributedProductMode *string `json:"distributedProductMode,omitempty" tf:"distributed_product_mode,omitempty"`

	// Allows to retunr empty result.
	EmptyResultForAggregationByEmptySet *bool `json:"emptyResultForAggregationByEmptySet,omitempty" tf:"empty_result_for_aggregation_by_empty_set,omitempty"`

	// Enables or disables data compression in the response to an HTTP request.
	EnableHTTPCompression *bool `json:"enableHttpCompression,omitempty" tf:"enable_http_compression,omitempty"`

	// Forces a query to an out-of-date replica if updated data is not available.
	FallbackToStaleReplicasForDistributedQueries *bool `json:"fallbackToStaleReplicasForDistributedQueries,omitempty" tf:"fallback_to_stale_replicas_for_distributed_queries,omitempty"`

	// Sets the data format of a nested columns.
	FlattenNested *bool `json:"flattenNested,omitempty" tf:"flatten_nested,omitempty"`

	// Disables query execution if the index can’t be used by date.
	ForceIndexByDate *bool `json:"forceIndexByDate,omitempty" tf:"force_index_by_date,omitempty"`

	// Disables query execution if indexing by the primary key is not possible.
	ForcePrimaryKey *bool `json:"forcePrimaryKey,omitempty" tf:"force_primary_key,omitempty"`

	// Sets behaviour on overflow while GROUP BY operation. Possible values:
	GroupByOverflowMode *string `json:"groupByOverflowMode,omitempty" tf:"group_by_overflow_mode,omitempty"`

	// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
	GroupByTwoLevelThreshold *float64 `json:"groupByTwoLevelThreshold,omitempty" tf:"group_by_two_level_threshold,omitempty"`

	// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
	GroupByTwoLevelThresholdBytes *float64 `json:"groupByTwoLevelThresholdBytes,omitempty" tf:"group_by_two_level_threshold_bytes,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	HTTPConnectionTimeout *float64 `json:"httpConnectionTimeout,omitempty" tf:"http_connection_timeout,omitempty"`

	// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
	HTTPHeadersProgressInterval *float64 `json:"httpHeadersProgressInterval,omitempty" tf:"http_headers_progress_interval,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	HTTPReceiveTimeout *float64 `json:"httpReceiveTimeout,omitempty" tf:"http_receive_timeout,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	HTTPSendTimeout *float64 `json:"httpSendTimeout,omitempty" tf:"http_send_timeout,omitempty"`

	// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	InputFormatDefaultsForOmittedFields *bool `json:"inputFormatDefaultsForOmittedFields,omitempty" tf:"input_format_defaults_for_omitted_fields,omitempty"`

	// Enables or disables the insertion of JSON data with nested objects.
	InputFormatImportNestedJSON *bool `json:"inputFormatImportNestedJson,omitempty" tf:"input_format_import_nested_json,omitempty"`

	// Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	InputFormatParallelParsing *bool `json:"inputFormatParallelParsing,omitempty" tf:"input_format_parallel_parsing,omitempty"`

	// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	InputFormatValuesInterpretExpressions *bool `json:"inputFormatValuesInterpretExpressions,omitempty" tf:"input_format_values_interpret_expressions,omitempty"`

	// The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	InsertKeeperMaxRetries *float64 `json:"insertKeeperMaxRetries,omitempty" tf:"insert_keeper_max_retries,omitempty"`

	// Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	InsertNullAsDefault *bool `json:"insertNullAsDefault,omitempty" tf:"insert_null_as_default,omitempty"`

	// Enables the quorum writes.
	InsertQuorum *float64 `json:"insertQuorum,omitempty" tf:"insert_quorum,omitempty"`

	// Write to a quorum timeout in milliseconds.
	InsertQuorumTimeout *float64 `json:"insertQuorumTimeout,omitempty" tf:"insert_quorum_timeout,omitempty"`

	// Sets behaviour on overflow in JOIN. Possible values:
	JoinOverflowMode *string `json:"joinOverflowMode,omitempty" tf:"join_overflow_mode,omitempty"`

	// Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	JoinUseNulls *bool `json:"joinUseNulls,omitempty" tf:"join_use_nulls,omitempty"`

	// Require aliases for subselects and table functions in FROM that more than one table is present.
	JoinedSubqueryRequiresAlias *bool `json:"joinedSubqueryRequiresAlias,omitempty" tf:"joined_subquery_requires_alias,omitempty"`

	// Method of reading data from local filesystem. Possible values:
	LocalFilesystemReadMethod *string `json:"localFilesystemReadMethod,omitempty" tf:"local_filesystem_read_method,omitempty"`

	// Allows or restricts using the LowCardinality data type with the Native format.
	LowCardinalityAllowInNativeFormat *bool `json:"lowCardinalityAllowInNativeFormat,omitempty" tf:"low_cardinality_allow_in_native_format,omitempty"`

	// Maximum abstract syntax tree depth.
	MaxAstDepth *float64 `json:"maxAstDepth,omitempty" tf:"max_ast_depth,omitempty"`

	// Maximum abstract syntax tree elements.
	MaxAstElements *float64 `json:"maxAstElements,omitempty" tf:"max_ast_elements,omitempty"`

	// A recommendation for what size of the block (in a count of rows) to load from tables.
	MaxBlockSize *float64 `json:"maxBlockSize,omitempty" tf:"max_block_size,omitempty"`

	// Limit in bytes for using memoru for GROUP BY before using swap on disk.
	MaxBytesBeforeExternalGroupBy *float64 `json:"maxBytesBeforeExternalGroupBy,omitempty" tf:"max_bytes_before_external_group_by,omitempty"`

	// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	MaxBytesBeforeExternalSort *float64 `json:"maxBytesBeforeExternalSort,omitempty" tf:"max_bytes_before_external_sort,omitempty"`

	// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	MaxBytesInDistinct *float64 `json:"maxBytesInDistinct,omitempty" tf:"max_bytes_in_distinct,omitempty"`

	// Limit on maximum size of the hash table for JOIN, in bytes.
	MaxBytesInJoin *float64 `json:"maxBytesInJoin,omitempty" tf:"max_bytes_in_join,omitempty"`

	// Limit on the number of bytes in the set resulting from the execution of the IN section.
	MaxBytesInSet *float64 `json:"maxBytesInSet,omitempty" tf:"max_bytes_in_set,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	MaxBytesToRead *float64 `json:"maxBytesToRead,omitempty" tf:"max_bytes_to_read,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	MaxBytesToSort *float64 `json:"maxBytesToSort,omitempty" tf:"max_bytes_to_sort,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxBytesToTransfer *float64 `json:"maxBytesToTransfer,omitempty" tf:"max_bytes_to_transfer,omitempty"`

	// Limits the maximum number of columns that can be read from a table in a single query.
	MaxColumnsToRead *float64 `json:"maxColumnsToRead,omitempty" tf:"max_columns_to_read,omitempty"`

	// The maximum number of concurrent requests per user. Default value: 0 (no limit).
	MaxConcurrentQueriesForUser *float64 `json:"maxConcurrentQueriesForUser,omitempty" tf:"max_concurrent_queries_for_user,omitempty"`

	// Limits the maximum query execution time in milliseconds.
	MaxExecutionTime *float64 `json:"maxExecutionTime,omitempty" tf:"max_execution_time,omitempty"`

	// Maximum abstract syntax tree depth after after expansion of aliases.
	MaxExpandedAstElements *float64 `json:"maxExpandedAstElements,omitempty" tf:"max_expanded_ast_elements,omitempty"`

	// Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	MaxFinalThreads *float64 `json:"maxFinalThreads,omitempty" tf:"max_final_threads,omitempty"`

	// Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
	MaxHTTPGetRedirects *float64 `json:"maxHttpGetRedirects,omitempty" tf:"max_http_get_redirects,omitempty"`

	// The size of blocks (in a count of rows) to form for insertion into a table.
	MaxInsertBlockSize *float64 `json:"maxInsertBlockSize,omitempty" tf:"max_insert_block_size,omitempty"`

	// Limits the maximum memory usage (in bytes) for processing queries on a single server.
	MaxMemoryUsage *float64 `json:"maxMemoryUsage,omitempty" tf:"max_memory_usage,omitempty"`

	// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	MaxMemoryUsageForUser *float64 `json:"maxMemoryUsageForUser,omitempty" tf:"max_memory_usage_for_user,omitempty"`

	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidth *float64 `json:"maxNetworkBandwidth,omitempty" tf:"max_network_bandwidth,omitempty"`

	// Limits the speed of the data exchange over the network in bytes per second.
	MaxNetworkBandwidthForUser *float64 `json:"maxNetworkBandwidthForUser,omitempty" tf:"max_network_bandwidth_for_user,omitempty"`

	// Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	MaxParserDepth *float64 `json:"maxParserDepth,omitempty" tf:"max_parser_depth,omitempty"`

	// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	MaxQuerySize *float64 `json:"maxQuerySize,omitempty" tf:"max_query_size,omitempty"`

	// The maximum size of the buffer to read from the filesystem.
	MaxReadBufferSize *float64 `json:"maxReadBufferSize,omitempty" tf:"max_read_buffer_size,omitempty"`

	// Disables lagging replicas for distributed queries.
	MaxReplicaDelayForDistributedQueries *float64 `json:"maxReplicaDelayForDistributedQueries,omitempty" tf:"max_replica_delay_for_distributed_queries,omitempty"`

	// Limits the number of bytes in the result.
	MaxResultBytes *float64 `json:"maxResultBytes,omitempty" tf:"max_result_bytes,omitempty"`

	// Limits the number of rows in the result.
	MaxResultRows *float64 `json:"maxResultRows,omitempty" tf:"max_result_rows,omitempty"`

	// Limits the maximum number of different rows when using DISTINCT.
	MaxRowsInDistinct *float64 `json:"maxRowsInDistinct,omitempty" tf:"max_rows_in_distinct,omitempty"`

	// Limit on maximum size of the hash table for JOIN, in rows.
	MaxRowsInJoin *float64 `json:"maxRowsInJoin,omitempty" tf:"max_rows_in_join,omitempty"`

	// Limit on the number of rows in the set resulting from the execution of the IN section.
	MaxRowsInSet *float64 `json:"maxRowsInSet,omitempty" tf:"max_rows_in_set,omitempty"`

	// Limits the maximum number of unique keys received from aggregation function.
	MaxRowsToGroupBy *float64 `json:"maxRowsToGroupBy,omitempty" tf:"max_rows_to_group_by,omitempty"`

	// Limits the maximum number of rows that can be read from a table when running a query.
	MaxRowsToRead *float64 `json:"maxRowsToRead,omitempty" tf:"max_rows_to_read,omitempty"`

	// Limits the maximum number of rows that can be read from a table for sorting.
	MaxRowsToSort *float64 `json:"maxRowsToSort,omitempty" tf:"max_rows_to_sort,omitempty"`

	// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	MaxRowsToTransfer *float64 `json:"maxRowsToTransfer,omitempty" tf:"max_rows_to_transfer,omitempty"`

	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	MaxTemporaryColumns *float64 `json:"maxTemporaryColumns,omitempty" tf:"max_temporary_columns,omitempty"`

	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForQuery *float64 `json:"maxTemporaryDataOnDiskSizeForQuery,omitempty" tf:"max_temporary_data_on_disk_size_for_query,omitempty"`

	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	MaxTemporaryDataOnDiskSizeForUser *float64 `json:"maxTemporaryDataOnDiskSizeForUser,omitempty" tf:"max_temporary_data_on_disk_size_for_user,omitempty"`

	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	MaxTemporaryNonConstColumns *float64 `json:"maxTemporaryNonConstColumns,omitempty" tf:"max_temporary_non_const_columns,omitempty"`

	// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	MaxThreads *float64 `json:"maxThreads,omitempty" tf:"max_threads,omitempty"`

	// It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominator *float64 `json:"memoryOvercommitRatioDenominator,omitempty" tf:"memory_overcommit_ratio_denominator,omitempty"`

	// It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	MemoryOvercommitRatioDenominatorForUser *float64 `json:"memoryOvercommitRatioDenominatorForUser,omitempty" tf:"memory_overcommit_ratio_denominator_for_user,omitempty"`

	// Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	MemoryProfilerSampleProbability *float64 `json:"memoryProfilerSampleProbability,omitempty" tf:"memory_profiler_sample_probability,omitempty"`

	// Memory profiler step (in bytes).  If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	MemoryProfilerStep *float64 `json:"memoryProfilerStep,omitempty" tf:"memory_profiler_step,omitempty"`

	// Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	MemoryUsageOvercommitMaxWaitMicroseconds *float64 `json:"memoryUsageOvercommitMaxWaitMicroseconds,omitempty" tf:"memory_usage_overcommit_max_wait_microseconds,omitempty"`

	// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxBytesToUseCache *float64 `json:"mergeTreeMaxBytesToUseCache,omitempty" tf:"merge_tree_max_bytes_to_use_cache,omitempty"`

	// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	MergeTreeMaxRowsToUseCache *float64 `json:"mergeTreeMaxRowsToUseCache,omitempty" tf:"merge_tree_max_rows_to_use_cache,omitempty"`

	// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	MergeTreeMinBytesForConcurrentRead *float64 `json:"mergeTreeMinBytesForConcurrentRead,omitempty" tf:"merge_tree_min_bytes_for_concurrent_read,omitempty"`

	// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	MergeTreeMinRowsForConcurrentRead *float64 `json:"mergeTreeMinRowsForConcurrentRead,omitempty" tf:"merge_tree_min_rows_for_concurrent_read,omitempty"`

	// The minimum data volume required for using direct I/O access to the storage disk.
	MinBytesToUseDirectIo *float64 `json:"minBytesToUseDirectIo,omitempty" tf:"min_bytes_to_use_direct_io,omitempty"`

	// How many times to potentially use a compiled chunk of code before running compilation.
	MinCountToCompile *float64 `json:"minCountToCompile,omitempty" tf:"min_count_to_compile,omitempty"`

	// A query waits for expression compilation process to complete prior to continuing execution.
	MinCountToCompileExpression *float64 `json:"minCountToCompileExpression,omitempty" tf:"min_count_to_compile_expression,omitempty"`

	// Minimal execution speed in rows per second.
	MinExecutionSpeed *float64 `json:"minExecutionSpeed,omitempty" tf:"min_execution_speed,omitempty"`

	// Minimal execution speed in bytes per second.
	MinExecutionSpeedBytes *float64 `json:"minExecutionSpeedBytes,omitempty" tf:"min_execution_speed_bytes,omitempty"`

	// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeBytes *float64 `json:"minInsertBlockSizeBytes,omitempty" tf:"min_insert_block_size_bytes,omitempty"`

	// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	MinInsertBlockSizeRows *float64 `json:"minInsertBlockSizeRows,omitempty" tf:"min_insert_block_size_rows,omitempty"`

	// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	OutputFormatJSONQuote64BitIntegers *bool `json:"outputFormatJsonQuote64BitIntegers,omitempty" tf:"output_format_json_quote_64bit_integers,omitempty"`

	// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
	OutputFormatJSONQuoteDenormals *bool `json:"outputFormatJsonQuoteDenormals,omitempty" tf:"output_format_json_quote_denormals,omitempty"`

	// Query priority.
	Priority *float64 `json:"priority,omitempty" tf:"priority,omitempty"`

	// Quota accounting mode.
	QuotaMode *string `json:"quotaMode,omitempty" tf:"quota_mode,omitempty"`

	// Sets behaviour on overflow while read. Possible values:
	ReadOverflowMode *string `json:"readOverflowMode,omitempty" tf:"read_overflow_mode,omitempty"`

	// Restricts permissions for reading data, write data and change settings queries.
	Readonly *float64 `json:"readonly,omitempty" tf:"readonly,omitempty"`

	// Receive timeout in milliseconds on the socket used for communicating with the client.
	ReceiveTimeout *float64 `json:"receiveTimeout,omitempty" tf:"receive_timeout,omitempty"`

	// Method of reading data from remote filesystem, one of: read, threadpool.
	RemoteFilesystemReadMethod *string `json:"remoteFilesystemReadMethod,omitempty" tf:"remote_filesystem_read_method,omitempty"`

	// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	ReplicationAlterPartitionsSync *float64 `json:"replicationAlterPartitionsSync,omitempty" tf:"replication_alter_partitions_sync,omitempty"`

	// Sets behaviour on overflow in result. Possible values:
	ResultOverflowMode *string `json:"resultOverflowMode,omitempty" tf:"result_overflow_mode,omitempty"`

	// Enables or disables sequential consistency for SELECT queries.
	SelectSequentialConsistency *bool `json:"selectSequentialConsistency,omitempty" tf:"select_sequential_consistency,omitempty"`

	// Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
	SendProgressInHTTPHeaders *bool `json:"sendProgressInHttpHeaders,omitempty" tf:"send_progress_in_http_headers,omitempty"`

	// Send timeout in milliseconds on the socket used for communicating with the client.
	SendTimeout *float64 `json:"sendTimeout,omitempty" tf:"send_timeout,omitempty"`

	// Sets behaviour on overflow in the set resulting. Possible values:
	SetOverflowMode *string `json:"setOverflowMode,omitempty" tf:"set_overflow_mode,omitempty"`

	// Enables or disables silently skipping of unavailable shards.
	SkipUnavailableShards *bool `json:"skipUnavailableShards,omitempty" tf:"skip_unavailable_shards,omitempty"`

	// Sets behaviour on overflow while sort. Possible values:
	SortOverflowMode *string `json:"sortOverflowMode,omitempty" tf:"sort_overflow_mode,omitempty"`

	// Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter.
	// Must be at least 1000.
	TimeoutBeforeCheckingExecutionSpeed *float64 `json:"timeoutBeforeCheckingExecutionSpeed,omitempty" tf:"timeout_before_checking_execution_speed,omitempty"`

	// Sets behaviour on overflow. Possible values:
	TimeoutOverflowMode *string `json:"timeoutOverflowMode,omitempty" tf:"timeout_overflow_mode,omitempty"`

	// Sets behaviour on overflow. Possible values:
	TransferOverflowMode *string `json:"transferOverflowMode,omitempty" tf:"transfer_overflow_mode,omitempty"`

	// Enables equality of NULL values for IN operator.
	TransformNullIn *bool `json:"transformNullIn,omitempty" tf:"transform_null_in,omitempty"`

	// Whether to use a cache of uncompressed blocks.
	UseUncompressedCache *bool `json:"useUncompressedCache,omitempty" tf:"use_uncompressed_cache,omitempty"`

	// Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	WaitForAsyncInsert *bool `json:"waitForAsyncInsert,omitempty" tf:"wait_for_async_insert,omitempty"`

	// The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	WaitForAsyncInsertTimeout *float64 `json:"waitForAsyncInsertTimeout,omitempty" tf:"wait_for_async_insert_timeout,omitempty"`
}

type UserSettingsParameters struct {

	// Include CORS headers in HTTP responces.
	// +kubebuilder:validation:Optional
	AddHTTPCorsHeader *bool `json:"addHttpCorsHeader,omitempty" tf:"add_http_cors_header,omitempty"`

	// Allows or denies DDL queries.
	// +kubebuilder:validation:Optional
	AllowDdl *bool `json:"allowDdl,omitempty" tf:"allow_ddl,omitempty"`

	// Enables introspections functions for query profiling.
	// +kubebuilder:validation:Optional
	AllowIntrospectionFunctions *bool `json:"allowIntrospectionFunctions,omitempty" tf:"allow_introspection_functions,omitempty"`

	// Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
	// +kubebuilder:validation:Optional
	AllowSuspiciousLowCardinalityTypes *bool `json:"allowSuspiciousLowCardinalityTypes,omitempty" tf:"allow_suspicious_low_cardinality_types,omitempty"`

	// Enables asynchronous inserts. Disabled by default.
	// +kubebuilder:validation:Optional
	AsyncInsert *bool `json:"asyncInsert,omitempty" tf:"async_insert,omitempty"`

	// The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
	// +kubebuilder:validation:Optional
	AsyncInsertBusyTimeout *float64 `json:"asyncInsertBusyTimeout,omitempty" tf:"async_insert_busy_timeout,omitempty"`

	// The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
	// +kubebuilder:validation:Optional
	AsyncInsertMaxDataSize *float64 `json:"asyncInsertMaxDataSize,omitempty" tf:"async_insert_max_data_size,omitempty"`

	// The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
	// +kubebuilder:validation:Optional
	AsyncInsertStaleTimeout *float64 `json:"asyncInsertStaleTimeout,omitempty" tf:"async_insert_stale_timeout,omitempty"`

	// The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
	// +kubebuilder:validation:Optional
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response.
	// Default value: false.
	// +kubebuilder:validation:Optional
	CancelHTTPReadonlyQueriesOnClientClose *bool `json:"cancelHttpReadonlyQueriesOnClientClose,omitempty" tf:"cancel_http_readonly_queries_on_client_close,omitempty"`

	// Enable compilation of queries.
	// +kubebuilder:validation:Optional
	Compile *bool `json:"compile,omitempty" tf:"compile,omitempty"`

	// Turn on expression compilation.
	// +kubebuilder:validation:Optional
	CompileExpressions *bool `json:"compileExpressions,omitempty" tf:"compile_expressions,omitempty"`

	// Connect timeout in milliseconds on the socket used for communicating with the client.
	// +kubebuilder:validation:Optional
	ConnectTimeout *float64 `json:"connectTimeout,omitempty" tf:"connect_timeout,omitempty"`

	// The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
	// +kubebuilder:validation:Optional
	ConnectTimeoutWithFailover *float64 `json:"connectTimeoutWithFailover,omitempty" tf:"connect_timeout_with_failover,omitempty"`

	// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
	// +kubebuilder:validation:Optional
	CountDistinctImplementation *string `json:"countDistinctImplementation,omitempty" tf:"count_distinct_implementation,omitempty"`

	// Sets behaviour on overflow when using DISTINCT. Possible values:
	// +kubebuilder:validation:Optional
	DistinctOverflowMode *string `json:"distinctOverflowMode,omitempty" tf:"distinct_overflow_mode,omitempty"`

	// Determine the behavior of distributed subqueries.
	// +kubebuilder:validation:Optional
	DistributedAggregationMemoryEfficient *bool `json:"distributedAggregationMemoryEfficient,omitempty" tf:"distributed_aggregation_memory_efficient,omitempty"`

	// Timeout for DDL queries, in milliseconds.
	// +kubebuilder:validation:Optional
	DistributedDdlTaskTimeout *float64 `json:"distributedDdlTaskTimeout,omitempty" tf:"distributed_ddl_task_timeout,omitempty"`

	// Changes the behaviour of distributed subqueries.
	// +kubebuilder:validation:Optional
	DistributedProductMode *string `json:"distributedProductMode,omitempty" tf:"distributed_product_mode,omitempty"`

	// Allows to retunr empty result.
	// +kubebuilder:validation:Optional
	EmptyResultForAggregationByEmptySet *bool `json:"emptyResultForAggregationByEmptySet,omitempty" tf:"empty_result_for_aggregation_by_empty_set,omitempty"`

	// Enables or disables data compression in the response to an HTTP request.
	// +kubebuilder:validation:Optional
	EnableHTTPCompression *bool `json:"enableHttpCompression,omitempty" tf:"enable_http_compression,omitempty"`

	// Forces a query to an out-of-date replica if updated data is not available.
	// +kubebuilder:validation:Optional
	FallbackToStaleReplicasForDistributedQueries *bool `json:"fallbackToStaleReplicasForDistributedQueries,omitempty" tf:"fallback_to_stale_replicas_for_distributed_queries,omitempty"`

	// Sets the data format of a nested columns.
	// +kubebuilder:validation:Optional
	FlattenNested *bool `json:"flattenNested,omitempty" tf:"flatten_nested,omitempty"`

	// Disables query execution if the index can’t be used by date.
	// +kubebuilder:validation:Optional
	ForceIndexByDate *bool `json:"forceIndexByDate,omitempty" tf:"force_index_by_date,omitempty"`

	// Disables query execution if indexing by the primary key is not possible.
	// +kubebuilder:validation:Optional
	ForcePrimaryKey *bool `json:"forcePrimaryKey,omitempty" tf:"force_primary_key,omitempty"`

	// Sets behaviour on overflow while GROUP BY operation. Possible values:
	// +kubebuilder:validation:Optional
	GroupByOverflowMode *string `json:"groupByOverflowMode,omitempty" tf:"group_by_overflow_mode,omitempty"`

	// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
	// +kubebuilder:validation:Optional
	GroupByTwoLevelThreshold *float64 `json:"groupByTwoLevelThreshold,omitempty" tf:"group_by_two_level_threshold,omitempty"`

	// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
	// +kubebuilder:validation:Optional
	GroupByTwoLevelThresholdBytes *float64 `json:"groupByTwoLevelThresholdBytes,omitempty" tf:"group_by_two_level_threshold_bytes,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	// +kubebuilder:validation:Optional
	HTTPConnectionTimeout *float64 `json:"httpConnectionTimeout,omitempty" tf:"http_connection_timeout,omitempty"`

	// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
	// +kubebuilder:validation:Optional
	HTTPHeadersProgressInterval *float64 `json:"httpHeadersProgressInterval,omitempty" tf:"http_headers_progress_interval,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	// +kubebuilder:validation:Optional
	HTTPReceiveTimeout *float64 `json:"httpReceiveTimeout,omitempty" tf:"http_receive_timeout,omitempty"`

	// Timeout for HTTP connection in milliseconds.
	// +kubebuilder:validation:Optional
	HTTPSendTimeout *float64 `json:"httpSendTimeout,omitempty" tf:"http_send_timeout,omitempty"`

	// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
	// +kubebuilder:validation:Optional
	InputFormatDefaultsForOmittedFields *bool `json:"inputFormatDefaultsForOmittedFields,omitempty" tf:"input_format_defaults_for_omitted_fields,omitempty"`

	// Enables or disables the insertion of JSON data with nested objects.
	// +kubebuilder:validation:Optional
	InputFormatImportNestedJSON *bool `json:"inputFormatImportNestedJson,omitempty" tf:"input_format_import_nested_json,omitempty"`

	// Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
	// +kubebuilder:validation:Optional
	InputFormatParallelParsing *bool `json:"inputFormatParallelParsing,omitempty" tf:"input_format_parallel_parsing,omitempty"`

	// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
	// +kubebuilder:validation:Optional
	InputFormatValuesInterpretExpressions *bool `json:"inputFormatValuesInterpretExpressions,omitempty" tf:"input_format_values_interpret_expressions,omitempty"`

	// The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.
	// +kubebuilder:validation:Optional
	InsertKeeperMaxRetries *float64 `json:"insertKeeperMaxRetries,omitempty" tf:"insert_keeper_max_retries,omitempty"`

	// Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
	// +kubebuilder:validation:Optional
	InsertNullAsDefault *bool `json:"insertNullAsDefault,omitempty" tf:"insert_null_as_default,omitempty"`

	// Enables the quorum writes.
	// +kubebuilder:validation:Optional
	InsertQuorum *float64 `json:"insertQuorum,omitempty" tf:"insert_quorum,omitempty"`

	// Write to a quorum timeout in milliseconds.
	// +kubebuilder:validation:Optional
	InsertQuorumTimeout *float64 `json:"insertQuorumTimeout,omitempty" tf:"insert_quorum_timeout,omitempty"`

	// Sets behaviour on overflow in JOIN. Possible values:
	// +kubebuilder:validation:Optional
	JoinOverflowMode *string `json:"joinOverflowMode,omitempty" tf:"join_overflow_mode,omitempty"`

	// Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
	// +kubebuilder:validation:Optional
	JoinUseNulls *bool `json:"joinUseNulls,omitempty" tf:"join_use_nulls,omitempty"`

	// Require aliases for subselects and table functions in FROM that more than one table is present.
	// +kubebuilder:validation:Optional
	JoinedSubqueryRequiresAlias *bool `json:"joinedSubqueryRequiresAlias,omitempty" tf:"joined_subquery_requires_alias,omitempty"`

	// Method of reading data from local filesystem. Possible values:
	// +kubebuilder:validation:Optional
	LocalFilesystemReadMethod *string `json:"localFilesystemReadMethod,omitempty" tf:"local_filesystem_read_method,omitempty"`

	// Allows or restricts using the LowCardinality data type with the Native format.
	// +kubebuilder:validation:Optional
	LowCardinalityAllowInNativeFormat *bool `json:"lowCardinalityAllowInNativeFormat,omitempty" tf:"low_cardinality_allow_in_native_format,omitempty"`

	// Maximum abstract syntax tree depth.
	// +kubebuilder:validation:Optional
	MaxAstDepth *float64 `json:"maxAstDepth,omitempty" tf:"max_ast_depth,omitempty"`

	// Maximum abstract syntax tree elements.
	// +kubebuilder:validation:Optional
	MaxAstElements *float64 `json:"maxAstElements,omitempty" tf:"max_ast_elements,omitempty"`

	// A recommendation for what size of the block (in a count of rows) to load from tables.
	// +kubebuilder:validation:Optional
	MaxBlockSize *float64 `json:"maxBlockSize,omitempty" tf:"max_block_size,omitempty"`

	// Limit in bytes for using memoru for GROUP BY before using swap on disk.
	// +kubebuilder:validation:Optional
	MaxBytesBeforeExternalGroupBy *float64 `json:"maxBytesBeforeExternalGroupBy,omitempty" tf:"max_bytes_before_external_group_by,omitempty"`

	// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
	// +kubebuilder:validation:Optional
	MaxBytesBeforeExternalSort *float64 `json:"maxBytesBeforeExternalSort,omitempty" tf:"max_bytes_before_external_sort,omitempty"`

	// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
	// +kubebuilder:validation:Optional
	MaxBytesInDistinct *float64 `json:"maxBytesInDistinct,omitempty" tf:"max_bytes_in_distinct,omitempty"`

	// Limit on maximum size of the hash table for JOIN, in bytes.
	// +kubebuilder:validation:Optional
	MaxBytesInJoin *float64 `json:"maxBytesInJoin,omitempty" tf:"max_bytes_in_join,omitempty"`

	// Limit on the number of bytes in the set resulting from the execution of the IN section.
	// +kubebuilder:validation:Optional
	MaxBytesInSet *float64 `json:"maxBytesInSet,omitempty" tf:"max_bytes_in_set,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
	// +kubebuilder:validation:Optional
	MaxBytesToRead *float64 `json:"maxBytesToRead,omitempty" tf:"max_bytes_to_read,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
	// +kubebuilder:validation:Optional
	MaxBytesToSort *float64 `json:"maxBytesToSort,omitempty" tf:"max_bytes_to_sort,omitempty"`

	// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// +kubebuilder:validation:Optional
	MaxBytesToTransfer *float64 `json:"maxBytesToTransfer,omitempty" tf:"max_bytes_to_transfer,omitempty"`

	// Limits the maximum number of columns that can be read from a table in a single query.
	// +kubebuilder:validation:Optional
	MaxColumnsToRead *float64 `json:"maxColumnsToRead,omitempty" tf:"max_columns_to_read,omitempty"`

	// The maximum number of concurrent requests per user. Default value: 0 (no limit).
	// +kubebuilder:validation:Optional
	MaxConcurrentQueriesForUser *float64 `json:"maxConcurrentQueriesForUser,omitempty" tf:"max_concurrent_queries_for_user,omitempty"`

	// Limits the maximum query execution time in milliseconds.
	// +kubebuilder:validation:Optional
	MaxExecutionTime *float64 `json:"maxExecutionTime,omitempty" tf:"max_execution_time,omitempty"`

	// Maximum abstract syntax tree depth after after expansion of aliases.
	// +kubebuilder:validation:Optional
	MaxExpandedAstElements *float64 `json:"maxExpandedAstElements,omitempty" tf:"max_expanded_ast_elements,omitempty"`

	// Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
	// +kubebuilder:validation:Optional
	MaxFinalThreads *float64 `json:"maxFinalThreads,omitempty" tf:"max_final_threads,omitempty"`

	// Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
	// +kubebuilder:validation:Optional
	MaxHTTPGetRedirects *float64 `json:"maxHttpGetRedirects,omitempty" tf:"max_http_get_redirects,omitempty"`

	// The size of blocks (in a count of rows) to form for insertion into a table.
	// +kubebuilder:validation:Optional
	MaxInsertBlockSize *float64 `json:"maxInsertBlockSize,omitempty" tf:"max_insert_block_size,omitempty"`

	// Limits the maximum memory usage (in bytes) for processing queries on a single server.
	// +kubebuilder:validation:Optional
	MaxMemoryUsage *float64 `json:"maxMemoryUsage,omitempty" tf:"max_memory_usage,omitempty"`

	// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
	// +kubebuilder:validation:Optional
	MaxMemoryUsageForUser *float64 `json:"maxMemoryUsageForUser,omitempty" tf:"max_memory_usage_for_user,omitempty"`

	// Limits the speed of the data exchange over the network in bytes per second.
	// +kubebuilder:validation:Optional
	MaxNetworkBandwidth *float64 `json:"maxNetworkBandwidth,omitempty" tf:"max_network_bandwidth,omitempty"`

	// Limits the speed of the data exchange over the network in bytes per second.
	// +kubebuilder:validation:Optional
	MaxNetworkBandwidthForUser *float64 `json:"maxNetworkBandwidthForUser,omitempty" tf:"max_network_bandwidth_for_user,omitempty"`

	// Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. Zero means unlimited.
	// +kubebuilder:validation:Optional
	MaxParserDepth *float64 `json:"maxParserDepth,omitempty" tf:"max_parser_depth,omitempty"`

	// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
	// +kubebuilder:validation:Optional
	MaxQuerySize *float64 `json:"maxQuerySize,omitempty" tf:"max_query_size,omitempty"`

	// The maximum size of the buffer to read from the filesystem.
	// +kubebuilder:validation:Optional
	MaxReadBufferSize *float64 `json:"maxReadBufferSize,omitempty" tf:"max_read_buffer_size,omitempty"`

	// Disables lagging replicas for distributed queries.
	// +kubebuilder:validation:Optional
	MaxReplicaDelayForDistributedQueries *float64 `json:"maxReplicaDelayForDistributedQueries,omitempty" tf:"max_replica_delay_for_distributed_queries,omitempty"`

	// Limits the number of bytes in the result.
	// +kubebuilder:validation:Optional
	MaxResultBytes *float64 `json:"maxResultBytes,omitempty" tf:"max_result_bytes,omitempty"`

	// Limits the number of rows in the result.
	// +kubebuilder:validation:Optional
	MaxResultRows *float64 `json:"maxResultRows,omitempty" tf:"max_result_rows,omitempty"`

	// Limits the maximum number of different rows when using DISTINCT.
	// +kubebuilder:validation:Optional
	MaxRowsInDistinct *float64 `json:"maxRowsInDistinct,omitempty" tf:"max_rows_in_distinct,omitempty"`

	// Limit on maximum size of the hash table for JOIN, in rows.
	// +kubebuilder:validation:Optional
	MaxRowsInJoin *float64 `json:"maxRowsInJoin,omitempty" tf:"max_rows_in_join,omitempty"`

	// Limit on the number of rows in the set resulting from the execution of the IN section.
	// +kubebuilder:validation:Optional
	MaxRowsInSet *float64 `json:"maxRowsInSet,omitempty" tf:"max_rows_in_set,omitempty"`

	// Limits the maximum number of unique keys received from aggregation function.
	// +kubebuilder:validation:Optional
	MaxRowsToGroupBy *float64 `json:"maxRowsToGroupBy,omitempty" tf:"max_rows_to_group_by,omitempty"`

	// Limits the maximum number of rows that can be read from a table when running a query.
	// +kubebuilder:validation:Optional
	MaxRowsToRead *float64 `json:"maxRowsToRead,omitempty" tf:"max_rows_to_read,omitempty"`

	// Limits the maximum number of rows that can be read from a table for sorting.
	// +kubebuilder:validation:Optional
	MaxRowsToSort *float64 `json:"maxRowsToSort,omitempty" tf:"max_rows_to_sort,omitempty"`

	// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
	// +kubebuilder:validation:Optional
	MaxRowsToTransfer *float64 `json:"maxRowsToTransfer,omitempty" tf:"max_rows_to_transfer,omitempty"`

	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
	// +kubebuilder:validation:Optional
	MaxTemporaryColumns *float64 `json:"maxTemporaryColumns,omitempty" tf:"max_temporary_columns,omitempty"`

	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. Zero means unlimited.
	// +kubebuilder:validation:Optional
	MaxTemporaryDataOnDiskSizeForQuery *float64 `json:"maxTemporaryDataOnDiskSizeForQuery,omitempty" tf:"max_temporary_data_on_disk_size_for_query,omitempty"`

	// The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. Zero means unlimited.
	// +kubebuilder:validation:Optional
	MaxTemporaryDataOnDiskSizeForUser *float64 `json:"maxTemporaryDataOnDiskSizeForUser,omitempty" tf:"max_temporary_data_on_disk_size_for_user,omitempty"`

	// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
	// +kubebuilder:validation:Optional
	MaxTemporaryNonConstColumns *float64 `json:"maxTemporaryNonConstColumns,omitempty" tf:"max_temporary_non_const_columns,omitempty"`

	// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
	// +kubebuilder:validation:Optional
	MaxThreads *float64 `json:"maxThreads,omitempty" tf:"max_threads,omitempty"`

	// It represents soft memory limit in case when hard limit is reached on user level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// +kubebuilder:validation:Optional
	MemoryOvercommitRatioDenominator *float64 `json:"memoryOvercommitRatioDenominator,omitempty" tf:"memory_overcommit_ratio_denominator,omitempty"`

	// It represents soft memory limit in case when hard limit is reached on global level. This value is used to compute overcommit ratio for the query. Zero means skip the query.
	// +kubebuilder:validation:Optional
	MemoryOvercommitRatioDenominatorForUser *float64 `json:"memoryOvercommitRatioDenominatorForUser,omitempty" tf:"memory_overcommit_ratio_denominator_for_user,omitempty"`

	// Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
	// +kubebuilder:validation:Optional
	MemoryProfilerSampleProbability *float64 `json:"memoryProfilerSampleProbability,omitempty" tf:"memory_profiler_sample_probability,omitempty"`

	// Memory profiler step (in bytes).  If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
	// +kubebuilder:validation:Optional
	MemoryProfilerStep *float64 `json:"memoryProfilerStep,omitempty" tf:"memory_profiler_step,omitempty"`

	// Maximum time thread will wait for memory to be freed in the case of memory overcommit on a user level. If the timeout is reached and memory is not freed, an exception is thrown.
	// +kubebuilder:validation:Optional
	MemoryUsageOvercommitMaxWaitMicroseconds *float64 `json:"memoryUsageOvercommitMaxWaitMicroseconds,omitempty" tf:"memory_usage_overcommit_max_wait_microseconds,omitempty"`

	// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
	// +kubebuilder:validation:Optional
	MergeTreeMaxBytesToUseCache *float64 `json:"mergeTreeMaxBytesToUseCache,omitempty" tf:"merge_tree_max_bytes_to_use_cache,omitempty"`

	// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
	// +kubebuilder:validation:Optional
	MergeTreeMaxRowsToUseCache *float64 `json:"mergeTreeMaxRowsToUseCache,omitempty" tf:"merge_tree_max_rows_to_use_cache,omitempty"`

	// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
	// +kubebuilder:validation:Optional
	MergeTreeMinBytesForConcurrentRead *float64 `json:"mergeTreeMinBytesForConcurrentRead,omitempty" tf:"merge_tree_min_bytes_for_concurrent_read,omitempty"`

	// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
	// +kubebuilder:validation:Optional
	MergeTreeMinRowsForConcurrentRead *float64 `json:"mergeTreeMinRowsForConcurrentRead,omitempty" tf:"merge_tree_min_rows_for_concurrent_read,omitempty"`

	// The minimum data volume required for using direct I/O access to the storage disk.
	// +kubebuilder:validation:Optional
	MinBytesToUseDirectIo *float64 `json:"minBytesToUseDirectIo,omitempty" tf:"min_bytes_to_use_direct_io,omitempty"`

	// How many times to potentially use a compiled chunk of code before running compilation.
	// +kubebuilder:validation:Optional
	MinCountToCompile *float64 `json:"minCountToCompile,omitempty" tf:"min_count_to_compile,omitempty"`

	// A query waits for expression compilation process to complete prior to continuing execution.
	// +kubebuilder:validation:Optional
	MinCountToCompileExpression *float64 `json:"minCountToCompileExpression,omitempty" tf:"min_count_to_compile_expression,omitempty"`

	// Minimal execution speed in rows per second.
	// +kubebuilder:validation:Optional
	MinExecutionSpeed *float64 `json:"minExecutionSpeed,omitempty" tf:"min_execution_speed,omitempty"`

	// Minimal execution speed in bytes per second.
	// +kubebuilder:validation:Optional
	MinExecutionSpeedBytes *float64 `json:"minExecutionSpeedBytes,omitempty" tf:"min_execution_speed_bytes,omitempty"`

	// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
	// +kubebuilder:validation:Optional
	MinInsertBlockSizeBytes *float64 `json:"minInsertBlockSizeBytes,omitempty" tf:"min_insert_block_size_bytes,omitempty"`

	// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
	// +kubebuilder:validation:Optional
	MinInsertBlockSizeRows *float64 `json:"minInsertBlockSizeRows,omitempty" tf:"min_insert_block_size_rows,omitempty"`

	// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
	// +kubebuilder:validation:Optional
	OutputFormatJSONQuote64BitIntegers *bool `json:"outputFormatJsonQuote64BitIntegers,omitempty" tf:"output_format_json_quote_64bit_integers,omitempty"`

	// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
	// +kubebuilder:validation:Optional
	OutputFormatJSONQuoteDenormals *bool `json:"outputFormatJsonQuoteDenormals,omitempty" tf:"output_format_json_quote_denormals,omitempty"`

	// Query priority.
	// +kubebuilder:validation:Optional
	Priority *float64 `json:"priority,omitempty" tf:"priority,omitempty"`

	// Quota accounting mode.
	// +kubebuilder:validation:Optional
	QuotaMode *string `json:"quotaMode,omitempty" tf:"quota_mode,omitempty"`

	// Sets behaviour on overflow while read. Possible values:
	// +kubebuilder:validation:Optional
	ReadOverflowMode *string `json:"readOverflowMode,omitempty" tf:"read_overflow_mode,omitempty"`

	// Restricts permissions for reading data, write data and change settings queries.
	// +kubebuilder:validation:Optional
	Readonly *float64 `json:"readonly,omitempty" tf:"readonly,omitempty"`

	// Receive timeout in milliseconds on the socket used for communicating with the client.
	// +kubebuilder:validation:Optional
	ReceiveTimeout *float64 `json:"receiveTimeout,omitempty" tf:"receive_timeout,omitempty"`

	// Method of reading data from remote filesystem, one of: read, threadpool.
	// +kubebuilder:validation:Optional
	RemoteFilesystemReadMethod *string `json:"remoteFilesystemReadMethod,omitempty" tf:"remote_filesystem_read_method,omitempty"`

	// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
	// +kubebuilder:validation:Optional
	ReplicationAlterPartitionsSync *float64 `json:"replicationAlterPartitionsSync,omitempty" tf:"replication_alter_partitions_sync,omitempty"`

	// Sets behaviour on overflow in result. Possible values:
	// +kubebuilder:validation:Optional
	ResultOverflowMode *string `json:"resultOverflowMode,omitempty" tf:"result_overflow_mode,omitempty"`

	// Enables or disables sequential consistency for SELECT queries.
	// +kubebuilder:validation:Optional
	SelectSequentialConsistency *bool `json:"selectSequentialConsistency,omitempty" tf:"select_sequential_consistency,omitempty"`

	// Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
	// +kubebuilder:validation:Optional
	SendProgressInHTTPHeaders *bool `json:"sendProgressInHttpHeaders,omitempty" tf:"send_progress_in_http_headers,omitempty"`

	// Send timeout in milliseconds on the socket used for communicating with the client.
	// +kubebuilder:validation:Optional
	SendTimeout *float64 `json:"sendTimeout,omitempty" tf:"send_timeout,omitempty"`

	// Sets behaviour on overflow in the set resulting. Possible values:
	// +kubebuilder:validation:Optional
	SetOverflowMode *string `json:"setOverflowMode,omitempty" tf:"set_overflow_mode,omitempty"`

	// Enables or disables silently skipping of unavailable shards.
	// +kubebuilder:validation:Optional
	SkipUnavailableShards *bool `json:"skipUnavailableShards,omitempty" tf:"skip_unavailable_shards,omitempty"`

	// Sets behaviour on overflow while sort. Possible values:
	// +kubebuilder:validation:Optional
	SortOverflowMode *string `json:"sortOverflowMode,omitempty" tf:"sort_overflow_mode,omitempty"`

	// Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter.
	// Must be at least 1000.
	// +kubebuilder:validation:Optional
	TimeoutBeforeCheckingExecutionSpeed *float64 `json:"timeoutBeforeCheckingExecutionSpeed,omitempty" tf:"timeout_before_checking_execution_speed,omitempty"`

	// Sets behaviour on overflow. Possible values:
	// +kubebuilder:validation:Optional
	TimeoutOverflowMode *string `json:"timeoutOverflowMode,omitempty" tf:"timeout_overflow_mode,omitempty"`

	// Sets behaviour on overflow. Possible values:
	// +kubebuilder:validation:Optional
	TransferOverflowMode *string `json:"transferOverflowMode,omitempty" tf:"transfer_overflow_mode,omitempty"`

	// Enables equality of NULL values for IN operator.
	// +kubebuilder:validation:Optional
	TransformNullIn *bool `json:"transformNullIn,omitempty" tf:"transform_null_in,omitempty"`

	// Whether to use a cache of uncompressed blocks.
	// +kubebuilder:validation:Optional
	UseUncompressedCache *bool `json:"useUncompressedCache,omitempty" tf:"use_uncompressed_cache,omitempty"`

	// Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
	// +kubebuilder:validation:Optional
	WaitForAsyncInsert *bool `json:"waitForAsyncInsert,omitempty" tf:"wait_for_async_insert,omitempty"`

	// The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
	// +kubebuilder:validation:Optional
	WaitForAsyncInsertTimeout *float64 `json:"waitForAsyncInsertTimeout,omitempty" tf:"wait_for_async_insert_timeout,omitempty"`
}

type ZookeeperInitParameters struct {

	// Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
	Resources []ZookeeperResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ZookeeperObservation struct {

	// Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
	Resources []ZookeeperResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ZookeeperParameters struct {

	// Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
	// +kubebuilder:validation:Optional
	Resources []ZookeeperResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ZookeeperResourcesInitParameters struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ZookeeperResourcesObservation struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ZookeeperResourcesParameters struct {

	// Volume of the storage available to a ZooKeeper host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// Type of the storage of ZooKeeper hosts.
	// For more information see the official documentation.
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

// ClickhouseClusterSpec defines the desired state of ClickhouseCluster
type ClickhouseClusterSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     ClickhouseClusterParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider ClickhouseClusterInitParameters `json:"initProvider,omitempty"`
}

// ClickhouseClusterStatus defines the observed state of ClickhouseCluster.
type ClickhouseClusterStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        ClickhouseClusterObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// ClickhouseCluster is the Schema for the ClickhouseClusters API. Manages a ClickHouse cluster within Yandex.Cloud.
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,yandex-cloud}
type ClickhouseCluster struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.environment) || (has(self.initProvider) && has(self.initProvider.environment))",message="spec.forProvider.environment is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.host) || (has(self.initProvider) && has(self.initProvider.host))",message="spec.forProvider.host is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	Spec   ClickhouseClusterSpec   `json:"spec"`
	Status ClickhouseClusterStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// ClickhouseClusterList contains a list of ClickhouseClusters
type ClickhouseClusterList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []ClickhouseCluster `json:"items"`
}

// Repository type metadata.
var (
	ClickhouseCluster_Kind             = "ClickhouseCluster"
	ClickhouseCluster_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: ClickhouseCluster_Kind}.String()
	ClickhouseCluster_KindAPIVersion   = ClickhouseCluster_Kind + "." + CRDGroupVersion.String()
	ClickhouseCluster_GroupVersionKind = CRDGroupVersion.WithKind(ClickhouseCluster_Kind)
)

func init() {
	SchemeBuilder.Register(&ClickhouseCluster{}, &ClickhouseClusterList{})
}
